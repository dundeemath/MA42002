[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA42002",
    "section": "",
    "text": "Introduction\nWelcome to MA42002 Mathematical Biology II.\nMy name is Philip Murray and I am the module lead.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-to-contact-me",
    "href": "index.html#how-to-contact-me",
    "title": "MA42002",
    "section": "How to contact me?",
    "text": "How to contact me?\n\nemail: pmurray@dundee.ac.uk\noffice: G11, Fulton Building",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "MA42002",
    "section": "Lecture notes",
    "text": "Lecture notes\nYou can find lecture notes for the module on this page. If you would like a pdf this can be easily generated by clicking on the pdf link on the top left of the webpages. I will occasionally edit/update the notes as we proceed through lectures. If you spot any errors/typos/inconsistencies/omissions etc. please report an issue using the report an issue link on the right-hand side of the webpages.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#reading",
    "href": "index.html#reading",
    "title": "MA42002",
    "section": "Reading",
    "text": "Reading\nMathematical Biology II, Murray (2003)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#python-codes",
    "href": "index.html#python-codes",
    "title": "MA42002",
    "section": "Python codes",
    "text": "Python codes\nI have provided Python codes for most of the figures in the html version of the notes (you can unfold code section by clicking `Code’). Note that the Python code does not appear in the pdf.\nMany of you have taken the Introduction to Programming module at Level 2 and have therefore some experience using Python. I strongly encourage you to use the provided codes as a tool to play around with numerical solutions of the various models that we will be working on. The codes should run as standalone Python codes.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "MA42002",
    "section": "Plan",
    "text": "Plan\n\nProjected delivery\n\n\nWeek\nUp to Section\nTutorial sheet\nClass Test\n\n\n\n\n1\n1.3.3\n1\n—-\n\n\n2\n2.1\n1\nQuiz 1\n\n\n3\n3\n2\n—-\n\n\n4\n3\n2\nQuiz 2\n\n\n5\n4\n3\n—\n\n\n6\n4\n4 Class Test 1\n\n\n\n7\n5\n4\n—-\n\n\n8\n5\n5\nQuiz 3\n\n\n9\n6\n5\n—-\n\n\n10\n6\n6\nClass Test 2\n\n\n11\n7\n6\n—-",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "MA42002",
    "section": "References",
    "text": "References\n\n\n\n\nMurray, James Dickson. 2003. Mathematical Biology: II: Spatial Models and Biomedical Applications. Vol. 3. Springer.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "conservationequations.html",
    "href": "conservationequations.html",
    "title": "1  Conservation equations",
    "section": "",
    "text": "1.1 Introduction\nMany biological systems are spatio-temporal, i.e. concentrations of biochemicals, densities of cells etc. depend on spatial position as well time. To describe such cases we must relax a major assumption that was made in Mathematical Biology I (MA32009): spatial homogeneity. We now models biological system using partial differential equations.\nA conservation equation is the most fundamental statement through which changes in the distribution of the density (or concentration, temperature) is described. \\[\n\\begin{pmatrix}\n\\text{rate of change}\\\\\n\\text{ in the population density}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{spatial movement}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{birth, growth, death},\\\\\n\\text{production or degradation}\\\\\n  \\text{due to chemical reactions}\n\\end{pmatrix}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conservation equations</span>"
    ]
  },
  {
    "objectID": "conservationequations.html#sec-conservation",
    "href": "conservationequations.html#sec-conservation",
    "title": "1  Conservation equations",
    "section": "",
    "text": "1.1.1 Notation\nWe will consider \\(x \\in \\mathbb R^n\\), \\(t \\in [0, \\infty)\\) and functions \\(c: \\mathbb R^n \\times [0, \\infty) \\to \\mathbb R\\), where \\(n=1,2,3\\). For example:\n\n\\(c(x,t)\\) - the density of a population [number per volume] at position \\(x\\) and time \\(t\\) (at \\((x,t)\\))\n\\(c(x,t)\\) - the concentration of a substance (chemicals, particles) [mass per volume] at position \\(x\\) and time \\(t\\) (at \\((x,t)\\))\n\\(c(x,t)\\) - the temperature at \\((x,t)\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conservation equations</span>"
    ]
  },
  {
    "objectID": "conservationequations.html#spatially-homogeneous-models",
    "href": "conservationequations.html#spatially-homogeneous-models",
    "title": "1  Conservation equations",
    "section": "1.2 Spatially homogeneous models",
    "text": "1.2 Spatially homogeneous models\nIn this section, we neglect spatial movement and consider examples of growth/death and chemical reactions (i.e. revision from MA32009).\n\n1.2.1 Population dynamics\n\n1.2.1.1 Modelling the growth of bacteria in a petri dish (flask) containing nutrient medium\nAs an example let’s consider a population of bacteria growing in a bounded domain (e.g. a petri dish).\nBacteria reproduce by undergoing successive cell divisions.\nLet \\(N(t)\\) represent bacterial density at time \\(t\\) (i.e. number of cells per volume).\nLet \\(K\\) represent the per capita rate of reproduction. Over a period of time, \\(\\Delta t\\), \\(K N(t) \\Delta t\\) cells will be added. Hence \\[\n\\begin{aligned}\nN(t+\\Delta t) &=  \\quad N(t)   + \\quad  K N(t) \\Delta t.\n\\end{aligned}\n\\tag{1.1}\\]\nAssuming that \\(N\\) is differentiable, dividing Equation 1.1 by \\(\\Delta t\\) and taking the limit as \\(\\Delta t \\to 0\\) \\[\n\\frac{dN}{dt} = K N.\n\\tag{1.2}\\]\nDepending on the biological context, the growth rate \\(K\\) may take several forms e.g.\n\n\\(K = \\textrm{constant}\\)\n\\(K = K(t)\\) time-dependent\n\\(K= K(N(t))\\) depends on bacterial density\n\\(K= K(c(t)):= \\kappa c(t), \\;\\; (\\text{with} \\;\\; \\kappa &gt;0 \\;\\; \\text{a constant}\\)), which depends on the nutrient concentration \\(c(t)\\) at time \\(t\\).\n\n\n\n1.2.1.2 Logistic growth via nutrient depletion\nSuppose that the population growth rate depends on nutrient availability. Suppose also that nutrient levels are depleted by population growth.\nLet \\(c(t)\\) represent the nutrient concentration at time, \\(t\\). Based on the above assumptions we derive \\[\n\\begin{aligned}\n\\frac{dN}{dt} &= K(c) N = \\kappa cN,  \\\\\n\\frac{ dc}{dt} &= - \\alpha \\frac{dN}{dt} = - \\alpha   \\kappa c N,  \n\\end{aligned}\n\\tag{1.3}\\] where \\(\\kappa\\) and \\(\\alpha\\) \\(\\in \\Re\\). Consider the initial conditions \\[\nN(0) = N_0 \\quad \\textrm{and}  \\quad  c(0)= c_0.\n\\]\nNoting the conserved quantity \\[\n\\alpha\\frac{dN}{dt}+\\frac{dc}{dt}=0,\n\\] integration yields \\[\nc(t)  = - \\alpha N(t) + c(0)+ \\alpha N(0) = - \\alpha N(t) + \\beta,\n\\tag{1.4}\\]\nwhere \\(\\beta=c_0 +\\alpha N_0\\). Substituting for Equation 1.4 in Equation 1.3 we obtain the logistic growth equation \\[\n\\frac{dN}{dt} = \\kappa ( \\beta- \\alpha N)  N, \\qquad  N(0)= N_0\\quad,\n\\tag{1.5}\\] where \\(K=K(N) = \\kappa (\\beta - \\alpha N)\\).\nThe last equation can be rewritten as \\[  \n\\frac{dN}{dt} = \\rho  N \\,  (1 - \\frac N B)  \\qquad \\quad N(0)= N_0,\n\\tag{1.6}\\]\nwhere \\(\\rho = \\kappa \\beta\\) is the intrinsic growth rate and \\(B = \\frac \\beta \\alpha\\) is the carrying capacity. The solution of Equation 1.6 is given by \\[\nN(t)= \\frac{ N_0 B} { N_0 + (B-N_0) e^{-\\rho t}} \\; .\n\\]\n\n\n1.2.1.3 Death/decay\nIn addition to growth, we may assume that cells die at rate \\(d\\) and the simple growth Equation 1.2 can be generalised to \\[\n\\frac{dN}{dt} = KN - d N,\n\\] where \\(d\\) is the mortality (death) rate.\n\n\n1.2.1.4 Competition\nConsider a situation in which the per capita death rate increases at higher density. For example, suppose that \\[\nd=d_1 N,\n\\] i.e. the mortality (death) rate is proportional to the population density. This assumption might arise in a situation where individuals compete for food, habitat (i.e. space) or any limited resources. Hence we could obtain the nonlinear ODE \\[\n\\frac{dN}{dt} = KN - d_1 N^2 ,\n\\]\n\n\n\n1.2.2 SIR Model\nConsider a model of infectious disease in which a population is split into three compartments:\n\nsusceptible\ninfected\nrecovered\n\nSuppose that when susceptible and infected individuals interact, the susceptibles become infected. Suppose also that infected people only remain infectious for a limited time.\nLet \\(S(t)\\), \\(I(t)\\) and \\(R(t)\\) represent the population densities of susceptible, infected and recovered populations, respectively.\nConsider the governing ODE\n\\[\n\\begin{aligned}\n\\frac{d S}{ dt} &= -rIS, \\\\\n\\frac{d I}{ dt} &= rIS - aI, \\\\\n\\frac{d R}{ dt} &= aI,\n\\end{aligned}\n\\] where \\(r\\) is the infection rate and \\(a\\) is the recovery rate.\nIn Figure 1.1 you can explore numerical solutions of the SIR model. Can you identify what the maximum value of the parameter \\(r\\) is such that the infected population size never exceeds some critical value (blue dashed line)?\n\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| components: [viewer]\n#| viewerHeight: 800\n#| eval: false\n\nfrom shiny import App, Inputs, Outputs, Session, render, ui\nfrom shiny import reactive\n\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.sidebar(\n    ui.input_slider(id=\"r\",label=\"r\",min=0.00001,max=0.001,value=0.001,step=0.00001),\n    ui.input_slider(id=\"S0\",label=\"Initial susceptible pop. (S(0))\",min=1000.0,max=8000.0,value=4000.1,step=5.0),\n    ui.input_slider(id=\"a\",label=\"a\",min=0.01,max=0.2,value=0.05,step=0.001),            \n    ui.input_slider(id=\"I0\",label=\"Initial infectious pop. (I(0)) \",min=0.0,max=17.0,value=17.0,step=0.5),  \n    ui.input_slider(id=\"T\",label=\"Simulation time\",min=0.0,max=70.0,value=40.0,step=0.5),\n    ui.input_slider(id=\"max_inf\",label=\"Max. infectiousness\",min=0.0,max=10000.0,value=2500.0,step=100.5),             \n          \n            ),\n\n        ui.output_plot(\"plot\"),\n    ),\n)\n\ndef server(input, output, session):\n    \n    @render.plot\n    def plot():\n        fig, ax = plt.subplots()\n        #ax.set_ylim([-2, 2])\n        # Filter fata\n        \n        \n        r=float(input.r())\n        S_0=float(input.S0())\n        a=float(input.a())\n        I_0=float(input.I0())\n        T=float(input.T())\n        max_inf=float(input.max_inf())\n\n        R_0=r*S_0/a\n        \n        # Define rhs of LV ODEs\n        def rhs_sir_model(x,t,r,a):\n          rhs=np.zeros_like(x,dtype=float)\n          S=x[0]\n          I=x[1]\n          R=x[2]\n\n          \n\n          dS_dt=-r*I*S\n          dI_dt=r*I*S-a*I\n          dR_dt=a*I\n\n          rhs[0]=dS_dt\n          rhs[1]=dI_dt\n          rhs[2]=dR_dt\n\n          return rhs\n\n        # Define discretised t domain\n        t = np.linspace(0, T, 1000)\n\n        # define initial conditions\n        init_cond=[S_0,I_0,0.0]\n        \n        # Compute numerical solution of ODEs\n        sol1 = odeint(rhs_sir_model, init_cond,t,args=(r,a))\n\n        # Plot results\n        S=sol1[:,0]\n        I=sol1[:,1]\n        R=sol1[:,2]\n        \n        ax.plot(t, S, 'b',t,I,'r',t,R,'k')\n        ax.plot(t,max_inf*np.ones_like(t),'--')\n        ax.legend(['S','I','R','Max. allowed infectiousness'],loc='best')\n        ax.set_xlabel('$t$')\n        ax.set_title('R_0 =' + str(R_0))\n\n        #plt.grid()\n        #plt.show()\n    \napp = App(app_ui, server)\n\n\nFigure 1.1\n\n\n\n\n\n1.2.3 Activator inhibitor kinetics\nConsider a pair of interacting biochemical species, A and B. Suppose that both A and B are produced at a constant rate and that A undergoes linear degradation. Suppose also that A and B interact such that \\[\n2A+B \\rightarrow 3A.\n\\]\nApplying the law of mass action \\[\n\\begin{aligned}\n\\frac{d a}{ dt} &= k_1 - k_2 a + k_3 a^2 b,  \\\\\n\\frac{d b}{ dt} &= k_4 - k_3 a^2 b,\n\\end{aligned}\n\\]\nwhere \\(k_1\\) and \\(k_4\\) are production rates, \\(k_2\\) is a degradation rate and \\(k_3\\) is the reaction rate for the A and B interaction.\nIn Figure 1.2 you can explore numerical solutions of the model. Can you identify parameters that are consistent with a linearly stable steady state.\n\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| components: [viewer]\n#| viewerHeight: 800\n#| eval: false\n\nfrom shiny import App, Inputs, Outputs, Session, render, ui\nfrom shiny import reactive\n\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.sidebar(\n    ui.input_slider(id=\"k_1\",label=\"k_1\",min=0.00001,max=10.0,value=1.1,step=0.1),\n    ui.input_slider(id=\"k_2\",label=\"k_2\",min=0.0,max=10.0,value=3.5,step=0.1),\n    ui.input_slider(id=\"k_3\",label=\"k_3\",min=0.01,max=10.2,value=0.5,step=0.01),            \n    ui.input_slider(id=\"k_4\",label=\"k_4 \",min=0.0,max=17.0,value=4.0,step=0.1),  \n    ui.input_slider(id=\"T\",label=\"Simulation time\",min=0.0,max=70.0,value=40.0,step=0.5),\n                 \n          \n            ),\n\n        ui.output_plot(\"plot\"),\n    ),\n)\n\ndef server(input, output, session):\n    \n    @render.plot\n    def plot():\n        fig, ax = plt.subplots(2,1)\n        #ax.set_ylim([-2, 2])\n        # Filter fata\n        \n        \n        k_1=float(input.k_1())\n        k_2=float(input.k_2())\n        k_3=float(input.k_3())\n        k_4=float(input.k_4())\n        T=float(input.T())\n\n        \n        # Define rhs of LV ODEs\n        def rhs_ai_model(x,t,k_1,k_2,k_3,k_4):\n          rhs=np.zeros_like(x,dtype=float)\n          \n          a=x[0]\n          b=x[1]\n\n          \n\n          da_dt=k_1-k_2*a-k_3*a*a*b\n          db_dt=k_4-k_3*a*a*b\n\n          rhs[0]=da_dt\n          rhs[1]=db_dt\n\n          return rhs\n\n        # Define discretised t domain\n        t = np.linspace(0, T, 1000)\n\n        a_0=3.0\n        b_0=2.0\n        # define initial conditions\n        init_cond=[a_0,b_0]\n        \n        # Compute numerical solution of ODEs\n        sol1 = odeint(rhs_ai_model, init_cond,t,args=(k_1,k_2,k_3,k_4))\n\n        # Plot results\n        a=sol1[:,0]\n        b=sol1[:,1]\n        \n        ax[0].plot(t, a, 'b',t,b,'r')\n        \n        ax[0].legend(['a','b'],loc='best')\n        ax[0].set_xlabel('$t$')\n        ax[0].set_title('Time series')\n\n        ax[1].plot( a,b,'r')\n        ax[1].set_xlabel('$a$')\n        ax[1].set_ylabel('$b$')\n\n\n        a_vec=np.linspace(0,np.max(a),1000)\n        ncline_a=(k_1-k_2*a_vec)/(k_3*a_vec*a_vec)\n        ncline_b=k_4/(k_3*a_vec*a_vec)\n        ax[1].plot(a_vec,ncline_a,'--',a_vec,ncline_b,'--')\n        ax[1].set_ylim([0,np.max(b)])\n        ax[1].set_title('Phase plane')\n\n        #plt.grid()\n        #plt.show()\n    \napp = App(app_ui, server)\n\n\nFigure 1.2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conservation equations</span>"
    ]
  },
  {
    "objectID": "conservationequations.html#spatial-movement",
    "href": "conservationequations.html#spatial-movement",
    "title": "1  Conservation equations",
    "section": "1.3 Spatial movement",
    "text": "1.3 Spatial movement\nConsider a spatial domain \\(V\\). A conservation equation can be written either in terms of the mass or number of particles of a species as follows:\n\\[\n\\begin{pmatrix}\n\\text{rate of change of}\\\\\n\\text{number of particles} \\\\\n\\text{per unit time }\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{rate of entry of}\\\\\n\\text{particles into $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n- \\begin{pmatrix}\n\\text{rate of exit of }\\\\\n\\text{particles from $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{rate of degradation}\\\\\n\\text{or creation of particles }\\\\\n  \\text{in $V$ per unit time}\n\\end{pmatrix}\n\\]\n\n1.3.1 One-dimensional conservation equations\nAssume\n\nmotion takes place in a one-dimensional domain (e.g. a long very thin tube)\nthe tube has a constant cross-section area\n\nLet \\(x\\) be the distance along the tube relative to an origin. We shall consider the interval \\((x+\\Delta x, t)\\), for some \\(\\Delta x &gt;0\\), and a domain \\(V= (x, x+ \\Delta x) \\times S\\), where \\(S\\) is the cross-section of the tube with the constant area \\(A=|S|\\).\n\n\\(c(x,t)\\) - concentration of particles (number of particles per unit volume) at time, \\(t\\), and position, \\(x\\)\n\\(J(x,t)\\) - flux of particles per unit time and unit area (number of particles crossing a unit area in the positive \\(x\\)-direction per unit time)\n\\(f(x,t ,c(x,t))\\) - source/sink (number of particles created or destroyed per unit volume and unit time)\n\nWe consider \\(S\\) to be very small and \\(c(x,t)\\) is assumed to be constant in \\(S\\) (independent of \\(y\\) and \\(z\\)). We also assume that \\(c\\) is continuously differentiable with respect to \\(t\\).\nThe volume of \\(V\\) is \\(A \\Delta x\\) and number of particles in the volume is given by \\[\n\\int_x^{x+\\Delta x} c(\\tilde x, t) \\,  d \\tilde x A.\n\\]\nThen a conservation equation for the number of particles in the volume \\(V\\) is given by \\[\n\\frac{\\partial}{\\partial t} \\int_x^{x+\\Delta x} c(\\tilde x, t) A d\\tilde x = J(x,t) \\, A  - J(x+\\Delta x,t) \\, A +\\int_x^{x + \\Delta x}  f(\\tilde x, t, c(\\tilde x, t))\\,  A \\, d \\tilde x.\n\\tag{1.7}\\]\ni.e. the flux that changes the total population in \\(V\\) is that entering through the cross-section at \\(x\\) and leaving through the cross-section at \\(x+\\Delta x\\) (it is assumed that there no flux through the external surface of the tube). Assuming \\(c\\) and \\(f\\) to be sufficiently smooth (continuous in \\(x\\)) and applying The Mean Value Theorem in Equation 1.7, we obtain \\[\n\\frac{\\partial}{\\partial t} c(\\xi, t) A \\Delta x = J(x,t) \\, A  - J(x+\\Delta x,t) \\, A +  f(\\eta,t,c(\\eta, t))\\,  A \\Delta x, \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.8}\\]\nDividing Equation 1.7 by \\(A \\, \\Delta x\\) yields \\[\n\\frac{\\partial}{\\partial t} c(\\xi, t)  = - \\frac  {J(x+\\Delta x,t ) - J(x,t)} { \\Delta x} + f(\\eta,t,c(\\eta, t)), \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.9}\\] Assuming that \\(J\\) is differentiable with respect to \\(x\\) and taking the limit as \\(\\Delta x \\to 0\\) (and using the definition of partial derivatives) we obtain a one-dimensional conservation (balance) equation: \\[\n\\frac{\\partial}{\\partial t} c(x,t)  = - \\frac  {\\partial} { \\partial x} J(x,t) + f(x,t ,c(x,t)).\n\\tag{1.10}\\]\n\n\n1.3.2 Conservation equations in \\(\\mathbb R^n\\)\nLet \\(V \\subset \\mathbb R^n\\) be an arbitrary bounded domain (i.e. satisfying the conditions of the divergence theorem) and let \\(S\\) be the surface enclosing \\(V\\), i.e \\(S = \\partial V\\).\n\n\\(c(x,t)\\) – concentration of particles at \\(x\\in V\\) and \\(t&gt;0\\) (number of particles per unit volume)\n\\(J(x,t)\\) – flux vector of particles across \\(V\\) (number of particles per unit area and per unit time entering or leaving through \\(S\\) (the boundary of \\(V\\)).\n\\(f(x,t ,c(x,t))\\) - source/sink term (number of particles created or destroyed per unit volume and per unit time)\n\nThen the conservation equation reads \\[\n\\frac{\\partial}{\\partial t} \\int_V c(x,t) \\, dx = - \\int_{S} J(x,t) \\cdot {\\mathbf{n}} \\, d\\sigma + \\int_V f(x,t ,c)dx,\n\\] where \\(\\mathbf{n}\\) is the outward normal vector to \\(S\\). The normal component of the flux \\(J\\) on \\(S\\) leads to a change of number of particles (of mass) in \\(V\\). Applying the divergence theorem, i.e. \\[\n\\int_S J \\cdot {\\mathbf{n}} \\, d\\sigma = \\int_V \\text{ div} J \\, dx,\n\\] and using the fact that \\(V\\) is independent of time \\(t\\) we obtain \\[\n\\int_V \\Big(\\frac{\\partial}{\\partial t} c(x,t) + \\nabla \\cdot  J(x,t) -  f(x,t ,c)\\Big) dx.\n\\] Since \\(V\\) can be chosen arbitrary we get the conservation equation in \\(\\mathbb R^n\\) (or a subdomain \\(\\Omega \\subset \\mathbb R^n\\))\n\\[\n\\frac{\\partial}{\\partial t} c(x,t) =  - \\nabla \\cdot  J(x,t)+  f(x,t ,c), \\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0.\n\\tag{1.11}\\]\n\n\n1.3.3 Types of flux terms\n\nFickian Diffusion\nDiffusion is an important and ‘’metabolically cheap’’ transport mechanism in biological systems. It can be also viewed as the random motion of individual molecules.\n\\[\n{\\mathbf{J}} = - D\\nabla c,\n\\tag{1.12}\\] where \\(D\\) is the diffusion coefficient. \\(D\\) depends on the size of the particles, the type of solvent, the temperature, .\nThen applying Equation 1.12 in Equation 1.11 we obtain reaction-diffusion equation \\[\n\\frac{\\partial}{\\partial t} c =  - \\nabla\\cdot ( - D \\nabla c(x,t))+  f(x,t ,c) = \\nabla \\cdot ( D \\nabla c) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n, \\,  \\, t &gt;0.\n\\tag{1.13}\\]\nIf \\(D\\) is a constant we can write \\[\n\\frac{\\partial}{\\partial t} c(x,t) =  D \\Delta c(x,t) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0,\n\\]\nwhere \\[\n\\Delta c = \\sum\\limits_{j=1}^n \\dfrac{\\partial^2 c}{\\partial x_j^2}.\n\\]\nNonlinear diffusion \\[\nD = D(c) , \\qquad \\text{ e.g. }\\,   D(c)= D_0 c^m, \\quad D_0 &gt;0,\n\\] and \\[\n  \\frac{\\partial}{\\partial t} c = D_0 \\nabla\\cdot (c^m \\nabla c) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n,  \\quad t &gt;0.\n\\tag{1.14}\\]\nConvection or advection \\[\nJ = \\textbf{v} c,\n\\] where \\(\\textbf{v}\\) is a velocity vector. Hence \\[\n\\frac{\\partial}{\\partial t} c(x,t) = - \\nabla\\cdot (\\textbf{v}(x,t) c(x,t))  + f(x,t ,c),\n\\quad x\\in \\mathbb R^n,   \\quad t &gt;0.\n\\tag{1.15}\\]\nIf \\(\\textbf{v}\\) is constant or \\(\\nabla \\cdot \\textbf{v} = 0\\), then \\[\n\\frac{\\partial}{\\partial t} c = - \\textbf{v} \\nabla c  + f(x,t ,c)\n\\quad x\\in \\mathbb R^n, \\,  \\quad t &gt;0.\n\\]\nTaxis - directed movement in response to an external chemical or physical signal.\n\nchemotaxis - movement directed by a chemical gradient\nhaptotaxis - movement directed by a gradient in density, adhesion\n\nIn the presence of some chemoattractant \\(a(x,t)\\) we have \\[\n  {\\mathbf{J}} = \\chi(a) c \\nabla a,  \n  \\] where \\(\\chi(a)\\) is a `model-specific’ function of \\(a\\) defining the sensitivity to the signal, and the conservation equation reads \\[\n  \\frac{\\partial}{\\partial t} c(x,t) = -\\nabla \\cdot (\\chi(a) c(x,t) \\nabla a )  + f(x,t ,c),\n  \\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n   \\tag{1.16}\\]\n\n\n\n1.3.4 Boundary conditions (B.C.)\n\nInfinite domain (e.g. \\((-\\infty, \\infty)\\), \\(\\mathbb R^2\\), \\(\\mathbb R^3\\) ):\n\nthe density is not influenced by the boundary \\[\nc(x,t) \\to 0 \\qquad \\text{ as } \\qquad \\|x\\| \\to \\infty \\quad  \\text{decay at infinity}\n\\]\n\nPeriodic B.C.\n\n\\(L\\)-periodic function: \\(c(x,t) = c(x,t +L)\\) for any \\(x\\) in the domain\nConsider a domain \\((0,L)\\). \\[\nc(t,0) = c(t,L) \\qquad  \\text{ periodic boundary conditions}\n\\]\n\nDirichlet B.C.\n\ndensity (concentration) is fixed at the boundary\nIn the \\(1\\)-dim domain \\((0,L)\\) \\[\nc(t,0) = c_1, \\quad  c(t,L) = c_2\n\\] can consider two reservoirs placed at the ends of the domain, that are held at constant densities (concentrations) \\(c_1\\) and \\(c_2\\), respectively.\nFor a domain \\(\\Omega\\subset \\mathbb R^n\\) we have \\[\nc(x,t) = c_D(x,t) \\qquad  x\\in  \\partial \\Omega, \\, \\, t\\geq 0 \\; .\n\\]\n\nNo-flux (homogeneous Neumann) B.C.\n\nparticles cannot escape from the domain\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c  \\cdot {\\mathbf{n}}  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] In one-dimensional domain \\((0,L)\\) \\[\n\\frac{\\partial c(x,t)}{\\partial x} = 0 \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Neumann B.C.\n\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c \\cdot {\\mathbf{n}} = g(x,t)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with a given function \\(g\\) ( \\(g\\) can also be a constant).\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x} = g(x,t)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nHomogeneous Robin B.C. \\[\nD\\nabla c(x,t)  \\cdot {\\mathbf{n}}  + k c(x,t)  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x}  + k c(x,t) = 0  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Robin B.C. \\[\nD\\nabla c(x,t)  \\cdot {\\mathbf{n}}  + k c(x,t)  = g(x,t)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\) and given function \\(g\\) ( \\(g\\) can also be a constant).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x}  + k c(x,t) = g(x,t)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\nRemark We can also have different types of boundary conditions at different parts of the boundary of the considered domain.\n\n\n1.3.5 Initial conditions\nFor a conservation equation defined in a domain \\(\\Omega \\subset \\mathbb R^n\\), \\(n=1,2,3\\), additionally to boundary conditions we need to define an initial concentration, i.e. initial condition \\[\nc(0,x) = c_0(x) , \\qquad x \\in \\Omega  \\; .\n\\]\n\n\n1.3.6 Formulating a model\nThe models that we will consider will comprise one or more partial differential equations together with boundary and initial conditions. The right-hand side of the PDEs will be derived based upon assumptions about a particular biological system under study. We will consider exploratory numerical solutions and then study qualitative behaviours of the solutions using analyses familiar from MA32009 (e.g. steady state analysis, linear stability analysis).\nWe can have any combination of fluxes, depending on the biological system. For example, chemotaxis and diffusion\n\\[\n\\frac{\\partial}{\\partial t} c = D \\Delta c -\\nabla \\cdot (\\chi(a) c \\nabla a )  + f(x,t ,c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0,\n\\tag{1.17}\\] which can be augmented by an equation for the (diffusible) chemoattractant \\(a\\) \\[\n\\frac{\\partial}{\\partial t} a = D \\nabla^2 a + g(x,t ,a, c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n\\tag{1.18}\\] Equation 1.17 and Equation 1.18 form a system of equations, a so-called chemotaxis system.\n\n\n\n\n\n\nChecklist\n\n\n\nDepending on the problem under study, you will have to define and justify your use of the following:\n\nIndependent variables\nDependent variables\nDomain of definition\nReaction kinetics\nFluxes\nInitial conditions\nBoundary conditions\n\n\n\n\n\n1.3.7 Nondimensionalization\nThe variables and parameters in a biological or physical model have units:\n\n\\(\\#\\textrm{velocity} = \\dfrac{\\#\\text{length }}{\\#\\text{time}}\\)\n\\(\\# \\textrm{concentration} = \\dfrac{ \\text{num.moles}}{\\#\\text{volume}}\\)\n\\(\\#\\text{density} = \\dfrac{\\text{number of particles}}{\\# \\text{volume}}\\)\n\\(\\#\\text{diffusion coefficient} = \\dfrac{\\#\\text{length}^2}{\\#\\text{time}}\\)\n\\(\\#\\text{source/sink (reaction term)} = \\dfrac{\\#\\text{concentration (or density)}}{\\#\\text{time}}\\)\n\\(\\#\\text{flux} = \\dfrac{\\text{mass (number) of particles}}{\\#\\text{area} \\times \\# \\text{time}}\\)\n\nIt is standard to non-dimensionalise a system of differential equations by scaling or non-dimensionalising both the dependent and independent variables in the model.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conservation equations</span>"
    ]
  },
  {
    "objectID": "linearreactiondiffusion.html",
    "href": "linearreactiondiffusion.html",
    "title": "2  Linear reaction diffusion equations",
    "section": "",
    "text": "2.1 One-dimensional diffusion equations\nIn order to provide some insight into the structure of solutions of reaction-diffusion equations, we make an initial simplifying assumption i.e. we assume \\(f(c)=0\\), and obtain the linear diffusion equation (or heat equation):\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2},   \\quad x\\in \\mathbb R, \\, \\, t &gt;0.\n\\tag{2.2}\\] This equation is used to model the evolution of the concentration of a chemical in a long thin tube, or the temperature of a long thin rod.\nWe assume that the solution is initialised to be non-zero at one point \\(x=0\\), i.e. \\[\nc(x_0 , 0) = \\delta_0(x)\\qquad x \\in \\mathbb R,\n\\tag{2.3}\\] where \\(\\delta_0\\) is a Dirac delta distribution (Dirac measure) satisfying \\[\n\\int_{-\\infty}^{+\\infty} \\delta_0(x) = 1 \\quad \\text{ and } \\quad \\int_{-\\infty}^{+\\infty} f(x) \\delta_0(x) = f(0) , \\text{ for continuous } f.\n\\]",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "href": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "",
    "text": "2.1.1 Fundamental solution\nIt can be shown that the sequence of functions \\(\\{ \\phi_\\varepsilon(x) \\}\\) given by \\[\n\\frac 1{\\varepsilon \\sqrt{\\pi} } e^{ - \\frac{x^2}{ \\varepsilon^2}}\n\\]\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# define domain size\nL=0.2\n\n# discretise domain\nN_x=10000\nx=np.linspace(0,L,N_x)-L/2\ndx=L/(N_x-1)\n\n\n\nepsilon_0=0.1\nepsilon_1=0.01\nepsilon_2=0.005\n\n# Define initial data\nu_0=1/(epsilon_0*np.sqrt(np.pi))*np.exp(-x**2/epsilon_0**2)\nu_1=1/(epsilon_1*np.sqrt(np.pi))*np.exp(-x**2/epsilon_1**2)\nu_2=1/(epsilon_2*np.sqrt(np.pi))*np.exp(-x**2/epsilon_2**2)\n\n\nfig, ax=plt.subplots()\nax.plot(x,u_0,x,u_1,x,u_2)\nplt.legend(['$\\epsilon=$'+str(epsilon_0),'$\\epsilon=$'+str(epsilon_1),'$\\epsilon=$'+str(epsilon_2)])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.1: Approximation of Dirac delta function.\n\n\n\n\n\nconverges to \\(\\delta_0(x)\\) as \\(\\varepsilon \\to 0\\) (in the sense of distributions or generalized functions).\nThen for the diffusion Equation 2.2 with initial condition Equation 2.3, it can be shown that the explicit (analytic) solution is given by \\[\nc(x, t) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ x^2}{ 4Dt} \\right).\n\\tag{2.4}\\]\nThis is known as the fundamental solution of the diffusion equation in \\(\\mathbb R\\).\nWe also have, for general initial condition \\(c(x, 0) = c_0(x)\\) for \\(x\\in \\mathbb R\\): \\[\nc(x, t) = \\int_{-\\infty}^{+\\infty} \\frac{c_0(y)}{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ (x-y)^2}{ 4Dt} \\right) dy.\n\\]\nThis result can be generalized to \\(\\mathbb R^n\\times (0,\\infty)\\) where the fundamental solution has the form \\[\nc(x,t) =  \\frac 1{(4 \\pi D t)^{n/2}} \\exp \\left( - \\frac{ (x_{1}^{2} + x_{2}^{2} + \\ldots + x_{n}^{2})}{ 4Dt} \\right).\n\\]\n\n\n2.1.2 Numerical solution\nIn Figure 2.3 we compute a numerical solution of the diffusion equation and compare it with the exact solution given by Equation 2.4.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# define domain size\nT=10\nL=10\n\n# discretise domain\nN_x=100\nN_t=120\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n# Define model parameters\nD=1.5\nepsilon=0.1\n\n\n# Define initial data\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\n# define rhs of PDE\ndef diffusionPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n\n    # Interior points on the domain\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n    \n    # Boundary at x=0 - flux is zero\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    \n    # Boundary at x=L - flux is zero\n    i=N_x-1\n    f[i]=D/dx**2*(u[i-1]-u[i])\n    return f  \n\n# Use method of lines to solve PDE\nsol=odeint(diffusionPDErhs,u_0,t)\n\n# Generate x and t mesh to compute exact solution\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\n# Plot solutions and compare\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.ylabel('$c$')\n\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.ylabel('$c$')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.2: Numerical solution of diffusion equation.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.3: Exact solution of diffusion equation.\n\n\n\n\n\n\n\n2.1.3 Key properties of the (linear) diffusion equation (heat equation)\n\nThe solution is infinitely smooth.\nThe solution \\(c(x,t)\\) stays positive for all \\(t &gt;0\\) and \\(x \\in \\mathbb R\\) if \\(c(x,0) &gt;0\\) for \\(x \\in \\mathbb R\\).\nThe solution propagates with infinite speed i.e. for any \\(t &gt; 0\\), the solution is everywhere in \\(\\mathbb R\\).\nIf we change the initial data \\(c(x,0)\\) (continuously) then the solution also changes (continuously).\n\n\n\n2.1.4 Diffusive transit time\nWe now demonstrate the connection between time and space in diffusion equations. Consider particles of concentration \\(c(x,t)\\) diffusing with constant diffusion, \\(D\\), in a one-dimensional domain \\((0,L)\\). Suppose that there is a constant concentration at one boundary and removed by a sink at the other boundary. At steady-state, the equation governing the concentration is given by:\n\\[\nD \\frac{ d^2 c}{dx^2} = 0  \\quad \\text{ in } (0,L), \\quad c(0) = C_0, \\, c(L) = 0 .\n\\]\nThe solution (Exercise) is: \\[\nc(x) = C_0 \\left( 1- \\frac x L\\right).\n\\] Then the number of particles entering at \\(x=0\\) due to diffusive flux (Fickian diffusion) is: \\[\nJ = - D \\frac{ dc}{ dx} = D \\frac{ C_0}{L},  \n\\]\nIn the middle of the domain the particle concentration is \\[\nc(\\frac{L}{2})=\\frac{C_0}{2}.\n\\]\nA typical particle speed is approximated by \\[\n\\frac{J}{c} = \\frac{D \\frac{ C_0}{L}}{\\frac{C_0}{2}} = \\frac{2D}{L}\n\\]\nTravelling at this speed, the average time it takes a particle to travel a distance, \\(L\\), is \\[\n\\tau = \\frac{\\textrm{distance}}{\\textrm{speed}}=\\dfrac{L^2}{2D.}\n\\] Hence the typical distance through which diffusion transports a particle in a time \\(\\tau\\) is \\(L= \\sqrt{ 2D\\tau}\\).\n\n\n2.1.5 Diffusion as the limit of a random walk\nConsider a random walk of particles in a one-dimensional domain. Let \\(\\lambda_L\\) and \\(\\lambda_R\\) represent hopping rates, such that the probability of a particle hopping distance \\(\\Delta x\\) to the right in time \\(\\Delta t\\) is \\[\n\\lambda_R \\Delta t.\n\\] Similarly, the probability of hopping a distance \\(\\Delta x\\) to the left is \\[\n\\lambda_L \\Delta t.\n\\]\nIn Figure 2.4 results from a simulation of 400 random walkers is presented. Each particle is initialised at the origin and can move one step left or right with equal probability at every time step of the simulation. As time evolves the particle density (histogram) disperses. The normalised particle density appears to be well described by the solution of the diffusion equation (see solid lines, Equation 2.4).\n\n\nCode\n# This code simulates random walk of a large number of particles and compares distribution in space with a solution of the diffusion equation \n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\n\n# Define total num particles\nN_particles=400\n\n# Discretise domain\nL=50\nN_x=200\n\nT=500\nN_t=25000\ndt=T/N_t\nx=np.linspace(0,L,N_x)-L/2\nt=np.linspace(dt,T,N_t)\n# Model parameters\nD=0.1\n\n# Relate diffusion coefficient to probability of moving distance dx in time dt\nmove_probability=D*dt/dx**2\n\n# Initialise particle positions at the origin\nparticle_positions=np.zeros((N_t,N_particles),dtype=float)\n\n# loop over time\nfor i in range(1,N_t):\n  # loop over particles\n  for j in range(N_particles):\n\n    # randomly sample uniform random number on U_[0,1]\n    r=random.random()\n    # move particle j right\n    new_particle_position=particle_positions[i-1,j]\n    if r&lt;move_probability:\n      new_particle_position+=dx\n    # move particle j left  \n    elif r&lt;2*move_probability:\n      new_particle_position-=dx\n    particle_positions[i,j]=new_particle_position\n\n\n# Compute exaxct solution of diffusion equation\n[x_mesh,t_mesh]=np.meshgrid(x,t)\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\n# Compare normalised histogram of particule positions with PDE solution\nfig,ax=plt.subplots(2,2)\nax[0,0].hist(particle_positions[5,:],density=True)\nax[0,0].plot(x, c_exact[5,:], 'r')\nax[0,0].set_title('$t=$'+str(t[4]))\n\nax[0,1].hist(particle_positions[500,:],density=True)\nax[0,1].plot(x, c_exact[500,:], 'm')\nax[0,1].set_title('$t=$'+str(t[500]))\n\nax[1,0].hist(particle_positions[1000,:],density=True)\nax[1,0].plot(x, c_exact[1000,:], 'b')\nax[1,0].set_title('$t=$'+str(t[1000]))\n\nax[1,1].hist(particle_positions[1500,:],density=True)\nax[1,1].plot(x, c_exact[1500,:], 'k')\nax[1,1].set_title('$t=$'+str(t[1500]))\n\nax[0,0].set_xlim([-L/2,L/2])\nax[0,1].set_xlim([-L/2,L/2])\nax[1,0].set_xlim([-L/2,L/2])\nax[1,1].set_xlim([-L/2,L/2])\n\nax[0,0].set_xlabel('$x$')\nax[0,1].set_xlabel('$x$')\nax[1,0].set_xlabel('$x$')\nax[1,1].set_xlabel('$x$')\n\nax[0,0].set_ylabel('$c$')\nax[0,1].set_ylabel('$c$')\nax[1,0].set_ylabel('$c$')\nax[1,1].set_ylabel('$c$')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.4: Numerical implementation of random walk\n\n\n\n\n\nLet \\(c(x,t)\\) represent the particle density at spatial location \\(x\\) and time \\(t\\).\nA conservation equation for \\(c\\) is given by \\[\nc(x, t+ \\Delta t) = c(x, t)  + \\lambda_R \\Delta t c(x- \\Delta x, t) - \\lambda_R \\Delta t c(x, t) + \\lambda_L \\Delta t c(x+ \\Delta x, t) - \\lambda_L \\Delta t c (x,t).\n\\]\nApplying a Taylor series expansion about \\((x,t)\\) implies\n\\[\nc(x,t) + \\frac{ \\partial c}{\\partial t} \\Delta t + \\frac{1}{2}  \\frac{ \\partial^2 c}{\\partial t^2} (\\Delta t )^2  + h.o.t. =\n\\lambda_R \\Delta t \\Big( c(x,t) - \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial x^2} (\\Delta x )^2  + h.o.t. \\Big)\\\\ +\n\\lambda_L \\Delta t \\Big( c(x,t) + \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial x ^2} (\\Delta x )^2  + h.o.t. \\Big).\n\\]\nUpon cancellation\n\\[\n\\frac{ \\partial c}{\\partial t} \\Delta t + \\frac 12  \\frac{ \\partial^2 c}{\\partial t^2} (\\Delta t )^2  + h.o.t. =\n  \\frac{ \\partial c}{\\partial x} \\Delta x\\Delta t (\\lambda_L-\\lambda_R) + \\frac 12 \\Delta t (\\lambda_L+\\lambda_R)  \\frac{ \\partial^2 c}{\\partial x ^2} (\\Delta x )^2  + h.o.t.\n\\]\nDividing by \\(\\Delta t\\) gives\n\\[\n\\frac{ \\partial c}{\\partial t}  + \\frac 12  \\frac{ \\partial^2 c}{\\partial t^2 } \\Delta t   + h.o.t. =\n   \\frac{ \\partial c}{\\partial x} \\Delta x (\\lambda_L-\\lambda_R) + \\frac 12  (\\lambda_L+\\lambda_R)  \\frac{ \\partial^2 c}{\\partial x^2} (\\Delta x )^2  + h.o.t.  \n\\]\nConsidering the symmetric case where the probability of hopping left and right are equal, i.e. \n\\[\n\\lambda=\\lambda_L=\\lambda_R\n\\]\nyields \\[\n\\frac{ \\partial c}{\\partial t}  + \\frac 12  \\frac{ \\partial^2 c}{\\partial t^2} \\Delta t   + h.o.t. =\n    \\lambda \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t.  \n\\]\nConsidering the limit \\(\\Delta t \\to 0\\) and \\(\\Delta x \\to 0\\) such that\n\\[\nD=\\lambda (\\Delta x )^2\n\\] is finite yields the (one-dimensional) diffusion equation\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}.\n\\]\nNote that \\(D\\) has appropriate units (length\\(^2\\)/time) and that the probability of a particle hopping a distance \\(\\Delta x\\) in time \\(\\Delta t\\) is \\[\n\\lambda \\Delta t = \\frac{D\\Delta t}{\\Delta x^2}.\n\\]\nThis approach can be extended to consider other types of movement e.g. convection. For example, biasing hopping such that \\[\n\\lambda_L - \\lambda_R = \\varepsilon,\n\\] yields a reaction-diffusion-convection equation (see tutorial).\nFinally we note that there is a connection between diffusion and the normal distribution function.\nRecall The normal distribution function in one-dimension with zero mean and variance \\(\\sigma^2\\) is given by\n\\[\nN(0, \\sigma^2) \\sim \\frac 1 { \\sqrt{ 2 \\pi \\sigma^2}} \\exp \\left( - \\frac{x^2}{ 2 \\sigma^2}\\right).\n\\] Examining the formula for the fundamental solution of the diffusion Equation 2.4 in one-dimension, we see by inspection that the probability density function of the position of a particle performing a random walk in one-dimension starting at the origin is normally distributed with mean zero and variance \\[\n\\sigma^2 = 2 D t.\n\\]",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "href": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "2.2 Linear reaction-diffusion equations",
    "text": "2.2 Linear reaction-diffusion equations\nConsider now the linear reaction term: \\(f(c) = \\rho c\\), so that Equation 2.1 takes the form \\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}   + \\rho \\, c, \\quad x\\in \\mathbb R, \\, \\, t &gt;0,\n\\tag{2.5}\\] where \\(\\rho \\in \\mathbb R\\) is a constant.\nOnce again we consider the initial condition to be concentrated at the origin: \\[\nc(0,x) = \\delta_0(x).\n\\tag{2.6}\\]\n\n2.2.1 Exact solution\nBy considering a separation of variables approach, i.e. making the ansatz \\[\nc(x,t) = w(t) \\tilde c(x,t),\n\\] it can be shown (Exercise) that the explicit solution for the linear reaction-diffusion Equation 2.5 with initial condition Equation 2.6 is given by\n\\[\nc(x,t) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left(\\rho t - \\frac{x^2}{ 4Dt} \\right).\n\\]\nIn Figure 2.6 we compare numerical and exact solutions of Equation 2.5.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=10\nL=10\n\nN_x=100\nN_t=120\n\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\n\nD=0.5\nrho=1.0\nepsilon=0.1\n\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n\n\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    i=N_x-1\n\n    f[i]=D/dx**2*(u[i-1]-u[i])\n\n    reac=rho*u\n    f=f+reac\n    return f  \n\nsol=odeint(logisticPDErhs,u_0,t)\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(rho*t_mesh-x_mesh**2/(4*D*t_mesh))\n\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nax.set_xlabel('$x$')\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nax.set_xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.5: Numerical solution of linear reaction diffusion equation\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.6: Exact solution of linear reaction diffusion equation\n\n\n\n\n\n\n\n2.2.2 Speed of a wave of invasion\nMuskrats, which were introduced in 1905 in Bohemia, initially spread rapidly throughout Europe through a combination of random movement and proliferation (initially there were no predators and proliferation was rapid). A model for the initial spread can therefore be given by a two-dimensional diffusion equation combined with exponential growth and assuming that \\(M\\) individuals were released at the origin (i.e. in Bohemia). Letting \\(u({\\mathbf{x}} , t)\\), represent the density of muskrats, the evolution equation is\n\\[\n\\frac{\\partial u}{\\partial t} = D \\left(\\frac{\\partial^2 u}{\\partial x_1^2} +  \\frac{\\partial^2 u}{\\partial x_2^2}\\right)  + \\rho \\, u, \\quad {\\mathbf{x}} = (x_1 , x_2) \\in \\mathbb R^2, \\, \\, t &gt;0,\n\\tag{2.7}\\]\nwith initial condition \\[\nu({\\mathbf{x}}, 0) = M \\delta_0({\\mathbf{x}}), \\quad {\\mathbf{x}} \\in \\mathbb R^2.\n\\tag{2.8}\\]\nIt can be shown that the solution of Equation 2.7 with initial conditions given by Equation 2.8 is:\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ |{\\mathbf{x}} |^2}{ 4Dt} \\right)\\; = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ (x_{1}^{2} + x_{2}^{2})}{4Dt} \\right).\n\\]\nTransforming to polar coordinates \\(x_1 = r \\cos\\varphi\\), \\(x_2 = r \\sin \\varphi\\) we obtain\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r^2}{ 4Dt} \\right).\n\\]\nFrom the properties of the fundamental solution, the wave of invasion extends all the way to infinity for any \\(t&gt;0\\). For practical purposes, we have to define the front of the wave.\nConsider that there is some detection threshold for the muskrats i.e. some predetermined small value of the density \\(u_1\\), say, such that any changes in density for \\(u &lt;u_1\\) cannot be detected.\nBecause of the symmetry of the problem, then the leading edge of the invading wave front of muskrats is the circle of radius \\(r=r_1(t)\\) where \\(u=u_1\\), i.e. from the explicit solution of Equation 2.7\n\\[\nu_1({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r_1^2}{ 4Dt} \\right).\n\\]\nRearranging and solving for \\(r_1\\), using the fact that \\[\n\\lim\\limits_{t\\to \\infty} \\dfrac {\\ln t} t =0,\n\\]\nwe obtain for large \\(t\\) that\n\\[\nr_1(t) \\approx 2 \\sqrt{ \\rho D} t.\n\\]\nHence, the speed of invasion of the leading edge of the muskrats is given by: \\[\nv = \\frac{r_1(t)}{t} =  2 \\sqrt{ \\rho D}.\n\\]",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Linear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "nonlinearreactiondiffusion.html",
    "href": "nonlinearreactiondiffusion.html",
    "title": "3  Travelling waves in nonlinear reaction diffusion equations",
    "section": "",
    "text": "3.1 Fisher’s equation\nWe now consider the one-dimensional diffusion equation with a non-linear reaction term of “logistic growth”, to give the nonlinear reaction-diffusion equation:\n\\[\n\\frac{\\partial u}{\\partial t} = D\\frac{\\partial^2 u}{\\partial x^2} +   \\rho u\\left(1-\\frac u K\\right), \\qquad x\\in \\mathbb R, \\, \\, t &gt;0,  \n\\tag{3.1}\\]\nwith initial Condition \\[\nu(x,0) =u_0(x).\n\\]\nThis is known as the Fisher equation, and was introduced by Fisher in \\(1937\\) (“The Wave of Advance of Advantageous Genes” (1937)).\nWe can non-dimensionalise Equation 3.1 by considering the scaling \\[t^\\ast = \\rho t, \\quad  x^\\ast = \\sqrt{\\dfrac \\rho D} x, \\quad  u^\\ast = \\displaystyle{\\frac u K}.\n\\] Dropping the asteriks we obtain the non-dimensionalised Fisher equation (Exercise):\n\\[\n\\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2} +   u(1-u), \\qquad x\\in \\mathbb R, \\, \\, t &gt;0\n\\] with initial condition \\[\nu(x,0) = u_0(x).\n\\tag{3.2}\\]",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Travelling waves in nonlinear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#fishers-equation",
    "href": "nonlinearreactiondiffusion.html#fishers-equation",
    "title": "3  Travelling waves in nonlinear reaction diffusion equations",
    "section": "",
    "text": "3.1.1 Numerical solutions\nIn Figure 3.1 we have computed a numerical solution to Equation 3.2 together with no-flux boundary conditions. See Python code for further details. The key point to note is that the numerical solutions appear to be a travelling wave, at successive times the solution is translated along the \\(x\\) axis. At long times the solution tends to \\(u\\sim1\\) (behind the wavefront). Ahead of the front, the solution is \\(u\\sim0\\).\nThe numerical results motivate the following questions:\n\nCan we prove the existence of a travelling wave (e.g. the numerical solution could have a profile that varies on a very slow time scale)?\nHow does the travelling depend on initial data?\nHow does the wave speed relate to model parameters?\nHow do the boundary conditions affect the wave propagation?\n\n\n\nCode\n#  This code computes a numerical solution to Fishers equation\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# Define domain and discretise\nT=100\nL=100\nN_x=100\nN_t=100\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n# Initial condition\nu_0=0.5*(1+np.tanh(-0.1*(x-20)))\n\n# encode rhs of Fishers equation\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1])+u[i]*(1-u[i])  \n\n\n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1])+u[i]*(1-u[i]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])+u[i]*(1-u[i]) \n    return f  \n\n# Solve system of ODEs representing discretised PDE\nsol=odeint(logisticPDErhs,u_0,t)\n\n# Plot results\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[4,:], 'b')\nplt.plot(x, sol[8,:], 'm')\nplt.plot(x, sol[12,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.1: Numerical solution of Fisher’s equation.\n\n\n\n\n\n\n\n3.1.2 Spatially homogeneous solutions\nConsider first the spatially uniform (homogeneous) solution of Equation 3.2\n\\[\n\\frac{\\partial u}{\\partial t} =    u(1-u), \\qquad   \\, \\, t &gt;0.\n\\tag{3.3}\\]\nSteady states of Equation 3.3 are \\[\nu=u_1 =1\n\\] and \\[\nu=u_2 =0.\n\\] To analyse the stability we consider \\[\nf(u)=u(1-u) \\quad \\textrm{and} \\quad \\frac{ df}{du}(u)= 1 - 2u.\n\\] Then \\[\n\\frac{ df}{du}(u_1)= -1 \\quad \\textrm{and} \\quad \\frac{ df}{du}(u_2)= 1.\n\\] Thus \\(u_1=1\\) is stable and \\(u_2=0\\) is unstable.\nThis stability analysis suggests that for the spatially dependent situation we can have a travelling wave solution that connects the two steady states \\(u_1\\) and \\(u_2\\) i.e. a travelling front.\n\n\n3.1.3 Travelling wave solutions\nConsider the travelling wave ansatz\n\\[\nu(x,t)= W(z) = W(x-vt),\n\\] where \\(v\\) is a positive constant. Changing variables in Equation 3.2 and using \\[\n\\begin{aligned}\n\\frac{ \\partial u}{\\partial t} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial t} = - v   \\frac{ dW}{dz}, \\\\\n\\frac{ \\partial u}{\\partial x} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial x} =\\frac{ dW}{dz}, \\\\\n\\frac{ \\partial^2 u}{\\partial x^2} &= \\frac{ d^2W}{dz^2} \\left(\\frac{\\partial z}{\\partial x} \\right)^2 +  \\frac{ dW}{dz} \\frac{\\partial^2 z}{\\partial x^2} =\\frac{ d^2W}{dz^2},\n\\end{aligned}\n\\]\nwe obtain a second order ordinary differential equation for \\(W\\)\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + W(1-W)  = 0.\n\\tag{3.4}\\]\nBoundary conditions are chosen that represent solutions to the spatially homogeneous problem, i.e. \\[\nW(z) \\to 1 \\quad \\text{ as } \\quad z \\to  - \\infty, \\quad\nW(z) \\to 0 \\quad \\text{ as } \\quad z \\to  +\\infty,\n\\tag{3.5}\\] and \\[\nW(z) \\in [0,1].\n\\tag{3.6}\\]\nWe can rewrite Equation 3.4 as a system of two first order ODEs\n\\[\n\\begin{aligned}\n\\frac{ dW}{dz}& = P  = F(W,P), \\\\\n\\frac{ d P}{dz}&= -  v P - W(1-W)  = G(W,P).  \n\\end{aligned}\n\\tag{3.7}\\]\n\n3.1.3.1 Numerical solutions\nIn Figure 3.2 we plot the numerical solution to equations Equation 3.7 for different values of the wave speed, \\(v\\). Note that when the wave speed is too small the solution spirals in towards the origin. This solution cannot be valid as it implies that \\(u&lt;0\\) for some \\(z\\).\n\n\n\n\n\n\nWhat if a travelling wave solution does not exist?\n\n\n\nNote that some problems will not have a travelling wave solution. In this situation we might still make the travelling wave ansatz but this would usually result in a contradiction.\n\n\n\n\nCode\n# This code uses a shooting method to compute solutions of the travellign wave ODEs at different values of the wave speed\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n# Discretise domain\nN_z=5000\nz=np.linspace(1,T,N_z)\n\n# Initial condition\nu_0=[0.99,-0.0001]\n\n# Different values of wavespeed\nv_1=2.0\nv_2=8.6\nv_3=0.5\n\n# rhs of travelling wave ODEs\ndef fisherTrWaveODErhs(u, t, v):\n    f=np.zeros_like(u)\n    reaction=u[0]*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-v*u[1]-reaction\n    return f  \n\n# Compute numerical solution of travelling wave ODEs\nsol=odeint(fisherTrWaveODErhs,u_0,z, args=(v_1,))\nsol2=odeint(fisherTrWaveODErhs,u_0,z, args=(v_2,))\nsol3=odeint(fisherTrWaveODErhs,u_0,z, args=(v_3,))\n\n# PLot results\nfig, ax = plt.subplots(1,2)\nax[0].plot(sol[:,0],sol[:,1], 'r')\nax[0].plot(sol2[:,0],sol2[:,1], 'b')\nax[0].plot(sol3[:,0],sol3[:,1], 'k')\nax[0].set_xlim([-0.5, 1.05])\nax[0].set_xlabel('$u$')\nax[0].set_ylabel('$dW/dz$')\n\nax[1].plot(z,sol[:,0], 'r')\nax[1].plot(z,sol2[:,0], 'b')\nax[1].plot(z,sol3[:,0], 'k')\nax[1].set_xlim([-0.5, 100])\n\nax[1].set_xlabel('$z$')\nax[1].set_ylabel('$W$')\nplt.legend(['v='+str(v_1),'v='+str(v_2), 'v='+str(v_3)])\nplt.grid()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.2: Numerical solution of Equation 3.7 with different values of wavespeed,\\(v\\).\n\n\n\n\n\n\n\n3.1.3.2 Steady state and linear stability analysis\nThe steady states of Equation 3.7 are \\((W_1, P_1) = (0,0)\\) and \\((W_2, P_2) = (1,0)\\).\nThe Jacobian matrix for Equation 3.7 is given by: \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n-1 + 2W & \\, - v\n\\end{pmatrix}.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) the eigenvalues of \\(J(0,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(0,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- 1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_1 = \\frac 12 ( - v \\pm \\sqrt{ v^2 - 4})\n\\] and we have for \\(v&gt;0\\) that \\({R} e(\\lambda_1^\\pm) &lt;0\\).\nTherefore at \\((0, 0)\\) we have a \\[\n\\begin{cases}\n\\text{ stable node if }\\,   v^2 \\geq 4, \\\\\n\\text{ stable focus if } \\,  v^2 \\leq 4 \\quad (\\text{ complex eigenvalues})\n\\end{cases}\n\\tag{3.8}\\]\nThe eigenvectors are defined by \\[\n- \\lambda W + P = 0.\n\\] Thus at \\((W_1, P_1)=(0,0)\\) we have \\[\n\\Phi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^- W\n\\end{pmatrix}, \\quad  \\Phi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_1^- \\leq \\lambda_1^+ &lt;0 \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\]\nAt \\((W_2, P_2)=(1,0)\\) the eigenvalues of \\(J(1,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(1,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1 \\\\\n1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda - 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_2 = \\frac 12 ( - v \\pm \\sqrt{ v^2 + 4})\n\\] and we have for \\(v&gt;0\\) that \\(\\lambda_2^{-} &lt;0 &lt; \\lambda_2^+\\). Therefore \\((1,0)\\) is a saddle.\nAt \\((W_2, P_2)=(1,0)\\) we have \\[\n\\Psi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^- W\n\\end{pmatrix}, \\quad  \\Psi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_2^- &lt;0 &lt; \\lambda_2^+  \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\] The eigenvectors are sketched in Figure 3.3.\n\n\n\n\n\n\nFigure 3.3: Schematic diagram of eigenvectors.\n\n\n\nWe seek a travelling wave solution that is represented by a trajectory that connects the unstable manifold of the saddle with the stable manifold at the origin.\n\nDefinition 3.1 The trajectory that connects two different points is called a heteroclinic connection. The trajectory that connects a point with itself is called a homoclinic connection.\n\n\n\n3.1.3.3 Minimal wave speed\nIt can be shown that for \\(v&lt;2\\) a heteroclinic connection between \\((0,0)\\) and \\((1,0)\\) exists, but in this situation the steady state \\((0,0)\\) is a stable focus and corresponds to an oscillatory front (see numerical solution in Figure 3.2)\nIn the context of a model of a biological process \\(W\\) is the profile of a population density and \\(W\\geq 0\\). Hence, for \\(v&lt;2\\) trajectories connecting \\((0,0)\\) and \\((1,0)\\) are not biologically realistic.\nTo avoid negative solutions we impose the condition that the origin cannot be a spiral. Considering Equation 3.8 we obtain the nondimensional minimal speed \\[\nv^\\ast_\\text{min}=2\n\\] for which we have a travelling wave front solution for Fisher’s equation.\nIn the original dimensional variables we have: \\[\nz^\\ast= x^\\ast - v^\\ast t^\\ast = x \\sqrt{ \\frac \\rho D} - v^\\ast t \\rho , \\quad\n\\sqrt{ \\frac D \\rho } z^\\ast= x  - \\sqrt{D \\rho}  \\, v^\\ast\\,  t.\n\\] Thus for \\(z = x - vt\\) we have \\[\nv=  v^\\ast \\sqrt{D \\rho},\n\\] and \\[\nv_{\\text{min}}=  v^\\ast_{\\text{min}} \\sqrt{D \\rho} = 2  \\sqrt{D \\rho}.\n\\]\n\n\n3.1.3.4 The existence of a travelling wave solution\nTo show the existence of a travelling wave we will construct a confined region or confined set in \\(\\mathbb{R}^2\\), which contains both steady states such that, once inside this region solution trajectories cannot escape from it (also known as an invariant region or invariant set). If we can then show that there are no other steady states in the confined region and that the solution is not oscillatory, the only valid solution must be a heteroclinic trajectory that connects the unstable manifold (eigenvector) of one steady state with the stable manifold of another.\nConsider \\[\nT= \\{ (W,P) : \\, 0 \\leq W \\leq 1,\\, \\, P \\leq 0, \\, \\,  P \\geq \\mu W \\}\n\\] for some \\(\\mu &lt;0\\).\nConsider normal vectors at each boundary of \\(T\\): \\[\n\\text{ at } P = 0 \\, : \\, \\, n_1 = \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix}, \\quad\n\\text{ at } W= 1 \\, : \\, \\, n_2 = \\begin{pmatrix}\n-1\\\\ 0\n\\end{pmatrix}, \\quad\n\\text{ at } P = \\mu W \\, : \\, \\, n_3 = \\begin{pmatrix}\n-\\mu \\\\1\n\\end{pmatrix}.\n\\] Consider the scalar product between normal vectors and the flow vector \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\ \\\\  \\dfrac{dP}{dz}\n\\end{pmatrix},\n\\] of Equation 3.7.\nAt \\(P=0\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_1 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix} =  \\left(v P + W(1-W)\\right) \\Big|_{P=0} =  W(1-W) \\geq 0 , \\text{ for } W\\in [0,1].\n\\]\nAt \\(W=1\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_2 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-1 \\\\ 0\n\\end{pmatrix} =  -P  \\geq 0 , \\text{ since }P \\leq 0.\n\\]\nAt \\(P=\\mu W\\) \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 &= \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-\\mu \\\\ 1\n\\end{pmatrix} \\\\\n& =\\left(  - \\mu  P - vP -  W(1-W)\\right) \\Big|_{P=\\mu W}  \\\\\n&=   - \\mu^2 W - \\mu v W - W(1-W) = - W( \\mu^2 + \\mu v + 1) + W^2.\n\\end{aligned}\n\\] Thus\n\\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0,\n\\] if \\[\n\\mu^2 + \\mu v + 1 \\leq 0.\n\\] The last inequality is satisfied if we have real roots of the equation \\(\\mu^2 + \\mu v + 1 = 0\\). We have that\n\\[\n\\mu_{1,2} = \\frac{ - v \\pm \\sqrt{ v^2 -4}} 2\n\\]\nare real if \\(v^2 \\geq 4\\).\nThus, since \\(v &gt;0\\), for \\(v \\geq 2\\) and any \\[\n\\mu\\in \\left[ \\dfrac{ - v -\\sqrt{ v^2 -4}} 2, \\dfrac{ - v +\\sqrt{ v^2 -4}} 2 \\right]\n\\] we have \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0 \\qquad \\text{ at } \\quad P=\\mu W.\n\\]\nTherefore we have shown that at the boundaries of \\(T\\) the flow vector points in to the region \\(T\\) and any trajectory approaching the boundaries from inside of \\(T\\) will return to \\(T\\) without crossing any of the boundaries of \\(T\\). Thus we have constructed an invariant (trapping) triangular region containing the steady states \\((0,0)\\) and \\((1,0)\\).\nIf we can show that there no other steady states or periodic solutions of the system Equation 3.7, then a trajectory that leaves \\((1,0)\\) must approach \\((0,0)\\).\n\nTheorem 3.1 Bendixson’s Negative Criterion, Dulac’s Negative Criterion\nIf there exists a function \\(\\varphi(W,P)\\), with \\(\\varphi \\in C^1(\\mathbb R^2)\\), such that \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P},\n\\]\nhas the same sign \\((\\neq 0)\\) almost everywhere in a simply connected region (region without holes), then the system \\[\n\\begin{aligned}\n\\dfrac{ dW}{dz} &= F(W,P) \\; ,\n\\\\   \\dfrac{dP}{dz} &= G(W,P),\n\\end{aligned}\n\\] has no periodic solutions in this region.\n\nWe can apply Theorem 3.1 to our situation taking \\(\\varphi(W,P) = 1\\). Then using Equation 3.7 we have \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P} = - v &lt; 0\\; .\n\\] Thus we have no periodic solutions and also only two steady states \\((0,0)\\) and \\((1,0)\\) in the confined (invariant) simply-connected region \\(T\\). Therefore the trajectory that leaves \\((1,0)\\) will approach \\((0,0)\\).\nWe have therefore shown that for any \\(v\\geq 2\\) there exist a heteroclinic trajectory \\(P(W)\\) connecting \\((0,0)\\) and \\((1,0)\\).\nThus for any wave speed \\(v\\) satisfying \\(v \\geq 2\\), we have the existence of travelling wave front \\(u(x,t)= W(x- vt)\\) of Fisher’s equation Equation 3.2.\n\n\n3.1.3.5 Sign of the wave speed\nConsider Equation 3.4 together with boundary condition \\[\nW(z\\rightarrow -\\infty)=1 \\quad W(z\\rightarrow \\infty)=0.\n\\] Multiply Equation 3.4 by \\(\\dfrac{dW}{dz}\\) and integrate over \\((-\\infty, + \\infty)\\): \\[\n\\int_{-\\infty}^{+ \\infty}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{-\\infty}^{+ \\infty}W(1-W)\\dfrac{dW}{dz} \\, dz =0.\n\\]\nThen \\[\n\\frac 12 \\int_{-\\infty}^{+ \\infty}  \\dfrac{d}{dz} \\left(\\left|\\dfrac{dW}{dz}\\right |^2\\right) \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{W(-\\infty)}^{W(+\\infty)}W(1-W) \\, dW =0.\n\\] and since \\(W(z) \\to 1\\) as \\(z \\to - \\infty\\) and \\(W(z) \\to 0\\) as \\(z \\to + \\infty\\) we obtain\n\\[\n\\frac 12 \\left( \\left|\\dfrac{dW(+\\infty)}{dz}\\right |^2-   \\left|\\dfrac{dW(-\\infty)}{dz}\\right |^2\\right)  + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{1}^{0}W(1-W)\\, dW =0.\n\\] The fact that \\(W\\) is constant at \\(\\pm \\infty\\) implies that \\[\n\\dfrac{dW}{dz}\\Big|_{z=-\\infty} = \\dfrac{dW}{dz}\\Big|_{z=+\\infty}=0.\n\\] Thus we have\n\\[\nv\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  =  \\int\\limits_{0}^{1}W(1-W) dW =\\frac{1}{6}\n\\] and \\[\nv= \\dfrac {\\frac{1}{6}}{\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz}.\n\\]\nThus the wave speed must be positive and the wave therefore travels in the positive direction along the \\(x\\) axis.\nIn contrast, if we were to swap the boundary conditions such that \\[\nW(z\\rightarrow -\\infty)=0 \\quad W(z\\rightarrow \\infty)=1,\n\\] the wavespeed would be negative and the wave would travel in the negative direction along the \\(x\\) axis.\n\n\n3.1.3.6 Initial conditions\nOne final key question is: For which initial conditions \\(u(x,0) = u_0(x)\\) does the solution evolve to a travelling wave solution?\nIf we start with a travelling wave shape initial condition, i.e. \\(u_0(x)= W(z)|_{t=0} = W(x)\\), then this simply propagates as a travelling wave. However if \\(u_0(x)\\neq W(x)\\), then it is not immediately obvious how the solution will evolve. This problem was considered by Kolmogorov et al. Kolmogorov, Petrovsky, and Piskunov (1937), who showed that for any initial data satisfying \\[\nu_0(x) \\geq 0, \\quad \\text{ with} \\quad  u_0(x) = \\begin{cases} 1 \\, \\text{ if } \\, x \\leq x_1, \\\\\n0 \\, \\text{ if } \\, x \\geq x_2,\n\\end{cases}\n\\] where \\(x_1 &lt; x_2\\) and \\(u_0\\) is continuous in \\([x_1, x_2]\\), the solution of Fisher’s Equation 3.2 evolves to a travelling wave with minimal speed \\[\nv_\\text{ min} = 2 \\sqrt{ \\rho D}\n\\] and \\[\nu(t,x) \\rightarrow 1 \\quad \\textrm{as} \\quad x\\rightarrow -\\infty, \\quad u(t,x) \\rightarrow 0 \\quad \\textrm{and} \\quad  x\\rightarrow +\\infty.\n\\]",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Travelling waves in nonlinear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#bistable-equation",
    "href": "nonlinearreactiondiffusion.html#bistable-equation",
    "title": "3  Travelling waves in nonlinear reaction diffusion equations",
    "section": "3.2 Bistable equation",
    "text": "3.2 Bistable equation\nWe now consider a reaction-diffusion equation of the form \\[\n\\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2} +   f(u),\\qquad x\\in \\mathbb R, \\, \\, t &gt;0,  \\\\\n\\tag{3.9}\\] with initial condition \\[\nu(x,0)=u_0(x),  \\qquad x\\in \\mathbb R.\n\\]\nWe impose the condition that \\(f\\) has three roots, such that \\[\nf(0) = f(a) = f(1)= 0, \\quad \\textrm{with} \\quad  0&lt;a&lt;1.\n\\]\nThere are therefore three spatially uniform steady states \\(u_1 =0\\), \\(u_2 =a\\), \\(u_3=1\\).\nWe also impose that \\[\nf^\\prime (0) &lt; 0, \\quad  f^\\prime(a) &gt;0 \\quad \\textrm{and} f^\\prime(1) &lt;0\n\\] Hence the spatially homogeneous steady states \\(u_1=0\\) and \\(u_3=1\\) are stable and \\(u_2 =a\\) is unstable.\nAn example of such a function (Figure 3.4) is\n\\[f=u(u-a)(1-u),\n\\] which arises in the study of nerve action potentials along nerve fibres and other problems in excitable media (Keener and Sneyd (2009)).\n\n\nCode\n# This codes computed and plots a numerical solution of bistable PDE\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n# Model parameters\na=0.2\n\n# Plot the reaction term\nfig, ax = plt.subplots(1)\nu_samp=np.linspace(-0.25,1.25,100)\nreac=u_samp*(u_samp-a)*(1-u_samp)\nax.plot(u_samp,reac) \nax.set_xlabel('$u$')\nax.set_ylabel('$f(u)$')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.4: A plot of f(u) against u. Note location of roots. ”\n\n\n\n\n\n\n3.2.1 Numerical solution\nIn Figure Figure 3.5 we plot a numerical solution of Equation 3.9. Note the emergence of a travelling wave solution.\n\n\nCode\n# This codes computed and plots a numerical solution of bistable PDE\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# Define domain\nT=100\nL=100\nN_x=100\nN_t=100\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n# Model parameters\na=0.2\n\n# Initial conditions\nu_0=6*0.5*(1+np.tanh(-1*(x-50)))*0.5*(1+np.tanh(1*(x-50)))\nu_0=0.5*(1+np.tanh(-1*0.2*(x-50)))\n\n# function encodes the right-hand side omf the disretised PDE\ndef bistablePDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])\n\n    reaction=u*(u-a)*(1-u) \n    f= f+reaction \n    return f  \n\n# Solve the system of ODES representing the disdcretised PDE\nsol=odeint(bistablePDErhs,u_0,t)\n\n# Plot results\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[15,:], 'b')\nplt.plot(x, sol[30,:], 'm')\nplt.plot(x, sol[45,:], 'k')\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.ylabel('$u$')\n\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.5: Travelling waves in a numerical solution of bistable PDE.\n\n\n\n\n\n\n\n3.2.2 Travelling wave ansatz\nIn a similar manner to Section 3.1.3, we look for a travelling wave solution of the form \\(u(x,t) = W(z)\\) with \\(z= x-vt\\), yielding\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + f(W)  = 0,  \\; .\n\\tag{3.10}\\]\nWe can rewrite Equation 3.10 as asystem of two 1st order ODEs \\[\n\\begin{aligned}\n\\frac{ dW}{dz} = P = F(W,P) , \\\\\n\\frac{ d P}{dz}= -  v P - f(W)  = G(W,P),  \n\\end{aligned}\n\\tag{3.11}\\]\n\n3.2.2.1 Linear stability of the steady states\nThe steady states of Equation 3.11 are \\[\n(W_1, P_1) = (0,0),\\quad (W_2, P_2) = (a,0), \\quad (W_3, P_3) = (1,0).\n\\]\nThe Jacobian matrix is given by \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n- f^\\prime(W) & \\, - v\n\\end{pmatrix}\n\\]\nAt steady states \\((W_j, P_j)\\), the eigenvalues of \\(J(W_j,P_j)\\) are solutions of the characteristic polynomial \\[\n\\det(J(W_j,P_j) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- f^\\prime(W_j) & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + f^\\prime(W_j) = 0 .\n\\]\nTherefore:\n\\[\n\\lambda^{\\pm}_j = \\frac{ - v \\pm \\sqrt{ v^2 - 4 f^\\prime(W_j)}}2.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) since \\(f^\\prime(0) &lt;0\\) we obtain \\[\n\\lambda_1^{-} &lt;0&lt;\\lambda_1^{+}.\n\\] Hence (0,0) is a saddle point.\nAt \\((W_2, P_2)=(a,0)\\) since \\(f^\\prime(a) &gt;0\\) we obtain \\[\n(a,0) - \\begin{cases}\n\\text{ focus} \\quad \\text{ if} \\, v^2 &lt; 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n  \\text{ node} \\quad \\text{ if} \\, v^2 \\geq 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n   \\text{centre } \\quad \\text{ if} \\, v=0 \\; . \\\\\n\\end{cases}\n\\]\nAt \\((W_3, P_3)=(1,0)\\) since \\(f^\\prime(1) &lt;0\\) we obtain \\[\n\\lambda_3^{-} &lt;0&lt;\\lambda_3^{+}\n\\] and it is a saddle point.\nEigenvectors are given by \\[\nP =\\lambda W\n\\] and at each steady state we have two eigenvectors \\[\n\\Psi_j^{\\pm} = \\begin{pmatrix}\nW\\\\\n\\lambda_j^\\pm W\n\\end{pmatrix} , \\qquad  j=1,2, 3.\n\\] See Figure 3.6 for a sketch of the phase plane in the cases \\(v&gt;0\\) and \\(v=0\\).\nThe stable and unstable manifolds are dependent on \\(v\\). We wish to show that for some \\(v\\) the unstable manifold leaving one saddle point coincides with the stable manifold entering the other saddle point, i.e. we can choose a value for the wave speed \\(v\\) such that a heteroclinic connection between \\((1,0)\\) and \\((0,0)\\) is obtained. We shall use a “shooting argument” to prove this.\n\n\n\n\n\n\nFigure 3.6: Schematic diagram of eigenvectors.\n\n\n\n\n\n3.2.2.2 Relation between sign of \\(v\\) and sign of \\(\\int\\limits_0^1 f(u) \\, du\\)\nUsing similar arguments to Section 3.1.3.5\n\\[\nv= \\dfrac {\\int\\limits_{0}^{1}f(W) \\, dW}{\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz}.\n\\] Since \\(\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz &gt;0\\) we can conclude that \\[\n\\int_{0}^{1}f(u) \\, du &gt; 0  \\quad  \\Longrightarrow  \\quad v&gt; 0, \\\\\n  \\int_{0}^{1}f(u) \\, du =0 \\quad  \\Longrightarrow  \\quad v=0, \\\\\n   \\int_{0}^{1}f(u) \\, du &lt; 0  \\quad  \\Longrightarrow \\quad v &lt; 0.\n\\]\nThus the direction of travel of the propagating front depends on the parameter \\(a\\).\n\n\n3.2.2.3 Numerical shooting method\nIn Figure 3.7 we plot numerical solutions to equation Equation 3.11. These results suggest that there are potentially different wavefront solutions connecting steady states.\n\n\nCode\n# This code uses a shooting method to compute solutions of the travlling wave problem at different values of the wavespeed\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# Model parameter\na=0.2\n\n# Define and discretise z domain\nN_z=5000\nZ=20\nz=np.linspace(1,Z,N_z)\n\n# Initial condition\nu_0=[0.99,-0.005]\n\n# Different values of wave speed\nv_1=0.38\nv_2=0.48\nv_3=0.68\n\n# compute rhs of the travlling wave ODEs \ndef bistableTrWaveODErhs(u, t, c):\n    f=np.zeros_like(u)\n    reaction=u[0]*(u[0]-a)*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-c*u[1]-reaction\n    return f  \n\n# numerically solve travelling wave ODEs at different values of the wavespeed\nsol=odeint(bistableTrWaveODErhs,u_0,z, args=(v_1,))\nsol2=odeint(bistableTrWaveODErhs,u_0,z, args=(v_2,))\nsol3=odeint(bistableTrWaveODErhs,u_0,z, args=(v_3,))\n\n# Plot results\nfig, ax = plt.subplots(1)\npython_indices1  = [index for index in range(N_z) if sol[index,1]&lt;0]\npython_indices2  = [index for index in range(N_z) if sol2[index,1]&lt;0]\npython_indices3  = [index for index in range(N_z) if sol3[index,1]&lt;0]\n\nplt.plot(sol[python_indices1,0],sol[python_indices1,1], 'r')\nplt.plot(sol2[:,0],sol2[:,1], 'b')\nplt.plot(sol3[:,0],sol3[:,1], 'k')\nax.set_xlim([-0.05, 1.05])\nax.set_ylim([-0.5, 0.5])\nplt.xlabel('$W$')\nplt.ylabel('$P$')\nplt.legend(['v='+str(v_1),'v='+str(v_2), 'v='+str(v_3)])\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.7: Using a shooting method to investigate travelling wave solutions. Continuity arguments suggest that there exists a travelling wave solution with v int he interval [0.38,0.48] such that a heteroclinic trajecotry connects (1,0) and (0,0).\n\n\n\n\n\n\n\n3.2.2.4 The shooting method proof of a heteroclinic connection\nLet’s assume that \\[\n\\int\\limits_{0}^{1}f(u) \\, du &gt; 0.\n\\]\nSuppose that \\(v=0\\). An explicit expression for the trajectory is found by multiplying Equation 3.10 by \\(P\\) and integrating over \\(z\\). Hence \\[\n\\frac{P^2}{2}+ \\int_0^W f(u)du=0.\n\\] If this trajectory reached \\(W=1\\) then \\[\n\\frac{P^2}{2}_{\\bigg|\\infty}+ \\int_0^1 f(u)du=0.\n\\] The boundary condition \\[\n\\frac{P^2}{2}_{\\bigg|\\infty}=0,\n\\] necessary for a travelling wave solution, therefore would imply that \\[\n\\int_0^1 f(u)du=0.\n\\]\nThis contradicts the assumption \\[\n\\int_0^1 f(u)du&gt;0.\n\\tag{3.12}\\]\nMoreover, such a trajectory intersects the \\(W=0\\) axis for some \\(P&lt;0\\). An intersection on the \\(P=0\\) axis would again imply (czerobreakingcond?).\nNow suppose that \\(v\\) is large. The aim in this case is to show that solutions leaving (1,0) must intersect the \\(P=0\\) axis for some \\(W&gt;0\\).\n\nThe stable eigenvector at (0,0) is \\[\nP=\\lambda_- W.\n\\] Note that \\(\\lambda_- &lt;v\\).\nA solution trajectory must satisfy \\[\n\\frac{dP }{dW} = \\frac{-vP-f(W)}{P}= -v-\\frac{f(W)}{P}\n\\]\nConsider the line \\(P=-\\sigma W\\) with \\(\\sigma&gt;0\\). On this line \\[\n\\frac{dP }{dW} = -v+\\frac{1}{\\sigma}(W-a)(1-W) &lt;-v+\\frac{K}{\\sigma}\n\\] for some \\(K\\) that can be identified (exercise).\nHence for large enough \\(v\\) \\(dP/dW\\) can be made arbitrarily negative and the condition \\[\n\\frac{dP}{dW} &lt; -\\sigma\n\\tag{3.13}\\] can be satisfied.\nThis result implies that a trajectory leaving (1,0) with sufficiently large \\(v\\) cannot intersect (0,0). If it did it would have to intersect the line \\(P=\\sigma W\\). This is not possible given Equation 3.13 and that \\(W\\) is decreasing.\n\nHence a trajectory approaching \\((0,0)\\) with sufficiently large \\(v\\) is bounded below by the line \\(P=-\\sigma W\\). Such a trajectory must intersect the \\(P=0\\) axis for some \\(W&gt;0\\).\nFinally, we have shown that * trajectories with \\(v=0\\) intersect the line \\(W=0\\) for \\(P&lt;0\\) * trajectories with large \\(v\\) intersect the line \\(P=0\\) for some \\(W&gt;0\\).\nAs solution trajectories depend continuously on parameters, there must exist some value of \\(v\\) for which a trajectory intersects (0,0). Hence a heteroclinic trajectory exists.\nWe can repeat the analysis for \\[  \n\\int\\limits_{0}^{1}f(u) \\, du &lt; 0\n\\] and obtain a travelling wave solution with \\(v_0 &lt;0\\).\nIf \\[\n\\int\\limits_{0}^{1}f(u) \\, du = 0,\n\\] then we have a standing wave with \\(v=0\\), since the calculations for \\(P_0\\) and \\(P_1\\) implies \\(P_0=P_1\\) and there exists a heteroclinic orbit between \\((1,0)\\) and \\((0,0)\\) in the phase space.\nNote: There exists a unique travelling wave velocity \\(v\\) for which we have a travelling wave solution for bistable Equation 3.9.",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Travelling waves in nonlinear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#references",
    "href": "nonlinearreactiondiffusion.html#references",
    "title": "3  Travelling waves in nonlinear reaction diffusion equations",
    "section": "3.3 References",
    "text": "3.3 References\n\n\n\n\nKeener, JP, and James Sneyd. 2009. “Mathematical Physiology 1: Cellular Physiology.” Springer New York, NY, USA.\n\n\nKolmogorov, AN, IG Petrovsky, and NS Piskunov. 1937. “Investigation of the Equation of Diffusion Combined with Increasing of the Substance and Its Application to a Biology Problem.” Bull. Moscow State Univ. Ser. A: Math. Mech 1 (6): 1–25.\n\n\n“The Wave of Advance of Advantageous Genes.” 1937. Annals of Eugenics 7 (4): 355–69.",
    "crumbs": [
      "Single species",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Travelling waves in nonlinear reaction diffusion equations</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html",
    "href": "LotkaVolteraPDE.html",
    "title": "4  Lotka Voltera model",
    "section": "",
    "text": "4.1 Nondimensionalization\nConsider the scaling \\[\nx^\\ast = x \\sqrt{\\frac \\rho {D_n}}, \\qquad t^\\ast = \\rho t , \\quad u^\\ast = \\frac uK, \\quad n^\\ast = n \\frac \\alpha \\rho.\n\\] Upon dropping the asteriked notation, Equation 4.1 transform to \\[\n\\begin{cases}\n&\\dfrac{\\partial u}{\\partial t} =  u ( 1 - u - n)  + D \\dfrac{\\partial^2 u}{\\partial x^2}\\; = \\; f(u,n) + D\\dfrac{\\partial^2 u}{\\partial x^2}, \\qquad x\\in \\mathbb R , t&gt;0 \\,,  \\\\\n& \\dfrac{\\partial n}{\\partial t} = a\\,  n(u -b) + \\dfrac{\\partial^2  n}{\\partial x^2}\\; =  g(u,n) + \\dfrac{\\partial^2  n}{\\partial x^2},  \\qquad x\\in \\mathbb R, t&gt;0,\n\\end{cases}\n\\tag{4.2}\\] where \\[\nD= \\dfrac{D_u}{D_n}, \\quad a = \\dfrac{\\beta K}\\rho, \\quad   b = \\dfrac \\gamma{ K \\beta}.\n\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html#numerical-solutions",
    "href": "LotkaVolteraPDE.html#numerical-solutions",
    "title": "4  Lotka Voltera model",
    "section": "4.2 Numerical solutions",
    "text": "4.2 Numerical solutions\nIn Figure 4.1 we plot numerical solution of Equation 4.2. No flux boundary conditions are imposed at \\(x=0\\) and \\(x=150\\).\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\n\n# Define domain and discretise\nT=100\nL=150\nN_x=100\nN_t=100\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\n# Define model parameters\na=0.2\nb=0.4\nD_u=0.10\n\nu_L= 1.0\nu_R=b\nn_L=0.0\nn_R=1-b\n\n\n# Define initial conditions\nu_0=b+(1-b)*0.5*(1+np.tanh(-1.0*0.5*(x-50)))\nn_0=(1-b)*0.5*(1+np.tanh(1.0*0.5*(x-50)))\n\nu_0=np.concatenate((u_0,n_0))\n\n\n# Compute rhs of discretised ODEs\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    n=sol[N_x:2*N_x]\n\n\n\n    f_u=np.zeros_like(u)\n    f_n=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=D_u/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f_u[i]=D_u/dx**2*(u_L-2*u[i]+u[i+1])  \n    i=N_x-1\n    f_u[i]=D_u/dx**2*(u_L-2*u[i]+u_R)  \n\n    for i in range(1,N_x-2):\n      f_n[i]=1/dx**2*(n[i-1]-2*n[i]+n[i+1]) \n    i=0\n    f_n[i]=1/dx**2*(n_L-2*n[i]+n[i+1]) \n    i=N_x-1\n    f_n[i]=1/dx**2*(n[i-1]-2*n[i]+n_R) \n\n    reaction_u=u*(1-u-n)\n    reaction_n=a*n*(u-b)\n\n    f_u=f_u+reaction_u\n    f_n=f_n+reaction_n\n\n    f= np.concatenate((f_u, f_n)) \n    return f  \n\n# Solve discretised ODEs\nsol=odeint(LVPDErhs,u_0,t)\n\n\nu=sol[:,0:N_x]\nn=sol[:,N_x:2*N_x]\n\n# Plot solutions\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, n[0,:],'r--')\nax[1].plot(x, n[16,:],'b--')\nax[1].plot(x, n[32,:],'m--')\nax[1].plot(x, n[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$n$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 4.1: Numerical solution of LV model. \\(a\\)=0.2. \\(b\\)=0.4.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "href": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "title": "4  Lotka Voltera model",
    "section": "4.3 Spatially homogeneous steady states",
    "text": "4.3 Spatially homogeneous steady states\nWe firstly consider spatially homogeneous steady states, i.e. \\[\nf(u,n) =0, \\quad g(u,n) = 0.\n\\] Thus \\[\n\\begin{aligned}\n&u(1-u-n) = 0,  \\quad  u =0, \\quad u+n=1,\\\\\n& an(u-b) = 0,  \\quad n =0, \\quad u =b.\n\\end{aligned}\n\\] Thus the steady states are \\[\n(u_1^\\ast, n_1^\\ast)= (0,0), \\quad (u_2^\\ast, n_2^\\ast)= (1,0), \\quad (u_3^\\ast, n_3^\\ast)= (b,1-b), \\, 0\\leq b &lt;1.\n\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html#stability-of-steady-states-to-spatially-homogeneous-perturbations",
    "href": "LotkaVolteraPDE.html#stability-of-steady-states-to-spatially-homogeneous-perturbations",
    "title": "4  Lotka Voltera model",
    "section": "4.4 Stability of steady states to spatially homogeneous perturbations",
    "text": "4.4 Stability of steady states to spatially homogeneous perturbations\nThe Jacobian matrix is \\[\n\\begin{aligned}\nJ(u_j^\\ast, n^\\ast_j) =\n\\begin{pmatrix}\n1-2u -n & -u \\\\\nan &a(u-b)\n\\end{pmatrix}_{(u^\\ast_j, n^\\ast_j)}, \\quad j = 1,2,3.\n\\end{aligned}\n\\]\nAt the steady state \\[\n(u_1^\\ast, n_1^\\ast)= (0,0)\n\\]\nthe characteristic equation is \\[\n\\det(J (0,0) - \\lambda I) = - (1- \\lambda)(\\lambda+ ab) = 0.\n\\]\nThe eigenvalues are \\[\n\\lambda_1^+ = 1, \\quad \\lambda_1^- = - ab &lt;0.\n\\]\nThus \\((0,0)\\) is a saddle point.\nAt the steady state\n\\[\n(u_2^\\ast, n_2^\\ast)= (1,0)\n\\]\nthe characteristic equation is\n\\[\n\\det(J (1,0) - \\lambda I) = - (1+ \\lambda)(a(1-b)- \\lambda) = 0.\n\\]\nThe eigenvalues are\n\\[\n\\lambda_2^- =- 1, \\quad \\lambda_2^+ = a(1-b) &gt;0 \\; \\text{ for } \\; 0 \\leq b &lt;1.\n\\]\nThus \\((1,0)\\) is a saddle point.\nAt the steady state \\[\n(u_3^\\ast, n_3^\\ast)= (b,1-b)\n\\]\nthe characteristic equation is\n\\[\n\\det(J (b,1-b) - \\lambda I) =\\lambda^2 + b \\lambda + ab(1-b) = 0.\n\\]\nIf \\[\n4 ab (1-b) \\leq b^2  \\implies \\lambda_3^{\\pm} &lt; 0,\n\\] (\\(b,1-b\\)) is a stable node.\nIf\n\\[\n4 ab (1-b) &gt; b^2 \\qquad \\implies  \\Re(\\lambda_3{\\pm}) &lt; 0,  \\Im(\\lambda_3^{\\pm}) \\neq 0,\n\\] (\\(b,1-b\\)) is a stable focus (spiral).\nFor \\(b&gt;0\\), \\(1-b&gt;0\\) spiral oscillations are biologically realistic so long \\(u&gt;0\\) and \\(n&gt;0\\).",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "href": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "title": "4  Lotka Voltera model",
    "section": "4.5 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)",
    "text": "4.5 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)\nCondider the travelling wave ansatz \\[\n\\begin{aligned}\nu(t,x) &= W(x+ vt) = W(z), \\quad v&gt;0, \\\\\nn(t,x) &= N( x + vt) = N(z), \\quad v &gt;0.\n\\end{aligned}\n\\]\nWe consider boundary conditions that connect \\((1,0)\\) to \\((b,1-b)\\), i.e. \\[\n\\begin{aligned}\nu(t,x) \\to 1 \\; \\text{ as } x \\to - \\infty,  & \\; \\qquad  W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad\\\\\nu(t,x) \\to b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad   W(z)\\to b \\; \\text{ as } z \\to + \\infty, \\\\\nn(t,x) \\to 0 \\;  \\text{ as } x \\to - \\infty ,  &\\qquad  \\;  N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad \\\\\nn(t,x) \\to 1-b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty.\n\\end{aligned}\n\\]\nEquation 4.2 transforms to \\[\n\\begin{aligned}\nv \\frac{dW}{dz} &= D \\frac{d^2W}{dz^2} + W(1-W-N),\\\\\nv \\frac{dN}{dz} &=  \\frac{d^2N}{dz^2} + a N(W-b),\n\\end{aligned}\n\\]\nwith boundary conditions given by \\[\n\\begin{aligned}\n& W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad W(z)\\to b \\; \\text{ as } z \\to + \\infty, \\\\\n& N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty.\n  \\end{aligned}\n\\tag{4.3}\\]\nUpon making the assumption that the prey moves much more slowly than the predator species, i.e.  \\[\nD= \\frac{D_u}{D_n} \\ll 1,\n\\]\nEquation 4.3 simplify to\n\\[\n\\begin{aligned}\nv \\frac{dW}{dz} &=  W(1-W-N) ,\\\\\nv \\frac{dN}{dz} &=  \\frac{d^2N}{dz^2} + a N(W-b).\n\\end{aligned}\n\\tag{4.4}\\]\nWe can rewrite Equation 4.4 as a system of first order ODEs: \\[\n\\begin{aligned}\n\\frac{dW}{dz} &= \\frac 1 v W(1-W-N) = F(W,N,P),\\\\\n\\frac{dN}{dz} &= P  = G(W, N,P),\\\\\n\\frac{dP}{dz} &= v P - a N(W-b)  = R(W,N,P).\n\\end{aligned}\n\\tag{4.5}\\]\nThe steady states of Equation 4.5 are \\[\n\\begin{aligned}\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) &= (0,0,0),\\\\\n(W^\\ast_2, N^\\ast_2, P^\\ast_2) &= (1,0,0), \\\\\n(W^\\ast_3, N^\\ast_3, P^\\ast_3) &=(b, 1-b, 0).\n\\end{aligned}\n\\]\nThe Jacobian matrix is \\[\nJ(W,N,P) = \\begin{pmatrix}\n\\dfrac 1 v - \\dfrac{2W} v - \\dfrac Nv & - \\dfrac Wv & 0 \\\\\n0 & 0 & 1 \\\\\n- aN & a(b-W) & v\n\\end{pmatrix}.\n\\]\nAt \\[\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) = (0,0,0)\n\\]\nwe have \\[\n\\det(J(0,0,0) - \\lambda I)= \\left( \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v - ab) =0\n\\] and \\[\n\\lambda_1^1= \\frac 1 v &gt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 + 4 ab} } 2.\n\\]\nThus \\((0,0,0)\\) is a saddle point with a \\(2\\)-dim unstable manifold.\nAt \\((W^\\ast_2, N^\\ast_2, P^\\ast_2) = (1,0,0)\\) we have \\[\n\\det(J(1,0,0) - \\lambda I)= \\left(- \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v + a(1-b)) =0,\n\\]\nand \\[\n\\lambda_1^1= -\\frac 1 v &lt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 - 4 a(1-b)} } 2.\n\\]\nSince \\[\n0\\leq b &lt; 1 \\quad \\textrm{and} \\quad 4(1-b)&gt;0,\n\\]\n\nIf \\(v^2 \\geq  4 a(1-b)\\), (1,0,0) is a saddle with 2-dim unstable manifold.\nIf \\(v^2 &lt;  4 a(1-b)\\) (1,0,0)is an unstable focus\n\nThus for a travelling wave with \\(W\\geq 0\\) and \\(N \\geq 0\\) to exist we require \\[\nv^2 \\geq  4 a(1-b)\n\\]\nand obtain a minimal wave speed \\[\nv_\\text{min}=2\\sqrt{a(1-b)}   \\quad \\text{ with } \\quad  0\\leq b&lt;1.\n\\]\nAt \\[\n(W^\\ast_3, N^\\ast_3, P^\\ast_3) =(b, 1-b, 0)\n\\] we have \\[\n\\det(J(b,1-b,0) - \\lambda I)= \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b) = p(\\lambda) =0.\n\\]\nIt can be shown that the extrema of \\(p(\\lambda)\\) are independent of the parameter \\(a\\).\nTo identify extrema, we compute \\[\np^\\prime(\\lambda) = 3 \\lambda^2 - 2 \\lambda \\left( v - \\frac b v\\right) - b = 0\n\\]\nand find that \\[\n\\lambda_{m,M}= \\frac 13 \\left[ \\left(v - \\frac bv \\right) \\pm \\sqrt{ \\left(v - \\frac bv\\right) ^2 + 3 b } \\right].\n\\]\nIf \\(a=0\\), the eigenvalues are \\[\n\\lambda_3^1 = 0, \\quad \\lambda_3^\\pm = \\frac 12 \\left( v - \\frac bv \\pm \\sqrt{\\left(v - \\frac bv\\right)^2 + 4 b} \\right).\n\\]\nThus there exists a critical value \\(a^\\ast&gt;0\\) such that for \\(a \\in (0, a^\\ast)\\), we obtain two real negative eigenvalues and one positive real eigenvalue. Hence \\((b, 1-b, 0)\\) is a saddle with \\(2\\)-dim stable manifold and \\(1\\)-dim unstable manifold\nFor \\(a&gt;a^\\ast\\), we obtain a pair of complex conjugate eigenvalues with negative real part and one real positive eigenvalue corresponding to \\(1\\)-dim unstable manifold.\nThis can be easily seen from a sketch of the cubic equation:\n\\[\np(\\lambda) = \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b).\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# discretise lambda\nlam=np.linspace(-1.2,1.2,100)\n\n# Define parameters\na=0.0\na2=0.05\na3=0.2\nb=0.2\nv=0.5\n\n# Compute polynomials\np1= lam**3-lam**2*(v-b/v)-lam*b-1/v*a*b*(1-b)\np2= lam**3-lam**2*(v-b/v)-lam*b-1/v*a2*b*(1-b)\np3= lam**3-lam**2*(v-b/v)-lam*b-1/v*a3*b*(1-b)\n\n# plot\nfig, ax= plt.subplots()\nax.plot(lam,p1,lam,p2,lam,p3)\nax.set_xlabel('$\\lambda$')\nax.set_ylabel('$p(\\lambda$)')\n\nax.grid(True)\n\n\n\n\n\n\n\n\nFigure 4.2: Plot of cubic.\n\n\n\n\n\nThus we have a possible heteroclinic connection between \\((1,0,0)\\) and \\((b, 1-b, 0)\\), i.e. between \\(2\\)-dim unstable manifold at \\((1,0,0)\\) and \\(2\\)-dim stable manifold at \\((b, 1-b, 0)\\), and therefore an existence of a travelling wave front solution for Equation 4.2 with\n\\[\n\\begin{aligned}\nu(x,t) \\to 1 \\; \\textrm{ as } x \\to - \\infty,  \\quad & u(x,t) \\to b \\; \\textrm{ as } x \\to +\\infty,  \\\\\nn(x,t) \\to 0 \\;  \\textrm{ as } x \\to - \\infty ,  \\quad & n(x,t) \\to 1-b \\; \\textrm{ as } x \\to +\\infty.\n\\end{aligned}\n\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "LotkaVolteraPDE.html#exercise",
    "href": "LotkaVolteraPDE.html#exercise",
    "title": "4  Lotka Voltera model",
    "section": "4.6 Exercise",
    "text": "4.6 Exercise\nUse Python code to numerically investigate dependence of travelling wave solution on the parameter \\(a\\).",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lotka Voltera model</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html",
    "href": "BacterialChemotaxis.html",
    "title": "5  Aggregation via chemotaxis",
    "section": "",
    "text": "5.1 Model derivation\nWe consider a model for Dicty aggregation through the secretion of and chemotactic response to cAMP. We denote by \\(n({\\mathbf{x}}, t)\\) the density of amoebae and \\(a({\\mathbf{x}}, t)\\) the concentration of cAMP. The general conservation equation for the amoebae can be written:\n\\[\n\\frac{\\partial n}{\\partial  t} + \\nabla \\cdot {\\mathbf{J}} = f(n,a),\n\\] where \\(f(n,a)\\) models any reaction terms for the amoebae e.g. proliferation, and the flux is given by \\[\n{\\mathbf{J}} = {\\mathbf{J}}_{diffusion} + {\\mathbf{J}}_{chemotaxis}.\n\\]\nAssuming Fickian diffusion and the general chemotactic flux stated earlier (Section 1.1), the general reaction-diffusion-chemotaxis model for the amoebae responding to cAMP is given by:\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  \\underbrace{D_n \\nabla^2 n}_{diffusion} - \\underbrace{\\nabla \\cdot \\left( \\chi(a) n \\nabla a \\right)}_{chemotaxis} + f(n,a),   \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a + g(n,a),\n\\end{aligned}\n\\]\nwhere we have assumed Fickian diffusion for the cAMP and \\(g(a,n)\\) represents the kinetics i.e. source/sink terms, of cAMP.\nOne simple model has the following assumptions:\n\\[f(n,a) = 0, \\;\\;\\; g(n,a) = \\mu n - \\delta a, \\;\\;\\; \\chi (a) = \\chi_0\\]\ni.e.\nUnder such assumptions we obtain the model equation\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} & =  D_n \\nabla^2 n - \\chi_0 \\nabla \\cdot \\left( n \\nabla a \\right), \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a +  \\mu n - \\delta a,\n\\end{aligned}\n\\]\nwhich becomes, upon considering a 1-dimensional domain \\([0,L]\\),\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  D_n \\frac{\\partial ^2 n}{\\partial x^2} - \\chi_0 \\frac{\\partial}{\\partial x} \\left( n \\frac{\\partial a}{\\partial x} \\right), \\\\\n  & & \\hspace{4.5cm} \\\\\n\\frac{\\partial a}{\\partial  t} &=  D_a \\frac{\\partial ^2 a}{\\partial x^2}  +  \\mu n - \\delta a,\n\\end{aligned}\n\\tag{5.1}\\]\nwith zero flux boundary conditions:\n\\[\n\\begin{aligned}\nD_a \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L, \\\\\nD_n \\frac{\\partial n}{\\partial  x} - \\chi_0 n \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L.\n\\end{aligned}\n\\]\nThese reduce to:\n\\[\n\\frac{\\partial a}{\\partial  x} = \\frac{\\partial n}{\\partial  x} = 0, \\;\\;\\; x = 0,L.\n\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#model-derivation",
    "href": "BacterialChemotaxis.html#model-derivation",
    "title": "5  Aggregation via chemotaxis",
    "section": "",
    "text": "there are no kinetics for the amoebae - they simply move randomly via diffusion and undergo chemotaxis in response to cAMP;\nproliferation is neglected; - this is a reasonable assumption given the timescales involved, since they amoebae move on a faster timescale than they proliferate;\nthe amoebae are assumed to produce cAMP in proportion to their density, which means the more amoebae there are, the more cAMP (a reasonable first approximation);\nthe chemotactic function is taken to be a constant, again a reasonable first approximation;\n\\(D_a &gt; D_n\\) since chemicals diffuse faster than cells move randomly.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#numerical-solutions",
    "href": "BacterialChemotaxis.html#numerical-solutions",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.2 Numerical solutions",
    "text": "5.2 Numerical solutions\nIn Figure 5.2 we plot numerical solution of Equation 5.1 together with no-flux boundary condition. The initial data are uniformly sampled. Note the emergence of periodic spatial structure in both variables. These correspond to peaks and troughs of cell density. The cells produce chemoattractant, \\(a\\), and the this induces a chemtactic flux up the gradient in \\(a\\). Hence more cells move towards regions where \\(a\\) is high, more chemoattractant is produced in this region etc.\n\nWhat is the long-time behaviour of these solutions\nFor which parameters do we expect to see pattern formation?\nHow does spatial pattern depend on the initial data?\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\n\n# Define domain and discretise\nT=80\nL=150\nN_x=200\nN_t=100\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\n# Define model parameters\nmu=1.2\ndelta=0.1\nD_n=2.50\nD_a=2.5\nchi_0=1.4\n\n\n# Define initial conditions\nu_0=np.ones_like(x)+0.01*np.random.uniform(low=0.0, high=0.1, size=(N_x,))\nn_0=np.ones_like(x)\nu_0=np.concatenate((u_0,n_0))\n\n\n# Function to compute rhs of discretised PDEs\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    n=sol[0:N_x]\n    a=sol[N_x:2*N_x]\n\n\n    # arrays to store rhs for the two dep variables\n    f_n=np.zeros_like(n)\n    f_a=np.zeros_like(n)\n\n    for i in range(1,N_x-2):\n      f_n[i]=D_n/dx**2*(n[i-1]-2*n[i]+n[i+1]) - chi_0*n[i]*1/dx**2*(a[i-1]-2*a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i-1])*(n[i+1]-n[i-1])\n\n    # No flux BC\n    i=0\n    f_n[i]=D_n/dx**2*(-n[i]+n[i+1]) - chi_0*n[i]*1/(2*dx)**2*(-a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i])*(n[i+1]-n[i])\n    # No flux BC\n\n    i=N_x-1\n    f_n[i]=D_n/dx**2*(n[i-1]-n[i])- chi_0*n[i]*1/(2*dx)**2*(a[i-1]-a[i])-chi_0/(2*dx)**2*(a[i]-a[i-1])*(n[i]-n[i-1])\n\n\n    for i in range(1,N_x-2):\n      f_a[i]=D_a/dx**2*(a[i-1]-2*a[i]+a[i+1]) \n    \n    # No flux BC\n    i=0\n    f_a[i]=D_a/dx**2*(-a[i]+a[i+1]) \n    # No flux BC\n    i=N_x-1\n    f_a[i]=D_a/dx**2*(a[i-1]-a[i])\n\n    reaction_n=0\n    reaction_a=mu*n-delta*a\n\n    f_n=f_n+reaction_n\n    f_a=f_a+reaction_a\n\n    f= np.concatenate((f_n, f_a)) \n    return f  \n\n\n# Integrate discretised ODEs\nsol=odeint(LVPDErhs,u_0,t)\n\nn=sol[:,0:N_x]\na=sol[:,0:N_x]\n\n# Plot solutions\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,n[0,:],'r')\nax[0].plot(x,n[16,:],'b')\nax[0].plot(x,n[32,:],'m')\nax[0].plot(x,n[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$n$')\n\nax[1].plot(x, a[0,:],'r--')\nax[1].plot(x, a[16,:],'b--')\nax[1].plot(x, a[32,:],'m--')\nax[1].plot(x, a[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$a$')\n\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5.2: Numerical solution of bacterial chemtaxis model.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#conservation-of-cell-number",
    "href": "BacterialChemotaxis.html#conservation-of-cell-number",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.3 Conservation of cell number",
    "text": "5.3 Conservation of cell number\nDefine the total number of cells, \\(N\\), \\[\nN= \\int_0^L n(x,t)dx\n\\] Upon differentiation with respect to time \\[\n\\begin{aligned}\n\\frac{dN}{dt} &=\\int_0^L \\frac{\\partial n(x,t)}{\\partial t}dx\n&=\\int_0^L  D_n \\frac{\\partial ^2 n}{\\partial x^2} - \\chi_0 \\frac{\\partial}{\\partial x} \\left( n \\frac{\\partial a}{\\partial x} \\right) dx.\n\\end{aligned}\n\\] Upon integration of the right-hand side w.r.t. \\(x\\), subsequent application of the no-flux boundary condition implies \\[\n\\frac{dN}{dt}=0.\n\\] Hence the total number of cells in the domain is fixed by the initial data.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#spatially-homogeneous-steady-state",
    "href": "BacterialChemotaxis.html#spatially-homogeneous-steady-state",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.4 Spatially homogeneous steady state",
    "text": "5.4 Spatially homogeneous steady state\nSuppose that \\((n^*,a^*)\\) is a spatially homogeneous, steady state solution, i.e. \\[\n\\frac{\\partial n}{\\partial x}=\\frac{\\partial n}{\\partial t}=\\frac{\\partial a}{\\partial x}=\\frac{\\partial a}{\\partial t}=0.\n\\]\nHence\n\\[\n\\mu n* - \\delta a*=0,\n\\]\nand therefore\n\\[\na*=\\frac{\\mu}{\\delta }n*.\n\\]\nGiven initial cell number, \\(N\\), and domain size, \\(L\\), conservation of cell number implies that \\[\nn^*=N/L\n\\]\nThus the steady state is \\[\n(n^*,a^*)=\\frac{N}{L}\\left(1,\\frac{\\mu}{\\delta}\\right).\n\\]\nIf this spatially homogeneous steady state is unstable, this will indicate that aggregation patterns may arise in the system.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#stability-analysis",
    "href": "BacterialChemotaxis.html#stability-analysis",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.5 Stability Analysis",
    "text": "5.5 Stability Analysis\nIn a similar manner to previous stability analyses, we consider small perturbations around the spatially homogeneous steady state \\((n^* , a^* )\\), i.e.\n\\[\nn(x,t) = n^* + \\tilde{n}(x,t), \\;\\;\\; a(x,t) = a^* + \\tilde{a}(x,t)\n\\]\nwhere \\(\\tilde{n}(x,t)\\) and \\(\\tilde{a}(x,t)\\) are “small” so that higher order terms can be neglected.\nNOTE Unlike previous stability analysis, these perturbations are both time and space dependent.\nSubstituting the above perturbations into Equation 5.1, we neglect higher order terms and retain only linear terms. This is largely straightforward, but we provide some detail for the linearisation of the chemotactic term i.e.\n\\[\n\\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial}{\\partial x} \\left( a^* + \\tilde{a} \\right) \\right] = \\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial \\tilde{a}}{\\partial x}  \\right] \\approx n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}.\n\\]\nThe fully linearised system is then given by: \\[\n\\begin{aligned}\n\\frac{\\partial \\tilde{n}}{\\partial  t} & =  D_n \\frac{\\partial ^2 \\tilde{n}}{\\partial x^2} - \\chi_0 n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2} \\\\\n\\frac{\\partial \\tilde{a}}{\\partial  t} & =   D_a \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}  +  \\mu \\tilde{n} - \\delta \\tilde{a}.\n\\end{aligned}\n\\tag{5.2}\\]\nAlthough the above equations are linear, an explicit solution is non-trivial and we are required to make a further “separation of variables” ansatz. We seek solutions of the form \\[\n\\tilde{n}(t,x) = u(t) \\phi_1(x)\n\\] and \\[\n\\tilde a (t,x) = v(t) \\phi_2(x)\n\\]\nUpon substitution \\[\n\\begin{aligned}\n&\\frac{d u}{d  t}  \\phi_1  =   D_n  u\\frac{d ^2 \\phi_1}{d x^2} - \\chi_0 n^*  v\\frac{d ^2 \\phi_2}{d x^2} \\\\\n& \\frac{d v}{d  t}  \\phi_2=     D_a v \\frac{d ^2  \\phi_2}{d x^2}  +  \\mu u \\,  \\phi_1 - \\delta v\\,  \\phi_2, \\\\\n\\end{aligned}\n\\] with boundary conditions \\[\n\\begin{aligned}\n& u \\frac{d \\phi_1}{d x} = 0, \\quad   v \\frac{d \\phi_2}{d x} = 0 \\quad \\text{ for } \\; x = 0, \\; x=L.\n\\end{aligned}\n\\]\n\n\n\n\n\n\nElliptic problem\n\n\n\nSuppose that \\(\\phi\\) is the solution of the elliptic problem \\[\n\\begin{aligned}\n\\frac{d^2 \\phi}{dx^2} &= - k^2 \\phi && \\text{ in } \\; (0,L), \\\\\n\\frac{d \\phi}{dx} &= 0  && \\text{ for } \\; x=0, \\; x=L.\n\\end{aligned}\n\\] We can compute that solution of the equation for \\(\\phi\\) are of the form \\[\n\\phi(x) = A \\cos(kx) + B\\sin(kx).\n\\] Since \\(\\phi\\) satisfied zero Neumann boundary conditions we have that \\[\n\\phi(x) = A \\cos(kx),\n\\] where \\(A\\) is an arbitrary constant, and \\[\nk = \\dfrac {m \\pi} L, \\quad m \\in \\mathbb N.\n\\]\n\n\nWe seek solutions \\[\n\\phi_1 = \\phi_2 = \\phi.\n\\]\nThen we have \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}  \\phi  =   - k^2 D_n  u \\phi +  \\chi_0 n^* k^2\\,  v \\, \\phi,  \\\\\n& \\frac{\\partial v}{\\partial  t} \\phi =   - k^2 D_a  \\, v \\phi  +  \\mu u \\,  \\phi - \\delta v\\,  \\phi,\n\\end{aligned}\n\\] and since \\(\\phi\\) is not identically zero on \\((0,L)\\) we obtain a system of linear ODEs for \\((u(t),v(t))\\) \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}    =   - k^2 D_n  u  +  \\chi_0 n^* k^2\\,  v,  \\\\\n& \\frac{\\partial v}{\\partial  t} =   - k^2 D_a  \\, v  +  \\mu u  - \\delta v.\n\\end{aligned}\n\\]\nWe know that solutions of linear ODEs have the form \\[\nu(t) = C_1 e^{\\lambda t} \\quad \\textrm{and} \\quad v(t) = C_2 e^{\\lambda t}\n\\] for some constant \\(C_1\\), \\(C_2\\) and \\(\\lambda\\) are eigenvalues of the corresponding matrix.\nThus we obtain \\[\n\\begin{aligned}\n\\lambda C_1 & =  - D_n k^2 C_1  + \\chi_0 n^* k^2 C_2,  \\\\\n\\lambda C_2 & = - D_a k^2 C_2 +  \\mu C_1 - \\delta C_2,\n\\end{aligned}\n\\] which can be written\n\\[\n\\left(\n\\begin{array}{cc}\n- D_n k^2 - \\lambda &  \\chi_0 n^* k^2 \\\\\n\\mu & - D_a k^2 -\\delta -\\lambda\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\nC_1 \\\\\nC_2\n\\end{array}\n\\right) = \\mathbf{0} .\n\\]\nRemark Notice that we obtained that \\(\\tilde n\\) and \\(\\tilde a\\) are of the form \\[\\tilde{n}(x,t) = C_1 e^{\\lambda t} e^{ikx}, \\;\\;\\; \\tilde{a}(x,t) = C_2 e^{\\lambda t} e^{ikx}.\\]\nFor a non-trivial solution (for non-trivial perturbations \\(\\tilde n\\), \\(\\tilde a\\)), i.e. \\(C_1 \\neq 0\\) and \\(C_2 \\neq 0\\), the determinant of the above matrix must be zero, and this leads to the following quadratic equation to be solved for \\(\\lambda\\):\n\\[\n\\lambda^2 + \\left( D_n k^2 + D_a k^2 + \\delta \\right) \\lambda + D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 = 0.\n\\]\nThis is of the form \\[\n\\lambda^2 + \\alpha \\lambda + \\beta = 0,\n\\]\nand so has roots: \\[\n\\lambda = \\frac{-\\alpha \\pm \\sqrt{\\alpha^2 - 4 \\beta}}{2}.\\]\nNOTE This has two real roots, since \\[\n\\alpha^2 - 4 \\beta &gt; 0\n\\] (see Exercise/Tutorial).\nFor stability, we require both roots to be negative. Since both roots are real, this leads to:\n\\[\n\\lambda &lt; 0  \\Leftrightarrow \\alpha &gt; 0 \\;\\;\\; \\text{and} \\;\\;\\; \\beta &gt;0.\n\\]\nNow \\[\\alpha = D_n k^2 + D_a k^2 + \\delta &gt; 0,\n\\] and so for stability, we require \\(\\beta &gt; 0\\) i.e.\n\\[\n\\begin{aligned}\n& & D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 &gt; 0 \\\\\n& & \\Rightarrow \\mu \\chi_0 n^* &lt;  D_n  \\left( D_a k^2 + \\delta \\right)\n\\end{aligned}\n\\] Hence, we will have instability when this condition is not satisfied i.e. \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a k^2 + \\delta \\right).\n\\]\nThe precise value of \\(k^2\\) can be determined from the zero-flux boundary conditions i.e. \\[\nk  =  \\frac{m \\pi}{L}, \\;\\;\\; m = 1,2, \\dots\n\\] if we look for non-constant \\(\\phi\\).\nHence, we will have instability whenever \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a \\frac{m^2 \\pi^2}{L^2} + \\delta \\right), \\;\\;\\; m = 1,2, \\dots\n\\]\nIt can be shown (see Exercise/Tutorial), that \\(\\lambda (k^2)\\) ( or \\(\\lambda (m^2)\\)) is monotonic decreasing and hence the fastest growing mode is \\(m=1\\) i.e. we have an instability as long as \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( \\frac{D_a \\pi^2}{L^2} + \\delta \\right).\n\\]\nIn general, from the above inequality, we can say that there is a likelihood of instability (amoebae aggregation) if:\n\n\\(D_a\\), \\(D_n\\) and \\(\\delta\\) are all ``small’’\nL is ``large’’\n\\(\\chi_0 , \\mu , n^*\\) are ``large’’\n\nConsidering all other parameters to be fixed, in theory the above result states that it is possible to find a large enough value for the chemotactic coefficient \\(\\chi_0\\) to satisfy the instability condition i.e. chemotaxis induces instability and leads to aggregation of the amoebae.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "BacterialChemotaxis.html#exercise",
    "href": "BacterialChemotaxis.html#exercise",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.6 Exercise",
    "text": "5.6 Exercise\nFrom the results we have obtained we deduce that:\n\nchemotaxis has a destabilizing effect\ndiffusion has a stabilizing effect on spatially homogeneous solutions\n\nIf this is true then one might expect the numerical results presented in Figure 5.2 to have spatially homogeneous solutions if the diffusion coefficient is made sufficiently large.\n\nCan you test this by running the code for larger values of the parameter \\(D\\)?\nAlternatively, what happens if you make the chemotactic coefficient \\(\\chi_0\\) smaller?\nwhat kind of aggregation patterns do you see if the system is solved in two spatial dimensions?\n\nHowever, there is one type of system where diffusion also has a destabilizing effect…\n\n\n\n\nDurston, AJ. 2013. “Dictyostelium: The Mathematician’s Organism.” Current Genomics 14 (6): 355–60.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Aggregation via chemotaxis</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html",
    "href": "DiffusionDrivenInstability.html",
    "title": "6  Diffusion driven instability",
    "section": "",
    "text": "6.1 Spatial Pattern Formation via Reaction-Diffusion",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion",
    "href": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion",
    "title": "6  Diffusion driven instability",
    "section": "",
    "text": "6.1.1 Pattern in Developmental Biology\nEmbryology or developmental biology is that part of biology which is concerned with the formation, growth and development of the embryo from fertilization until birth. From the very moment of conception the embryo undergoes a process of dynamic change, brought about largely by cells responding to various chemical signalling cues e.g. migration, differentiation, proliferation.\n\nMany of the processes occurring at this early stage are vital for the successful subsequent development of the embryo and also lay down basic structures (e.g. somites) that form the foundation of major body structures later on (e.g. the vertebrae of the spine)\n\n\n\n\n\n\n\nProfessor Lewis Wolpert\n\n\n\nIt is not birth, marriage, or death, but gastrulation which is truly the most important time in your life.\n\n\nA fundamental question is: how do robust pattern emerge during embryo development?\nIn the Turing pre-pattern theory, chemicals, or morphogens, react together and, if certain conditions concerning their reaction kinetics and diffusion rates are satisfied (to be derived in the next section), then a pre-pattern of varying chemical concentrations is set up in the spatial domain. This means that throughout the spatial domain, the concentration levels of the chemicals will vary i.e. there will be a heterogeneous distribution of chemical concentrations which is known as a pre-pattern. Any cells in the domain which subsequently encounter these varying levels of morphogens will then respond by, for example, proliferating differentially throughout the domain. In this way, the domain will then contain a spatially heterogeneous distribution of cell densities (i.e. a cellular pattern) which have responded to the morphogen pre-pattern. This pre-pattern theory was first proposed by Alan Turing (of Enigma Code fame) in his seminal 1952 paper, The chemical basis of morphogenesis Turing (1990).\nIn the mechano-chemical theory, cells interact with their surroundings and by exerting forces perturb their local environment. The combination of cell migration/proliferation and cell-generated forces is sufficient in certain circumstances to create a spatially heterogeneous distribution of cell densities i.e. the pattern is generated simultaneously with the cell migration/proliferation. This alternative pattern formation theory was proposed by Murray and Oster Murray and Oster (1984).",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "href": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "title": "6  Diffusion driven instability",
    "section": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms",
    "text": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms\nWe now consider a general (dimensional) reaction-diffusion model for two chemicals or morphogens with concentrations \\(A({\\mathbf{x}}, t)\\) and \\(B({\\mathbf{x}}, t)\\) that react together and diffuse in some spatial domain:\n\\[\n\\begin{aligned}\n\\frac{\\partial A}{\\partial  t} & =  F(A,B)  + D_A \\nabla^2 A, \\\\\n\\frac{\\partial B}{\\partial  t} & =  G(A,B)  + D_B \\nabla^2 B,\n\\end{aligned}\n\\]\nwhere \\(F(A,B)\\) and \\(G(A,B)\\) describe the reaction kinetics between the two morphogens and \\(D_A, D_B &gt; 0\\) are the diffusion coefficients. Turing’s theory (Turing, 1952) The chemical basis of morphogenesis proposed that it was the diffusion of the substances \\(A,B\\) which led to the evolution of a spatially heterogeneous solution to arise i.e. a spatial pattern. This has given rise to the phrase diffusion-driven instability. This was a rather revolutionary and counter-intuitive proposal, since, as we have seen, diffusion normally has the opposite tendency i.e. to smooth or average out spatial heterogeneities, and to give rise to spatially homogeneous solutions.\nVarious forms can be considered for the kinetic functions \\(F\\) and \\(G\\). However, we will focus mainly on three specific classes as follows:\n\n6.2.1 Schnackenberg kinetics\n\\[\nF(A,B) = k_1 - k_2 A + k_3 A^2 B, \\;\\;\\;\\; G(A,B) = k_4 - k_3 A^2 B\n\\]\n\\(k_1\\), \\(k_2\\), \\(k_3\\), \\(k_4\\) \\(&gt;0\\). The term \\(k_3 A^2 B\\) is autocatalytic, since the species \\(A\\) upregulates its own production.\n\n\n6.2.2 Gierer and Meinhardt kinetics\nGierer and Meinhardt “A Theory of Biological Pattern Formation” (1972) developed a model that describes activator-inhibitor kinetics. The total reaction rates are \\[\nF(A,B) = k_1 - k_2 A + \\frac{k_3 A^2}{B}, \\quad G(A,B) = k_4 A^2 - k_5 B\n\\]\nwhere \\(k_1\\), \\(k_2\\), \\(k_3\\), \\(k_4\\), \\(k_5\\) &gt; 0. The term \\(k_3 A^2 / B\\) is autocatalytic.\n\n\n6.2.3 Thomas kinetics\nThomas developed a model of substrate inhibition in which \\[\n\\begin{aligned}\nF(A,B) &= k_1 - k_2 A - H(A,B), \\\\\nG(A,B) &= k_4 A^2 - k_4 B -H(A,B), \\\\\nH(A,B) &= \\frac{k_5 AB}{k_6 + k_7 + k_8 A^2}.\n\\end{aligned}\n\\]\nwith \\(k_i &gt; 0\\). In the original paper of Thomas (1975), \\(A\\) represents the concentration of oxygen (substrate) and \\(B\\) the concentration of uricase (enzyme). Substrate inhibition is evident in the term \\(k_8 A^2\\).",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#non-dimensionalisation",
    "href": "DiffusionDrivenInstability.html#non-dimensionalisation",
    "title": "6  Diffusion driven instability",
    "section": "6.3 Non-dimensionalisation",
    "text": "6.3 Non-dimensionalisation\nBefore proceeding further, it is prudent to non-dimensionalise each of the above systems.\n\n6.3.1 Schnakenberg\nWe illustrate this process for the Schnakenberg kinetics. Using the scaling\n\\[\nu = A \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad v = B \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad t^* = \\frac{D_A t}{L^2},\\quad x^* = \\frac{x}{L},\n\\]\nwhere \\(L\\) is a typical length scale, the dimensionless reaction-diffusion system with Schnakenberg kinetics becomes (upon dropping the \\(*\\) for notational convenience):\n\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma ( a - u + u^2 v ) + \\nabla^2 u = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma ( b - u^2 v ) + d \\nabla^2 v = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\tag{6.1}\\]\nwhere \\[\nd = \\frac{D_B}{D_A}, \\quad a = \\frac{k_1}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad b = \\frac{k_4}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad \\gamma = \\frac{L^2 k_2}{D_A}.\n\\]\n\n\n6.3.2 Gierer and Meinhardt\nThe Gierer-Meinhardt kinetics can be non-dimensionalised as follows:\n\\[\n\\begin{aligned}\nf(u, v) & =  a - b u + \\frac{u^2}{v}, \\\\\ng(u,v) &= u^2 - v, \\\\\n\\end{aligned}\n\\] where \\(a\\) and \\(b\\) are positive parameters (Exercise/Tutorial).\n\n\n6.3.3 Thomas\nThe Thomas kinetics can be non-dimensionalised as follows:\n\\[\n\\begin{aligned}\nf(u,v) & =  a - u - h(u,v), \\\\\ng(u,v) &= \\alpha (b - v) - h(u,v), \\\\\nh(u,v) & =  \\frac{\\rho u v}{1 + u + K u^2},\n\\end{aligned}\n\\] where \\(a\\) , \\(b\\), \\(\\alpha\\), \\(\\rho\\) , \\(K\\) are positive parameters (see Exercise/Tutorial).\n\n\n6.3.4 General\nAny reaction-diffusion system can be non-dimensionalised and scaled following the above procedure to take the general form: \\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\]\nwhere the parameter \\(d\\) is the ratio of the diffusion coefficients and the parameter \\(\\gamma\\) can be interpreted in any one of the following ways:\n\n\\(\\gamma^{1/2}\\) is proportional to the linear size of the spatial domain in one-dimension. In two-dimensions, \\(\\gamma\\) is proportional to the area.\n\\(\\gamma\\) represents the relative strength of the reaction terms – an increase in \\(\\gamma\\) may represent an increase in the activity of some rate-limiting step in the reaction sequence.\nAn increase in \\(\\gamma\\) is equivalent to a decrease in the diffusion coefficient, \\(d\\).\n\nNote that in the case where the parameter \\(d &gt; 1\\), this means that the original diffusion coefficients are not equal. Specifically, in the case of the Gierer-Meinhardt activator-inhibitor system, \\(d &gt;1\\) implies that the inhibitor diffuses more quickly than the activator [\\(d &gt; 1 \\Rightarrow D_B &gt; D_A\\) ]. The spatial implications of this are shown in Figure 6.1 – the inhibitor diffuses a greater distance than the activator, giving rise to what is known as local activation, long-range inhibition.\n\n\n\n\n\n\nFigure 6.1: Schematic diagram of activator inhibitor",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#numerical-solution",
    "href": "DiffusionDrivenInstability.html#numerical-solution",
    "title": "6  Diffusion driven instability",
    "section": "6.4 Numerical solution",
    "text": "6.4 Numerical solution\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\n\n# MOdel parameters\ngamma=650.0\na=0.2\nb=1.3\nd=30.0\n\n# Define and discretise domain\nT=3\nL=1\nN_x=80\nN_t=50\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n# Initial conditions - spat hom + noise to excite different solution modes\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\n\nu_0=np.concatenate((u_0,v_0))\n\n\n# Function to compute RHS of discretised PDE\ndef ShcnackPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    v=sol[N_x:]\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n\n    # no flux BC\n    i=0\n    f_u[i]=1/dx**2*(-u[i]+u[i+1])\n    # no flux BC\n\n    i=N_x-1\n    f_u[i]=1/dx**2*(u[i-1]-u[i])\n\n\n    for i in range(1,N_x-2):\n      f_v[i]=d/dx**2*(v[i-1]-2*v[i]+v[i+1]) \n    \n    # no flux BC\n    i=0\n    f_v[i]=d/dx**2*(-v[i]+v[i+1])\n    \n    # no flux BC\n    i=N_x-1\n    f_v[i]=d/dx**2*(v[i-1]-v[i])\n\n    # Reactions\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n    f= np.concatenate((f_u,f_v)) \n    return f  \n\n\n# Nunmerically solve discretised ODEs\nsol=odeint(ShcnackPDErhs,u_0,t)\nu=sol[:,0:N_x]\nv=sol[:,N_x:]\n\n\n# Plot results\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, v[0,:],'r--')\nax[1].plot(x, v[16,:],'b--')\nax[1].plot(x, v[32,:],'m--')\nax[1].plot(x, v[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$v$')\n\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6.2: DDI with Schnackenberg kinetics.\n\n\n\n\n\nIn Figure 6.3 we consider a numerical solution of the Schnackenberg model on a 2D square domain with no-flux boundary conditions.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\n\n\n# Model parameters\ngamma=650.0\na=0.2\nb=1.3\nd=25.0\n\n\n# Define and discretise domain\nT=5\nL=1\nN_x=20\nN_t=30\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ny=np.linspace(0,L,N_x)\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n# Define initial conditions\n[x,y]=np.meshgrid(x,y)\n\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\n\nu_0=np.concatenate((np.ravel(u_0),np.ravel(v_0)))\n\n\n\n# Compute rhs of discretised PDE\ndef ShcnackPDErhs2d(sol,t):\n\n    num_nodes=int(np.ceil(len(sol)/2))\n\n    u=sol[0:num_nodes]\n    v=sol[num_nodes:]\n\n\n    u=np.reshape(u,(N_x,N_x))\n    v=np.reshape(v,(N_x,N_x))\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n \n    # Interior nodes\n    for i in range(1,N_x-2):\n      for j in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-4*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-4*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n    \n    # LHS BC\n\n    i=0 \n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(-3*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(-3*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n    # RHS BC\n\n    i=N_x-1\n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i,j+1]+v[i,j-1])   \n    # bottom BC\n\n    j=0\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j+1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j+1]) \n    # Top BC\n\n    j =N_x-1\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j-1])  \n    \n    # Bottom left corner\n\n    i=0\n    j=0\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j+1]) \n    # Bottom right corner\n\n    i=0\n    j=N_x-1\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j-1]) \n    # Top left corner\n\n    i=N_x-1\n    j=0\n\n    f_u[i,j]=1/dx**2*(u[i-1,j]-2*u[i,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(v[i-1,j]-2*v[i,j]+v[i,j+1]) \n    # Top right corner\n   \n    i=N_x-1\n    j=N_x-1\n\n\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i-1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i-1,j]+v[i,j-1]) \n\n\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n    f= np.concatenate((np.ravel(f_u),np.ravel(f_v))) \n    return f  \n\n# Numerically solve discretised ODEs\nsol=odeint(ShcnackPDErhs2d,u_0,t)\n\n\n# Grab solution at time 1 and reshape into square domain\nu_0=sol[0,0:N_x**2]\nv_0=sol[0,N_x**2:]\nu_0=np.reshape(u_0,(N_x,N_x))\nv_0=np.reshape(v_0,(N_x,N_x))\n\n# Grab solution at time 20 and reshape into square domain\n\nu_m=sol[20,0:N_x**2]\nv_m=sol[20,N_x**2:]\nu_m=np.reshape(u_m,(N_x,N_x))\nv_m=np.reshape(v_m,(N_x,N_x))\n\nu=sol[-1,0:N_x**2]\nv=sol[-1,N_x**2:]\nu=np.reshape(u,(N_x,N_x))\nv=np.reshape(v,(N_x,N_x))\n\n# Plot results\nfig, ax = plt.subplots(2,3)\nax[0,0].imshow(u_0)\nax[1,0].imshow(v_0)\nax[0,1].imshow(u_m)\nax[1,1].imshow(v_m)\nax[0,2].imshow(u)\nax[1,2].imshow(v)\n\nax[0,0].set_xlabel('$x$')\nax[0,1].set_xlabel('$x$')\nax[0,2].set_xlabel('$x$')\nax[1,0].set_xlabel('$x$')\nax[1,1].set_xlabel('$x$')\nax[1,2].set_xlabel('$x$')\n\nax[0,0].set_ylabel('$y$')\nax[0,1].set_ylabel('$y$')\nax[0,2].set_ylabel('$y$')\nax[1,0].set_ylabel('$y$')\nax[1,1].set_ylabel('$y$')\nax[1,2].set_ylabel('$y$')\n\n\nplt.xlabel('$x$')\nplt.tight_layout()\n\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6.3: DDI with Schnackenberg kinetics in 2D",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#general-conditions-for-diffusion-driven-instability",
    "href": "DiffusionDrivenInstability.html#general-conditions-for-diffusion-driven-instability",
    "title": "6  Diffusion driven instability",
    "section": "6.5 General conditions for diffusion-driven instability",
    "text": "6.5 General conditions for diffusion-driven instability\nLet \\(\\Omega \\subset R^n\\) be a domain with smooth (sufficiently regular) boundary, \\(\\partial \\Omega\\), with outward unit normal \\({\\mathbf{n}}\\). Our general, non-dimensional reaction-diffusion system is then:\n\\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t} = \\gamma\\, f(u,v)  +  \\nabla^2 u, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\\frac{\\partial v}{\\partial  t} = \\gamma\\, g(u,v)  + d \\nabla^2 v, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\n\\end{aligned}\n\\tag{6.2}\\]\ntogether with boundary and initial conditions \\[\n\\begin{aligned}\n\\nabla u \\cdot {\\mathbf{n} } = 0, \\qquad \\nabla v \\cdot {\\mathbf{n} } = 0, \\qquad x\\in \\partial \\Omega, \\quad t&gt;0, \\\\\nu(x,0)  = u_0(x), \\qquad  v(x,0)  = v_0(x), \\qquad x\\in \\Omega\\; .\n\\end{aligned}\n\\tag{6.3}\\]\nA spatially homogeneous steady-state of Equation 6.2 and Equation 6.3 satisfies \\[\nf(u,v) = 0 , \\qquad g(u,v) =0.\n\\]\nand we denote it by \\((u_0, v_0)\\).\n\n6.5.1 Stability of spatially homogeneous steady states to spatially homogeneous perturbations\nBefore we consider the effect of diffusion in Equation 6.2 and Equation 6.3, we first explore the stability of the spatially homogeneous steady state.\nConsider the following perturbations to the steady state \\((u_0 , v_0)\\): \\[\nu(x,t) = u_0 + \\tilde u(t), \\quad  v(x,t) = v_0 + \\tilde v(t), \\qquad \\|\\tilde u(t) \\| \\ll 1, \\quad  \\|\\tilde v(t) \\| \\ll 1.\n\\]\nUpon substitution into Equation 6.2 \\[\n\\begin{aligned}\n\\frac{d\\tilde u}{d t} = \\gamma\\, f(u_0 + \\tilde u,v_0 + \\tilde v),  \\\\\n\\frac{d \\tilde v}{d  t} = \\gamma\\, g(u_0 + \\tilde u,v_0 + \\tilde v).\n\\end{aligned}\n\\tag{6.4}\\]\nTaylor expansion of \\(f\\) and \\(g\\) about \\((u_0, v_0)\\) yields the linearised system \\[\n\\begin{pmatrix}\n\\tilde u_t \\\\\n\\tilde v_t\n\\end{pmatrix}  = \\gamma J  \\begin{pmatrix}\n\\tilde u \\\\\n\\tilde v\n\\end{pmatrix},\n\\tag{6.5}\\]\nwhere \\[\nJ =J(u_0, v_0) =  \\begin{pmatrix}\nf_u & f_v  \\\\\ng_u & g_v\n\\end{pmatrix}_{(u_0 , v_0)} \\; .  \n\\]\nThe general solution of Equation 6.5 is\n\\[\n\\begin{pmatrix}\n\\tilde u(t) \\\\\n\\tilde v(t)\n\\end{pmatrix}   =  C_1 \\phi_1 e^{\\lambda_1 t} +  C_2 \\phi_2 e^{\\lambda_2 t},\n\\]\nwhere \\(C_1\\), \\(C_2\\) are arbitrary constants, \\(\\lambda_1, \\lambda_2\\) are the eigenvalues of \\(\\gamma J\\), i.e. solutions of the characteristic equation \\[\n\\det (\\gamma J - \\lambda I) = 0,\n\\]\nand \\(\\phi_1\\), \\(\\phi_2\\) are corresponding eigenvectors. It is easily seen that\n\\[\n\\lambda_{1,2} = \\frac \\gamma 2 \\left( \\textrm{tr} (J) \\pm \\sqrt{ \\textrm{tr}(J)^2 - 4 \\det(J)} \\right),\n\\]\nand thus a spatially homogeneous steady state \\((u_0, v_0)\\) is stable to spatially homogeneous perturbations if \\[\n{\\mathrm Re}( \\lambda_{1,2}) &lt;0,\n\\]\ni.e. if \\[\n\\begin{aligned}\n\\mathrm{tr}(J) & = f_u + g_v &lt; 0, \\\\\n\\det(J) & = f_u g_v - f_v g_u &gt; 0.\n\\end{aligned}\n\\tag{6.6}\\]\nWe shall be interested only in such parameter values for which conditions Equation 6.6 are satisfied (i.e. the spatially homogeneous steady state is linearly stable in the absence of diffusion).\n\n\n6.5.2 Stability of spatially homogeneous steady states to spatially heterogeneous perturbations\nWe now consider perturbations about the spatially homogeneous steady state that are spatially dependent, i.e. \\[\nu(x,t) = u_0 + \\tilde u(x,t), \\quad  v(x,t) = v_0 + \\tilde v(x,t), \\qquad \\|\\tilde u(x,t) \\| \\ll 1, \\quad  \\|\\tilde v(x,t) \\| \\ll 1.\n\\]\nUpon substitution in Equation 6.2 and Taylor expanding \\(f\\) and \\(g\\) about \\((u_0, v_0)\\) yields the linearised problem\n\\[\n\\begin{aligned}\n\\frac{\\partial \\tilde u(x,t)}{\\partial t} = \\gamma\\, \\left(f_u \\tilde u(x,t) + f_v \\tilde v(x,t)\\right) + \\nabla^2 \\tilde u(x,t)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{\\partial \\tilde v(x,t)}{\\partial   t} = \\gamma\\,  \\left(g_u  \\tilde u(x,t) + g_v \\tilde v(x,t)\\right) +d \\nabla^2 \\tilde v(x,t)  \\quad x\\in \\Omega,   t &gt;0,\n\\end{aligned}\n\\tag{6.7}\\]\nwith boundary conditions \\[\n\\begin{aligned}\n{\\mathbf{n}} \\cdot \\nabla \\tilde u (x,t) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla \\tilde v (x,t)  = 0, \\qquad   x\\in \\partial \\Omega, \\; t &gt;0.\n\\end{aligned}\n\\tag{6.8}\\]\nDefining \\[\nV(x,t) = \\begin{pmatrix}\n\\tilde u(x,t) \\\\\n\\tilde v(x,t)\n\\end{pmatrix}\n\\]\nwe rewrite Equation 6.7 as \\[\n\\frac{\\partial}{\\partial t}  V(x,t) = \\gamma J  V(x,t) + D \\nabla^2   V(x,t),\n\\]\nwhere\n\\[\nD =  \\begin{pmatrix}\n1 & 0 \\\\\n0 & d\n\\end{pmatrix}.\n\\]\n\n6.5.2.1 Separation of variables\nWe shall consider a separation of variables approach, i.e. \\[\nV(x,t) =\\begin{pmatrix}  \n\\bar u(t)  \\varphi_1(x)\n\\\\\n\\bar v(t)  \\varphi_2(x)\n\\end{pmatrix},\n\\]\nand obtain \\[\n\\begin{aligned}\n\\frac{d \\bar u(t)}{d t}\\varphi_1(x) = \\gamma\\, \\left(f_u \\bar u(t) \\varphi_1(x) + f_v \\bar v(t) \\varphi_2(x)\\right) +\\bar u(t)  \\nabla^2 \\varphi_1(x)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{d \\bar v(t)}{d t}\\varphi_2(x) = \\gamma\\,  \\left(g_u  \\bar u(t) \\varphi_1(x) + g_v \\bar v(t) \\varphi_2(x)\\right) +  d \\bar v(t) \\nabla^2  \\varphi_2(x)  ,  \\quad x\\in \\Omega, \\;  t &gt;0,  \\\\\n\\end{aligned}\n\\tag{6.9}\\]\nwith boundary conditions \\[\n\\begin{aligned}\n{\\mathbf{n}} \\cdot \\nabla \\varphi_1(x) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla\\varphi_2 (x) = 0, \\qquad   x\\in   \\partial \\Omega, \\; t &gt;0.\n\\end{aligned}\n\\tag{6.10}\\]\nIt is assumed that \\[\n\\bar u(t)\\, / \\hspace{-0.35 cm}\\equiv 0 \\quad \\textrm{and} \\quad  \\bar v(t)\\, / \\hspace{-0.35 cm}\\equiv 0\n\\] for \\(t&gt;0\\).\n\n\n6.5.2.2 Eigenvalues of the Laplacian\nWe can make the assumption that \\[\n\\phi_1(x)=\\phi_2(x)=\\phi_k(x)\n\\] and use the substitution \\[\n\\nabla^2 \\varphi_k=-k^2\\varphi_k.\n\\]\n1D Cartesian\nSubsitution in Equation 6.9 yields \\[\n\\begin{aligned}\n\\frac{d \\bar u(t)}{d t}\\varphi_k(x) = \\gamma\\, \\left(f_u \\bar u(t) \\varphi_k(x) + f_v \\bar v(t) \\varphi_k(x)\\right) +\\bar u(t)  \\nabla^2 \\varphi_k(x)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{d \\bar v(t)}{d t}\\varphi_k(x) = \\gamma\\,  \\left(g_u  \\bar u(t) \\varphi_k(x) + g_v \\bar v(t) \\varphi_k(x)\\right) +  d \\bar v(t) \\nabla^2  \\varphi_k(x)  ,  \\quad x\\in \\Omega, \\;  t &gt;0,  \\\\\n\\end{aligned}\n\\]\nSeparating variables\n\\[\n\\begin{aligned}\n\\frac{\\nabla^2  \\varphi_k(x)}{\\varphi_k(x)}= \\frac{\\frac{d \\bar u(t)}{d t} - \\gamma\\, \\left(f_u \\bar u(t)  + f_v \\bar v(t)\\right)}{\\bar{u}(t)}     , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\end{aligned}\n\\]\nHence \\[\n\\frac{\\nabla^2  \\varphi_k(x)}{\\varphi_k(x)}=-k^2.\n\\]\nIn 1D Cartesians \\[\n\\frac{d^2  \\varphi_k(x)}{dx^2}=-k^2\\varphi_k(x).\n\\]\nwith no-flux boundary condition on \\(x=0\\) and \\(x=1\\). The solution is \\[\n\\varphi_k(x)=B_k\\psi_k (kx), \\quad k=n\\pi, \\quad n\\in Z,\n\\] where \\[\n\\psi_k(x)=\\cos(kx).\n\\]\nThe cosine function are eigenfunctions of the Laplacian operator in 1D Cartesian coordinates with no-flux boundary conditions.\nNote that:\n\n\\(k\\) is called the wavenumber\n\\(1/k\\) is proportional to the wavelength\n\n\n\n\n\n\n\nA general approach to the spatial eigenvalue problem\n\n\n\nConsider the spatial eigenvalue problem for the Laplacian \\(\\nabla^2\\) with zero-Neumann boundary conditions, i.e.\n\\[\n\\begin{aligned}\n\\nabla^2 \\psi(x) = -k^2 \\psi(x), \\qquad x \\in \\Omega,  \\\\\n{\\mathbf{n}} \\cdot \\nabla \\psi(x) = 0, \\qquad x\\in \\partial \\Omega.\n\\end{aligned}\n\\tag{6.11}\\]\nFor a bounded domain \\(\\Omega\\) there exists a discrete set of eigenvalues \\[\n0 \\leq k^2_1&lt; k_2^2\\leq k_3^2\\leq \\ldots \\leq k_j^2\\leq \\ldots,\n\\]\nwith \\[\nj \\in \\mathbb N, \\quad  \\textrm{and} \\quad k_j^2 \\to \\infty \\quad \\textrm{as}  \\quad j \\to \\infty.\n\\]\nMoreover, the eigenfunctions \\(\\{\\psi_k(x) \\}\\) form an orthogonal set of basis functions of the corresponding functional space (i.e. \\(L^2(\\Omega)\\), \\(H^1(\\Omega)\\)).\n\n\n\n\n6.5.2.3 Instability of spatially heterogeneous perturbations\nwe can look for the spatial component of the solution of Equation 6.9 as follows: \\[\n\\varphi(x) = \\begin{pmatrix}  \n\\varphi_1(x) \\\\\n\\varphi_2(x)\n\\end{pmatrix} = \\sum_k C_k \\psi_k(x), \\qquad C_k =  \\begin{pmatrix}  C_k^1 \\\\ C_k^2 \\end{pmatrix} \\in \\mathbb R^2 \\;\n\\] and \\[\n\\begin{aligned}\nV(x,t) =\\sum_k \\hat V_k(t) \\psi_k(x), \\qquad \\textrm{ where}\n\\quad \\hat V_k(t)=\n\\begin{pmatrix}  \nC_k^1 \\; \\bar u(t)\n\\\\\nC_k^2 \\; \\bar v(t)\n\\end{pmatrix}.\n\\end{aligned}\n\\tag{6.12}\\]\nSince \\[\n\\nabla^2 \\psi_k(x) = - k^2 \\psi_k(x)\n\\]\nwe obtain\n\\[\nD \\nabla^2  V(x,t) = D \\nabla^2 \\left[ \\sum_k \\hat V_k(t) \\psi_k(x) \\right]   = \\sum_k D \\hat V_k(t) \\nabla^2 \\psi_k(x)=\n- \\sum_k k^2 D \\hat V_k(t)  \\psi_k(x).\n\\]\nHence \\[\n\\sum_k \\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n  \\sum_k \\gamma J \\hat V_k(t) \\psi_k(x) -  \\sum_k k^2  D \\hat V_k(t) \\psi_k(x).\n\\]\nSince \\(\\{\\psi_k(x) \\}\\) is an orthogonal basis we obtain that\n\\[\n\\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n   \\gamma J  \\hat V_k(t) \\psi_k(x) -  k^2  D \\hat V_k(t) \\psi_k(x),\n\\]\nfor each \\(k\\). Finally, since \\[\n\\psi_k(x)\\;  /\\hspace{-0.35 cm }\\equiv 0\n\\]\nin \\(\\Omega\\) this implies for each \\(k\\) a system of ODEs:\n\\[\n\\begin{aligned}\n\\frac{d}{d t}  \\hat V_k(t)   =   \\left(\\gamma J  -  k^2  D\\right) \\hat V_k(t) = \\tilde J\\hat V_k(t) ,\n\\end{aligned}\n\\tag{6.13}\\]\nwhere \\(\\tilde J\\) is the “modified” Jacobian:\n\\[\n\\tilde{J} =  \\begin{pmatrix}\n\\gamma f_u - k^2 & \\gamma f_v \\\\\n\\gamma g_u & \\gamma g_v - d k^2\n\\end{pmatrix}.\n\\]\nNow solutions of Equation 6.13 are of the form \\[\n\\hat V_k(t) = e^{\\lambda t} P_k\n\\]\nwith \\(P_k \\in \\mathbb R^2\\), where, since \\(P_k\\neq 0\\) (looking for nontrivial solutions), we find that \\(\\lambda\\) are the eigenvalues of \\(\\tilde J\\) , i.e. solutions of the characteristic equation \\[\n\\det(\\tilde J - \\lambda I) = \\det ( \\gamma J - k^2 D - \\lambda I) =0.\n\\tag{6.14}\\]\nEvaluating the determinant \\[\n\\lambda^2 + [ k^2 (1 + d) - \\gamma (f_u + g_v) ] \\lambda + h(k^2) = 0,\n\\tag{6.15}\\]\nwhere \\[\nh(k^2) = dk^4 - \\gamma (df_u + g_v) k^2 + \\gamma^2 | J | .\n\\tag{6.16}\\]\nNOTE: From Equation 6.14, Equation 6.15 we can recover the characteristic equation for the spatially homogeneous perturbation when \\(k=0\\), i.e. \\[\n\\tilde J \\Big|_{k=0} = ( \\gamma J - k^2 D )\\Big|_{k=0} = \\gamma J.\n\\]\nThus the steady state \\((u_0, v_0)\\) is unstable to spatially heterogeneous perturbations iff \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\textrm{and/or} \\quad {\\mathrm Re}(\\lambda_2) &gt;0,\n\\]\nwhere \\(\\lambda_{1,2}\\) are solutions of Equation 6.14, Equation 6.15.\nNow for \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\textrm{and/or } \\quad {\\mathrm Re}(\\lambda_2) &gt;0\n\\]\nto be satisfied we require \\[\n\\textrm{tr}(\\tilde J) &gt; 0 \\quad \\textrm{ or } \\quad \\det(\\tilde J) &lt;0.\n\\]\nConsider first \\({\\mathrm tr} (\\tilde{J})\\). We have \\[\n\\textrm{tr}(\\tilde J) = \\gamma ( f_u+ g_v) - k^2(1+d) &lt; 0, \\hspace{4 cm}  \n\\]\nsince \\(\\gamma &gt; 0\\) and \\[\nf_u+ g_v &lt; 0\n\\]\nby the stability condition for the spatially homogeneous perturbation Equation 6.6. Thus instability to the spatially heterogeneous perturbation can only occur if \\[\n\\det(\\tilde J) &lt; 0\n\\]\nand so we require: \\[\n\\det(\\tilde J) = h(k^2) = dk^4  - \\gamma ( d\\,  f_u + g_v) k^2 + \\gamma^2 \\det(J) &lt; 0.\n\\]\nFrom the spatially homogeneous stability conditions Equation 6.6 we have \\(\\det(J) &gt;0\\). Thus \\(h(k^2)&lt;0\\) is possible only if \\[\nd f_u + g_v &gt;0.\n\\tag{6.17}\\]\nHowever, once again, due to Equation 6.6, we have \\(f_u+ g_v &lt;0\\), and so we can conclude that \\(d\\neq 1\\) and \\(f_u\\) and \\(g_v\\) must have opposite signs.\nCondition Equation 6.17 is necessary but not sufficient to ensure \\(h(k^2) &lt;0\\). In order to guarantee that \\(h(k^2) &lt; 0\\), the minimum value \\(h_{min}\\) must be negative. Differentiating Equation 6.16 w.r.t. \\(k^2\\), we find that:\n\\[\nk^2_{m} = \\gamma \\frac{d f_u + g_v}{2d} \\;\\; \\Rightarrow \\;\\; h_{min} = \\gamma^2 \\left[ | J | - \\frac{(df_u + g_v)^2}{4d} \\right].\n\\tag{6.18}\\]\nThus the condition that \\(h(k^2) &lt; 0\\) for some \\(k^2\\) is:\n\\[\n\\frac{(df_u + g_v)^2}{4d} &gt; |J|.\n\\]\nThe transition from stability to instability i.e. bifurcation, occurs when \\(h_{min} = 0\\). From Equation 6.18, this means at bifurcation we have \\[\n|J| = \\frac{(df_u + g_v)^2}{4d}.\n\\tag{6.19}\\]\nFor a fixed set of kinetics parameters, this means that we have a critical diffusion coefficient \\(d_c(&gt;1)\\), which, after re-arranging Equation 6.19, is the appropriate root of\n\\[\nq(d_c) = d^2_c f_u^2 + 2( 2 f_v g_u - f_u g_v) d_c + g_v^2 =0.\n\\tag{6.20}\\]\nFinally, we note that using Equation 6.18, Equation 6.19, the critical wave number can be written: \\[\nk_c^2 =\\gamma  \\frac{( d_c f_u + g_v)} { 2 d_c} = \\gamma \\left[ \\frac {|J|}{d_c} \\right]^{1/2} = \\gamma \\left[ \\frac{f_u g_v - f_v g_u}{d_c} \\right]^{1/2}.\n\\tag{6.21}\\]\nFigure 6.5 (a) shows a schematic diagram of the (quadratic) function \\(h(k^2)\\) for three different values of the diffusion coefficient \\(d\\):\n\n\\(d &lt; d_c, \\; h(k^2) &gt; 0\\), and there is no pattern;\n\\(d = d_c, \\; h_{min} = 0\\), critical case;\n\\(d &gt; d_c, \\; h(k^2) &lt; 0\\), and there is pattern.\n\nHence we can see from Equation 6.15 that whenever \\(h(k^2) &lt; 0\\) the curve \\(\\lambda(k^2)\\) is positive for the same range of wavenumbers that make \\(h(k^2)\\) negative. The range of unstable wavenumbers \\[\nk^2_1 &lt; k^2 &lt; k^2_2\n\\]\ncan be found from the roots of Equation 6.16, \\(h(k^2) = 0\\):\n\\[\n\\begin{aligned}\nk^2_1 &= \\gamma \\frac{(df_u + g_v) - \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2} }{2d} &lt; k^2  \\\\\n&&lt; \\gamma \\frac{(df_u + g_v) +  \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2}}{2d} = k^2_2\n\\end{aligned}\n\\tag{6.22}\\]\nFigure 6.5 (b) shows a schematic diagram of \\({\\mathrm Re}\\lambda (k^2)\\) for three different values of the diffusion coefficient \\(d\\):\n\n\\(d &lt; d_c\\), ; $Re (k^2) &lt; 0, k^2 $, and there is no pattern;\n\\(d = d_c, \\; k^2_c = 0\\), critical case;\n\nThe expression \\(\\lambda = \\lambda (k^2)\\) is known as the dispersion relation and the plot of \\({\\mathrm Re} \\lambda\\) against \\(k^2\\) is known as the dispersion curve.\nFrom the previous analysis, within the unstable range of wavenumbers \\((k^2_1 , k^2_2)\\), \\({\\mathrm Re}\\lambda (k^2) &gt; 0\\) has a maximum value at wavenumber \\(k^2_m\\) given by Equation 6.18 when \\(d &gt; d_c\\). This implies that there is a fastest growing mode in the solution Equation 6.12 of our linearised system Equation 6.9.\nRecalling Equation 6.12,\n\\[\nV(x,t) = \\sum_k C_k e^{\\lambda(k^2) t} \\, \\psi_k(x),\n\\]\nand noting the above analysis, this implies that as \\(t\\to \\infty\\) the dominant contributions in the above sum are those for which \\({\\mathrm Re} \\lambda(k^2) &gt; 0\\), since all other modes will tend to zero exponentially fast as \\(t\\to \\infty\\). Thus, for large \\(t\\), the solution is effectively given by: \\[\nV(x,t) \\approx \\sum_{k_{1}}^{k_2} C_k e^{\\lambda(k^2) t} \\, \\psi_k(x) \\; .\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# discrtise k^2 for plotting\nk_sq_max=35\nk_sq_min_plot=6.4\nk_sq=np.linspace(0,k_sq_max,100)\n\n\n# Some made up numbers for this example\ngamma=100.0\nd_1=3.0\nd_2=6.0\n\nf_u=0.4\ng_v=-0.5\nJ=0.1 # positive determinant\n\n\n# Compute h - defined in notes -DDI possible  this is negative\ndef Computeh(k_sq,d):\n  term1=d*f_u+g_v\n\n  h=d*k_sq**2-gamma*(term1)*k_sq+ gamma**2*J\n  return h\n\n# Compute Re lambda - DDI when this is positive\n\ndef SolveReLambda(k_sq,d):\n   # a lam^2 + b * lam +c\n    a=1\n    b= k_sq*(1+d)-gamma*(f_u+g_v)\n    c= Computeh(k_sq,d)\n    lambda_m= (-b-np.sqrt(b**2-4*a*c))/(2*a)\n    lambda_p= (-b+np.sqrt(b**2-4*a*c))//(2*a)\n    return lambda_m,lambda_p\n\n\n# Test if DDI conditions are satisfied\ndef TestDDIconditions(d):\n\n    cond_1=f_u+g_v\n    cond_2 = J\n    cond_3 = d*f_u+g_v\n    cond_4 = (d*f_u+g_v)**2-4*d*J\n\n    cond_true=np.zeros((4,1),dtype=bool)\n    cond_true[0]=(cond_1&lt;0) \n    cond_true[1]= (cond_2&gt;0) \n    cond_true[2]= (cond_3&gt;0)\n    cond_true[3]=(cond_4&lt;0)\n\n\n    return cond_true\n\nh_1=Computeh(k_sq,d_1)\nh_2=Computeh(k_sq,d_2)\n\nl_1_m, l_1_p = SolveReLambda(k_sq,d_1)\nl_2_m, l_2_p = SolveReLambda(k_sq,d_2)\n\nconditions_satisfied1=TestDDIconditions(d_1)\nconditions_satisfied2=TestDDIconditions(d_2)\n\n\n# Plot results\nfig, ax=plt.subplots()\nax.plot(k_sq,h_1,'r',k_sq,h_2,'k')\nax.set_xlabel('$k^2$')\nax.set_ylabel('$h$')\nax.legend(['d='+str(d_1),'d='+str(d_2)])\nax.set_ylim([-1000,4000])\nax.fill_betweenx ([-1000, 4000], [k_sq_min_plot], [25],alpha=0.2)\nax.set_xlim([0,k_sq_max])\n\nplt.show()\n\nfig, ax=plt.subplots()\nax.plot(k_sq,np.real(l_1_m),'r',k_sq,np.real(l_2_m),'k')\nax.plot(k_sq,np.real(l_1_p),'r--',k_sq,np.real(l_2_p),'k--')\n\nplt.grid()\nax.set_xlabel('$k^2$')\nax.set_ylabel('$\\Re\\{\\lambda\\}$')\nax.set_ylim([-100,25])\nax.fill_betweenx ([-100, 5], [k_sq_min_plot], [25],alpha=0.2)\nax.set_xlim([0,k_sq_max])\n\nax.legend(['d='+str(d_1),'d='+str(d_2)])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 6.4: A plot of \\(h(k^2)\\) plotted against \\(k^2\\). Shaded region denotes unstable wave numbers in case of largets \\(d\\).\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.5: The real part of the eigenvalue plotted against \\(k^2\\).\n\n\n\n\n\nNOTE\nAll the previous calculations concern a linear stability analysis carried out about a spatially homogeneous steady state of the system Equation 6.2. This linear theory indicates that for \\(d &gt; d_c\\) there exists a finite number of linearly unstable spatial eigenfunctions which grow exponentially as \\(t \\to \\infty\\). However, this linear theory holds only when we are close to the steady state i.e. it only holds for small perturbations. In the full nonlinear system the exponentially growing (unbounded) modes will eventually be bounded by the nonlinear terms and so bounded, stable spatial patterns characterised by the corresponding wavenumbers will be formed.\nSummary\nWe have obtained conditions for the generation of spatial patterns via systems of reaction-diffusion equations of the general form Equation 6.2. Such systems involve two chemicals or morphogens reacting and diffusing together to generate a chemical pre-pattern that underlies a subsequent cellular pattern. The four conditions are as follows:\n\\[\n\\begin{aligned}\nf_u + g_v &&lt; 0, \\\\\nf_u g_v - f_v g_u &&gt; 0, \\\\\nd f_u + g_v &&gt; 0, \\\\\n(d f_u + g_v)^2 - 4d (f_u g_v - f_v g_u)^2 &&lt; 0 , \\nonumber\n\\end{aligned}\n\\tag{6.23}\\]\nwith all partial derivatives being evaluated at the spatially homogeneous steady state \\((u_0 , v_0)\\).\nFrom the first and third conditions, \\(d \\neq 1\\) and \\(f_u\\) and \\(g_v\\) must be of different signs. For each of the reaction kinetics mentioned here (Schnakenberg, Gierer-Meinhardt, Thomas), we have that \\(f_u &gt; 0, g_v &lt; 0\\) and so this implies that \\(d &gt; 1\\).\nIf the conditions Equation 6.23 are satisfied, then there is a range of unstable wavenumbers given by Equation 6.22 which give rise to a spatial pattern. The spatial patterns which initially grow are those spatial eigenfunctions \\(\\psi_k(x)\\) whose wavenumbers \\(k\\) are such that \\(k_1 &lt; k &lt; k_2\\).\nIn most biological systems, the kinetic parameters and diffusion coefficients are fixed. This means that the only variable parameter in the system is \\(\\gamma\\) which as we have seen is related to the size of the domain under consideration. This has implications when considering patterns on finite domains, as will be seen in the next section.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#exercises",
    "href": "DiffusionDrivenInstability.html#exercises",
    "title": "6  Diffusion driven instability",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\nDemonstrate that the derived results are consistent with numerical solutions. Some predictions to test:\n\nNo patterning when diffusion coefficients are equal\nHow does spatial pattern formation change as you try values of parameters \\(a\\) and \\(b\\)?\nCan you correlate the observation of pattern to the conditions for DDI being satisfied?\nwhat about different kinetics (e.g. Gierer-Meinhardt, Thomas models)?",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "DiffusionDrivenInstability.html#references",
    "href": "DiffusionDrivenInstability.html#references",
    "title": "6  Diffusion driven instability",
    "section": "6.7 References",
    "text": "6.7 References\n\n\n\n\n“A Theory of Biological Pattern Formation.” 1972. Kybernetik 12: 30–39.\n\n\nMurray, James D, and George F Oster. 1984. “Generation of Biological Pattern and Form.” Mathematical Medicine and Biology: A Journal of the IMA 1 (1): 51–75.\n\n\nTuring, Alan Mathison. 1990. “The Chemical Basis of Morphogenesis.” Bulletin of Mathematical Biology 52: 153–97.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Diffusion driven instability</span>"
    ]
  },
  {
    "objectID": "SIR_PDE.html",
    "href": "SIR_PDE.html",
    "title": "7  Infectious disease",
    "section": "",
    "text": "7.1 Generalising the SIR model\nAssumptions\nConsider consider three categories of population\nProgress through the disease \\[\nS \\longrightarrow I \\longrightarrow R\n\\]\nModel assumptions\n\\(1/a\\) measures the time spent in the infectious state.\nThen a simple SIR model reads (in a long thin domain or in \\(3\\)-dim domain with solutions in a form of planar fronts) \\[\n\\begin{aligned}\n\\frac{\\partial S}{\\partial t} &= - r SI + D_S \\frac{ \\partial^2 S}{\\partial x^2}\\; ,  \\quad x \\in \\mathbb R ,  t&gt;0 \\; , \\\\\n\\frac{\\partial I}{\\partial t} &= r SI - a I+ D_I \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  \\quad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n\\frac{\\partial R}{\\partial t} &= a I + D_R \\frac{ \\partial^2 R}{\\partial x^2} \\; ,  \\quad x \\in \\mathbb R , \\; t&gt;0 \\; \\\\\nS(0,x) &= S_0(x), \\qquad I(0,x) = I_0(x), \\quad R(0,x) = R_0(x), \\qquad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.1}\\]\nwhere\nWe assume that \\(S_0(x) \\geq 0\\), \\(I_0(x) \\geq 0\\), \\(R_0(x) \\geq 0\\) for \\(x \\in \\mathbb R\\) and obtain that solutions of Equation 7.1 are nonnegative, i.e. \\[\nS(t,x) \\geq 0, \\quad I(t,x) \\geq 0, \\quad R(t,x) \\geq 0, \\quad  x\\in \\mathbb R, \\quad t &gt;0 \\; .\n\\]\nTo analyse the model Equation 7.1 it is sufficient to consider the first two equations, since \\(R\\) is completely determined by \\(I\\) and does not influence the dynamics of \\(S\\) and \\(I\\).\nConsidering the non-dimensionalisation \\[\ni = \\frac I{\\bar S_0} , s= \\frac S{\\bar S_0} ,  \\quad x^\\ast = \\left(\\frac{ r \\bar S_0}{D_I} \\right)^{1/2} x, \\quad t^\\ast = r \\bar S_0 t\n\\] we obtain\n\\[\n\\begin{aligned}\n& \\frac{\\partial s}{\\partial \\tau} = -  si + d \\frac{ \\partial^2 s}{\\partial x^2}\\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial i}{\\partial \\tau} = si - \\mu i+  \\frac{ \\partial^2 i}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& s(x,0) = \\frac{S_0(x)}{\\bar S_0}, \\qquad i(x,0) = \\frac{I_0(x)}{\\bar S_0},  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\] where \\(\\bar S_0\\) is a representative population density and \\(\\mu = a /{ r \\bar S_0}\\).\nWe would like to investigate the spatial spread of an epidemic wave of infectives into a uniform susceptibles population \\(S_0(x) =\\bar S_0\\). We would like to determine conditions for existence of an epidemic wave and propagation speed.\nWe shall assume first that \\(D_S= D_I\\), i.e. \\(d=1\\). Consider travelling wave solutions \\[\ns(x,t) = \\bar{s}(z), \\quad i(x,t) = \\bar{i}(z), \\quad z = x - v t, \\quad v &gt;0\n\\] and obtain following ODEs for \\(s\\) and \\(i\\) \\[\n\\begin{aligned}\n\\bar{s}^{\\prime \\prime} + v \\bar{s}^\\prime - \\bar{i}\\bar{s} = 0 \\; , \\\\\n\\bar{i}^{\\prime \\prime} + v \\bar{i}^\\prime + \\bar{i}\\bar{s} - \\mu \\bar{i}= 0\\; .\n\\end{aligned}\n\\tag{7.2}\\]\nWe would like to analyse the existence of a travelling wave from for \\(s\\) and travelling wave pulse for \\(i\\). We assume that the infection comes into susceptible population from the left.\nTherefore we consider the following boundary conditions for the travelling wave solutions\n\\[\n\\begin{aligned}\n\\bar{s}(z) \\to 1 \\qquad  z\\to + \\infty, \\quad \\qquad  \\bar{i}(z) \\to 0 \\qquad  z\\to + \\infty\\; ,\\\\\n\\bar{s}(z) \\to \\sigma \\qquad  z\\to - \\infty, \\quad \\qquad  \\bar{i}(z) \\to 0 \\qquad  z\\to - \\infty\\; ,\\\\\n\\bar{s}^\\prime(z) \\to 0\\qquad  z\\to \\pm \\infty, \\quad \\qquad \\bar{i}^\\prime(z) \\to 0 \\qquad z \\to \\pm \\infty \\; ,\n\\end{aligned}\n\\tag{7.3}\\] where \\(0 \\leq \\sigma &lt;1\\).\nFor notational convenience the barred notation is now dropped.\nThe steady states of Equation 7.2 are given by \\[\nis =0 , \\quad i ( s- \\mu) = 0  \\quad \\Longrightarrow \\quad \\ i=0, \\quad s = \\text{const}.\n\\]\nConsidering boundary conditions Equation 7.3 we obtain two steady states \\[\n(s^*, i^*) = ( 1, 0), \\qquad (s^*, i^*) = (\\sigma, 0)\n\\] Hence we would like to have a heteroclinic connection between \\((\\sigma , 0)\\) and \\((1,0)\\).\nBy imposing the constraint that (1,0) cannot be a spiral, a necessary condition for the existence of travelling wave solutions satisfying Equation 7.2 and Equation 7.3 is\n\\[\nv \\geq 2 \\sqrt{ 1- \\mu} \\, \\quad \\text{ and } \\quad 0 \\leq \\mu &lt; 1\\; .  \n\\tag{7.4}\\]\nIn terms of original parameters we have \\[\n\\mu = \\frac a { r S_0} &lt; 1.\n\\] This is the necessary threshold conditions for the propagation of an epidemic wave pulse. The condition Equation 7.4 determine also the non-dimensionalised minimal wave speed \\[\nv^\\ast_{\\text{min}} = 2\\sqrt{ 1- \\mu}\n\\]\nIn dimensional terms we obtain \\[\nz^\\ast = x^\\ast - v^\\ast t^\\ast = \\left( \\frac { r S_0} {D_I} \\right)^{1/2} x - v^\\ast r S_0 t  =\n\\left( \\frac { r S_0} {D_I} \\right)^{1/2} ( x - v t) = \\left( \\frac { r S_0} {D_I} \\right)^{1/2} z\n\\] and \\[\nv = \\sqrt{ r S_0 D_I} v^\\ast \\quad v_{\\text{min}} = 2  \\sqrt{ r S_0 D_I}\\sqrt{ 1- \\mu} =\n2  \\sqrt{ r S_0 D_I}\\sqrt{ 1- \\frac a{ r S_0} }\n\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Infectious disease</span>"
    ]
  },
  {
    "objectID": "SIR_PDE.html#generalising-the-sir-model",
    "href": "SIR_PDE.html#generalising-the-sir-model",
    "title": "7  Infectious disease",
    "section": "",
    "text": "Total population is constant: the duration of the epidemic is short compared to the lifetime of its hosts, so we can neglect birth and disease-unrelated death\nConsider a disease which, after recovery, confers immunity (and/or death if lethal)\nSimple diffusion for spatial distribution of population\n\n\n\n\\(S\\) – susceptibles - can be infected\n\\(I\\) – infectives - have the disease and can transmit to susceptibles\n\\(R\\) – recovered (removed) - have had the disease and are no longer infective.\n\n\n\n\nThe gain in the infectives class is at the rate proportional to the number of infectives \\(I\\) and susceptibles \\(S\\), i.e. \\(r\\; I\\; S\\), ; \\(r&gt;0\\).\nThe susceptibles are lost at the same rate, i.r. \\(r\\; I\\; S\\)\nThe rate of removal of infectives to the recovered class \\(R\\) is proportional to the number of invfectives, i.e. \\(a\\; I\\), ; \\(a&gt;0\\).\n\n\n\nThe incubation period is short enough to be negligible: susceptibles are directly infected after coming into contact with the disease (with infectives).\n\n\n\n\n\\(a&gt;0\\) – removal or death rate\n\\(r&gt;0\\) – transmission or infection rate\n\\(D_S&gt;0\\), ; \\(D_I&gt;0\\), ; \\(D_R&gt;0\\) – diffusion coefficients\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.1 The leading edge of the epidemic front\nWe can analyse the behaviour of travelling wave solutions as \\(z \\to + \\infty\\).\nLinearised equation for the second equation in Equation 7.2 near \\(s=1\\), \\(i=0\\), i.e. as \\(z \\to + \\infty\\) reads \\[\ni^{\\prime \\prime} + v i^\\prime + i  - \\mu i = 0\\; .\n\\]\nThus \\[\ni(z) \\sim \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.5}\\] We can also show that the travelling wave solution \\(s(z)\\) cannot have a local maximum, since for \\(s^\\prime(z) = 0\\) first equation in Equation 7.2 implies \\[\ns^{\\prime \\prime}(z) = is &gt;0,\n\\] which implies a local minimum. So \\(s(z)\\) is monotone increasing.\nConsidering linearisation of the first equation in Equation 7.2 near \\(s=1\\), \\(i=0\\), i.e. as \\(z \\to + \\infty\\), we obtain with \\(s(z) = 1 - \\tilde s(z)\\) \\[\n\\tilde s^{\\prime \\prime} + v \\tilde s^{\\prime} - i = 0 \\; .\n\\] Then using Equation 7.5 we can conclude that\n\\[\n\\tilde s(z) \\sim \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.6}\\] and\n\\[\ns(z) \\sim 1 - C \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.7}\\]",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Infectious disease</span>"
    ]
  },
  {
    "objectID": "SIR_PDE.html#spatial-spread-of-rabies-among-foxes",
    "href": "SIR_PDE.html#spatial-spread-of-rabies-among-foxes",
    "title": "7  Infectious disease",
    "section": "7.2 Spatial spread of rabies among foxes",
    "text": "7.2 Spatial spread of rabies among foxes\nSpread of rabies is due primary to the migration of infected foxes. We assume the heathy foxes are territorial and do not travel very far, whereas rabid foxes wander over large distances.\nThus we assume that \\(D_S \\ll D_I\\) and \\(d= { D_S}/{D_I} \\approx 0\\).\n\\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  SI \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} = SI - \\mu I+  \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = 1, \\qquad I(0,x) = \\frac{I_0}{\\bar S_0},  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.8}\\]\nWe shall look for travelling wave solutions of Equation 7.8: travelling wave front for \\(S\\) and travelling wave pulse for \\(I\\). Considering \\[\nS(t,x) = s(z), \\quad I(t,x) = i(z), \\quad z = x - v t, \\quad v &gt;0\n\\] and obtain following ODEs for \\(s\\) and \\(i\\)\n\\[\n\\begin{aligned}\n&  v s^\\prime = i s  \\; , \\\\\n& i^{\\prime \\prime} + v i^\\prime + i s - \\mu i= 0\\;\n\\end{aligned}\n\\tag{7.9}\\] and corresponding boundary conditions\n\\[\n\\begin{aligned}\ns(z) \\to 1 \\qquad  z\\to + \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to + \\infty\\; ,\\\\\ns(z) \\to \\sigma \\qquad  z\\to - \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to - \\infty\\; ,\\\\\ns^\\prime(z) \\to 0\\qquad  z\\to \\pm \\infty, \\quad \\qquad i^\\prime(z) \\to 0 \\qquad z \\to \\pm \\infty \\; ,\n\\end{aligned}\n\\tag{7.10}\\] where \\(0 \\leq \\sigma &lt;1\\).\nAs before, the steady states of Equation 7.9 are given by \\[\nis =0 , \\quad i ( s- \\mu) = 0  \\quad \\Longrightarrow \\quad  i=0, \\quad s = \\text{const} \\; .\n\\]\nConsidering boundary conditions Equation 7.10 we obtain two steady states \\[\n(s_0, i_0) = ( 1, 0), \\qquad (s_0, i_0) = (\\sigma, 0) \\; .\n\\]\nLinearising equations Equation 7.9 about the steady state \\((1,0)\\) and requiring that \\(i\\) is nonnegative we obtain, as for Equation 7.2, the necessary conditions for existence of travelling wave solutions satisfying Equation 7.9 and Equation 7.10 : \\[\nv \\geq 2 \\sqrt{ 1- \\mu} \\, \\quad \\text{ and } \\quad 0 \\leq \\mu &lt; 1\\; .  \n\\]\nWe can determine the relation between density of susceptibles left behind the infection pulse and the model parameters.\nUsing substituting the first equation in Equation 7.9 in the second implies \\[\ni^{\\prime \\prime} + v i^\\prime + v s^\\prime  - \\mu i= 0\\; .\n\\tag{7.11}\\]\nIntegrating with respect to \\(z\\) yields\n\\[\ni^{\\prime } + v i + v s  - \\mu \\int i\\, dz = K= const\\; .\n\\tag{7.12}\\]\nConsider now rearranging the first equation in Equation 7.9 \\[\ni= v \\frac {s^\\prime} s, \\quad \\quad s \\neq 0 \\;\n\\]\nand obtain from Equation 7.12 \\[\ni^{\\prime } + v i + v s  - v  \\mu \\int   \\frac {s^\\prime} s\\, dz = K= const\\; .\n\\] or \\[\ni^{\\prime } + v i + v s  - v  \\mu \\ln(s) = K\\; .\n\\tag{7.13}\\]\nUsing now in Equation 7.13 boundary conditions as \\(z \\to + \\infty\\), from Equation 7.10, we can determine constant \\(K\\):\n\\[\nv    = K\\; .\n\\] Thus we have \\[\ni^{\\prime } + v i + v( s  - \\mu \\ln(s) -1)= 0\\; .\n\\tag{7.14}\\] Using now in Equation 7.14 boundary conditions as \\(z \\to - \\infty\\), see Equation 7.10, gives\n\\[\nv( \\sigma - \\mu \\ln(\\sigma) -1)= 0\\; .\n\\] and \\[\n\\frac{ \\sigma- 1}{\\ln(\\sigma)} = \\mu \\; .\n\\tag{7.15}\\] We obtain that the number of susceptibles is defined independently of the wave speed and the smaller \\(\\mu\\) corresponds to smaller \\(\\sigma\\) ( i.e. fever susceptibles survive infection wave). Thus \\(\\mu\\) measures how sever the epidemic is.\nConsidering the critical value for \\(\\mu =1\\), which in dimensional terms means \\[\n\\frac a { r S_0} = 1,\n\\] we can conclude that there exists no wave of infection\n\nif \\(S_0\\) is too low - density of foxes is too low in order to spread the disease,\n\nor if removal rate is too large - high death rate and the infection is too virulent\nor if infection rate \\(r\\) is too small - the disease is not infective enough.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Infectious disease</span>"
    ]
  },
  {
    "objectID": "SIR_PDE.html#generalisation-of-simple-sir-model",
    "href": "SIR_PDE.html#generalisation-of-simple-sir-model",
    "title": "7  Infectious disease",
    "section": "7.3 Generalisation of simple SIR model",
    "text": "7.3 Generalisation of simple SIR model\nWe developed a simple model for the passage of a wave of infection, however data of a spread of rabies in continental Europe looks quite different, i.e. comprises oscillations behind the wave front. It is likely that birth-death processes, not included in the simple model, impact dynamics of susceptibles and invectives.\nWe generalise the simple model by considering growth of susceptibles population in a logistic manner\n\\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  rSI + B S\\left( 1 - \\frac S{S_0} \\right) \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} =  r SI - a I+  D_I \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = S_0, \\qquad I(0,x) = I_0,  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.16}\\] where \\(B\\) is the intrinsic growth rate and \\(S_0\\) is the carrying capacity.\nWe can non-dimensionalize Equation 7.16 as before and obtain \\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  SI + b S\\left( 1 -  S \\right) \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} =   SI - \\mu \\,  I+   \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = 1, \\qquad I(0,x) = I_0/S_0,  & \\quad x \\in \\mathbb R,\n\\end{aligned}\n\\tag{7.17}\\] where \\[\nb= \\frac{B}{r S_0}.\n\\]\nSpatially homogeneous steady states of Equation 7.17 are \\((S^\\ast_1, I^\\ast_1) = (1,0)\\) and \\((S^\\ast_1, I^\\ast_1) = (\\mu, b(1-\\mu))\\).\nTo analyse the existence of travelling wave solutions we write equations for \\(s(z)\\) and \\(i(z)\\), where \\(s(z)=S(t,x)\\), \\(i(z) = I(t,x)\\) with \\(z= x- vt\\)\n\\[\n\\begin{aligned}\n&  -v s^\\prime =- i s  + b s ( 1-s) \\; , \\\\\n& - v i^\\prime =  i s - \\mu i +  i^{\\prime \\prime}  \\;\n\\end{aligned}\n\\] {eq-sir_tw_growth} and by introducing new variable \\(w= i^\\prime\\) obtain\n\\[\n\\begin{aligned}\n&   s^\\prime = \\frac 1 v i\\,  s  - \\frac  b v \\,  s ( 1-s) \\; , \\\\\n& i^\\prime = w, \\\\\n& w^{\\prime}= -  v w - i (s - \\mu)\\; .\n\\end{aligned}\n\\tag{7.18}\\] The system Equation 7.18 has two stationary solutions\n\\[\n(s^\\ast_1, i^\\ast_1, w^\\ast_1) = (1,0,0)\n\\] and\n\\[\n(s^\\ast_2, i^\\ast_2, w^\\ast_2) = (\\mu, b(1-\\mu),0).\n\\]\nConsidering linearisation of Equation 7.18 and computing eigenvalues of the Jabocian matrix \\[\nJ(s,i,w)= \\begin{pmatrix}\n\\frac{i}{v} - \\frac{b}{v}  + \\frac{2bs}{v} & \\frac{s}{v} & 0 \\\\\n0 & 0 & 1\\\\\n- i & \\mu - s & -v\n\\end{pmatrix}\n\\]\nevaluated at the steady states we obtain that \\[\n(s^\\ast_1, i^\\ast_1, w^\\ast_1) = (1,0,0)\n\\]\nis a saddle point and \\[\n(s^\\ast_2, i^\\ast_2, w^\\ast_2) = (\\mu, b(1-\\mu),0)\n\\]\nis a stable node for \\(\\mu &lt; \\mu^\\ast\\) and a stable spiral (focus) for \\(\\mu &gt;\\mu^\\ast\\), with some threshold value \\(\\mu^\\ast\\).\nThus we can show that a travelling wave solution exists which connects two steady states \\((1,0)\\) and \\[\n(\\mu, b(1-\\mu))\n\\] and there exists a threshold \\(\\mu=\\mu^\\ast\\) such that for \\[\n1&gt;\\mu &gt; \\mu^\\ast\n\\]\nthe approach to \\[\n(\\mu, b(1-\\mu))\n\\] is oscillatory, whereas for \\[\n0&lt;\\mu &lt; \\mu^\\ast\n\\] it is monotonic.",
    "crumbs": [
      "Multi species",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Infectious disease</span>"
    ]
  },
  {
    "objectID": "NumericalMethods.html",
    "href": "NumericalMethods.html",
    "title": "8  Numerical methods in Python",
    "section": "",
    "text": "8.1\nPython has been installed on most computers on campus and you can access it via AppsAnywhere. The icon is located on your desktop. From AppsAnywhere, please select Anaconda 3.\nHowever, you can also use your own personal computer. If you decide to do so, you will need to install Python on it. Python is free and works on Windows, Mac OS X and Linux.\nIt is strongly recommended that you download and install ​ Anaconda. Install might take 5-15 minutes. Then reboot your computer.\nOnce you have installed Anaconda you can open Spyder. This will provide you with an editor to run python codes.\nInstall a development environment (for writing and unnirn gscripts). I use Visual studio Code.\nInstall the VS Code Python extension\nCopy and paste the code below and save as DemoPythonCode.py.\nx=2\ny=2\nz=x+y\nprint(z)\n\n4\nYou should see the answer 4 printed out on the terminal.\nYou will likely now need to install some libraries",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical methods in Python</span>"
    ]
  },
  {
    "objectID": "NumericalMethods.html#python-libraries",
    "href": "NumericalMethods.html#python-libraries",
    "title": "8  Numerical methods in Python",
    "section": "8.2 Python libraries",
    "text": "8.2 Python libraries\n\nmatplotlib\nnumpp\nscipy",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical methods in Python</span>"
    ]
  },
  {
    "objectID": "NumericalMethods.html#computing-the-numerical-solution-of-a-single-pde",
    "href": "NumericalMethods.html#computing-the-numerical-solution-of-a-single-pde",
    "title": "8  Numerical methods in Python",
    "section": "8.3 Computing the numerical solution of a single PDE",
    "text": "8.3 Computing the numerical solution of a single PDE\nLet \\(c=c(x,t)\\).\nSuppose that we want to solve the PDE\n\\[\n\\frac{\\partial c}{\\partial t}=D\\frac{\\partial ^ 2 c}{\\partial x ^2}\n\\]\non the domain \\(x\\in[0,L]\\) with \\(t\\in[0,T]\\).\nThe initial condition is \\[\nc(0,x)=\\frac{c_0}{1+e^{\\gamma (x-L/2)}}\n\\] where \\(D, c_0, \\gamma \\in \\Re^+\\).\nAt \\(x=0\\) we fix the density to be \\[\nc(0,t)=c_0.\n\\] At \\(x=L\\) we impose a no-flux condition, i.e. \\[\nJ_{x=0}=-D\\frac{\\partial c}{\\partial x}\\bigg|_{x=L}=0 \\implies \\frac{\\partial c}{\\partial x}\\bigg|_{x=L}=0.\n\\]\nWe will use the finite difference method.\n\nDiscretise the independent variables\nLet \\(x_i=i\\Delta x\\) where \\(i=0,..,N_x\\). Choose \\[\nN_x \\Delta x=L \\implies \\Delta x = \\frac{L}{N_x}.\n\\]\nSimilarly, discretise time such that\n\\(t_j=j\\Delta t\\) where \\(j=0,..,N_t\\). Choose \\[\nN_t \\Delta t=T \\implies \\Delta t = \\frac{T}{N_t}.\n\\]\nDiscretise the dependent variable\nLet \\(c_{i,j}\\) represent the solution at the \\(i^{th}\\) spatial position and \\(j^{th}\\) time point.\nApproximate derivatives in the PDE using finite differences\nThe first order time derivative is approximated by\n\\[\n\\frac{\\partial c}{\\partial t}= \\frac{c_{i,j+1}-c_{i,j}}{\\Delta t}.\n\\]\nIf we use an explicit method the second order spatial derivative is approximated by\n\\[\n\\frac{\\partial^2 c}{\\partial x^2}= \\frac{c_{i-1,j}-2c_{i,j}+c_{i+1,j}}{\\Delta x ^2}.\n\\]\nInterior points in the spatial domain\nFor \\(0&lt;i&lt;N_x\\) the PDE can be expressed as\n\\[\n\\frac{c_{i,j+1}-c_{i,j}}{\\Delta t} =\nD\\frac{\\partial^2 c}{\\partial x^2}= \\frac{c_{i-1,j}-2c_{i,j}+c_{i+1,j}}{\\Delta x ^2}\n\\]\nNote that terms involving time \\(j+1\\) only appear in one position. To obtain an iterative scheme rearrange such that \\[\nc_{i,j+1}=c_{i,j} +\n\\nu \\left(c_{i-1,j}-2c_{i,j}+c_{i+1,j}\\right)\n\\]\nwhere\n\\[\n\\nu=\\frac{D \\Delta t}{\\Delta x ^2}.\n\\]\nBoundary conditions\nAt \\(x=0\\) the boundary condition is that \\(c=c_0 \\forall t\\). In the discretised system this is represented by \\[\nc_{0,j}=c_0 \\forall j.\n\\]\nAt \\(x=L\\) we need to impose the no-flux condition. Consider the second derivative \\[\n\\frac{\\partial^2 c}{\\partial x^2}\n=\n\\lim_{\\Delta x \\rightarrow 0} \\frac{\\frac{\\partial c}{\\partial x}\\bigg|_{x^+}-\\frac{\\partial c}{\\partial x}\\bigg|_{x^-}}{\\Delta x}.\n\\]\nNow impose the boundary condition at \\(x=L\\), i.e. \\[\n\\frac{\\partial c}{\\partial x}_{x^+}=0.\n\\]\nHence the Laplacian term can be represented by\n\\[\n\\frac{\\partial^2 c}{\\partial x^2}\n=\n\\lim_{\\Delta x \\rightarrow 0} \\frac{-\\frac{\\partial c}{\\partial x}\\bigg|_{ x^-}}{\\Delta x}=\n\\frac{c_{i-1,j}-c_{i,j}}{\\Delta x ^2}.\n\\]\n\n\n\n\n\n\n\nNote\n\n\n\n# Boundary condition\nSo the update rule is \\[\nc_{i,j+1}=c_{i,j}+\\nu (c_{i-1,j}-c_{i,j}), \\quad i=N_x.\n\\]\n\n\nIn Figure 8.1 an implementation of the above method is coded in Python.\n\nCode\n# Include python modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Model parameters\nT=10.0\nL=12.0\n\nD=1.2\nc_0=2.5\ngamma=3.0\n\n# Discretise independent variables\n\n# x\nN_x=30\nDelta_x=L/N_x\nx=np.linspace(0,L,N_x)\n\n# t\nN_t=600\nDelta_t=T/N_t\nt=np.linspace(0,T,N_t)\n\n# Define solution matrix\n\nc=np.zeros((N_t,N_x),dtype=float)\n\nprint(c.shape)\nprint(x.shape)\n\n# Impose initial condition\n# t=0 is the first row of the solution matrix\n\nc[0,:]=c_0/(1+np.exp(gamma*(x-L/2.0)))\n\n# Loop over time\n\nnu=D*Delta_t/(Delta_x**2)\n\n# Stability shows this condition must hold for numerical stability\nprint(nu)\nassert(nu&lt;0.5)\n\nfor i in range(0,N_t-1):\n\n    # interior nodes\n    for j in range(1,N_x-1):\n        \n        c[i+1,j]= c[i,j]+nu*(c[i,j-1]-2*c[i,j]+c[i,j+1])\n    \n    # at x=0\n    j=0\n    c[i+1,j]=c_0\n\n    # at x=L\n    j=N_x-1\n    c[i+1,j]= c[i,j]+nu*(c[i,j-1]-c[i,j])\n\n## Visualise solution\n\nfig,ax=plt.subplots(2,2,figsize=(10,10))\n\nax[0,0].imshow(c,extent=[0,L,0,T],origin='lower')\nax[0,0].set_xlim([0,L])\nax[0,0].set_ylim([0,T])\nax[0,0].set_xlabel('$x$')\nax[0,0].set_ylabel('$t$')\nax[0,0].set_title('Solution surface in 3D')\n\nax[0,1].plot(x,c[0,:])\nax[0,1].set_xlim([0,L])\nax[0,1].set_xlabel('$x$')\nax[0,1].set_title('Initial condition')\n\n\nax[1,0].plot(t,c[:,0])\nax[1,0].set_xlim([0,T])\nax[1,0].set_ylim([0,c_0*1.3])\n\nax[1,0].set_xlabel('$t$')\nax[1,0].set_ylabel('$c$')\nax[1,0].set_title('B.C. at x=0')\n\nflux_x_L=(c[:,-1]-c[:,-2])/Delta_x\nax[1,1].plot(t,flux_x_L)\nax[1,1].set_xlim([0,T])\nax[1,1].set_xlabel('$t$')\nax[1,1].set_title('B.C. at x=L')\nax[1,1].set_ylabel('Flux')\n\n\n\n#plt.axis(\"equal\")  # Ensures square axes\nplt.show()\n\n\n\n\n\n\n(600, 30)\n(30,)\n0.12499999999999997\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.1\n\n\n\nExercises:\n\nExplore numerical behaviour of the PDE solution for different value of parmeters \\(D\\), \\(c_0\\) and \\(\\gamma\\).\nConsider changing the initial condition, e.g. try \\[\nc_0(x)=\\frac{c_0}{1+(x-\\frac{L}{2})}.\n\\]\nIntroduce a line reaction term such that the governing PDE is \\[\n\\frac{\\partial c}{\\partial t}=D\\frac{\\partial ^ 2 c}{\\partial x ^2}+f(c).\n\\] Try the following cases:\n\n\n\\(f(c)=rc\\)\n\\(f(c)=rc(1-\\frac{c}{c_0})\\)\n\n\nTry changing the boundary condition at x=L such that \\[\nc(L)=0.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical methods in Python</span>"
    ]
  },
  {
    "objectID": "NumericalMethods.html#an-implicit-method",
    "href": "NumericalMethods.html#an-implicit-method",
    "title": "8  Numerical methods in Python",
    "section": "8.4 An implicit method",
    "text": "8.4 An implicit method\nHere we consider using an implicit method. The key idea is that the Laplacian is approximated using the solution at time \\(j+1\\)rather than time \\(j\\). Hence \\[\n\\frac{\\partial^2 c}{\\partial x^2}= \\frac{c_{i-1,j+1}-2c_{i,+1j}+c_{i+1,j+1}}{\\Delta x ^2}.\n\\]\nFor \\(0&lt;i&lt;N_x\\) the PDE can be expressed as\n\\[\n\\frac{c_{i,j+1}-c_{i,j}}{\\Delta t} =\nD\\frac{\\partial^2 c}{\\partial x^2}= \\frac{\\partial^2 c}{\\partial x^2}= \\frac{c_{i-1,j+1}-2c_{i,+1j}+c_{i+1,j+1}}{\\Delta x ^2}\n\\]\nTo update at time \\(j+1\\) we must now simultaneously solve for all discretised spatial points.\nLet the vector \\(\\mathbf{c}_j\\) represent the solution vector a the \\(j^{th}\\) time point. The iterative scheme can be written as\n\\[\nA\\mathbf{c}_{j+1}=\\mathbf{c}_j\n\\] where \\(A\\) is a tridiagonal matrix given by \\[\nA= \\begin{pmatrix}\n1 & 0 & 0 &0 & 0 ... & 0 \\\\   \n0  &-\\nu & 1+2\\nu &-\\nu & 0 & . . . & 0 \\\\\n0  & 0 &-\\nu & 1+2\\nu &\\nu &  . . . & 0 \\\\\n&.& .& .& .& . &. & .\\\\\n0 & 0& 0 & 0 & 0 &-\\nu & 1+2\\nu & -\\nu  \\\\\n0& 0 & 0& 0 & 0 & 0 &-\\nu & 1+\\nu  \\\\\n\\end{pmatrix}\n\\]\nThe boundary conditions are represented by the first and last rows in the matrix \\(A\\).\nAfter computing A and calculating its inverse the solution can be computed using a matrix multiplication\n\\[\n\\mathbf{c}_{j+1}=A^{-1}\\mathbf{c}_j\n\\]\n\nCode\n# Include python modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Model parameters\nT=10.0\nL=12.0\n\nD=1.2\nc_0=2.5\ngamma=3.0\n\n# Discretise independent variables\n\n# x\nN_x=30\nDelta_x=L/N_x\nx=np.linspace(0,L,N_x)\n\n# t\nN_t=600\nDelta_t=T/N_t\nt=np.linspace(0,T,N_t)\n\n# Define solution matrix\n\nc=np.zeros((N_t,N_x),dtype=float)\n\nprint(c.shape)\nprint(x.shape)\n\n# Impose initial condition\n# t=0 is the first row of the solution matrix\n\nc[0,:]=c_0/(1+np.exp(gamma*(x-L/2.0)))\n\n# Loop over time\n\nnu=D*Delta_t/(Delta_x**2)\n\n# Tridiagonal matrix A\nA = np.zeros((N_x, N_x))\nfor i in range(N_x):\n    A[i, i] = 1 + 2*nu\n    if i &gt; 0:\n        A[i, i-1] = -nu\n    if i &lt; N_x-1:\n        A[i, i+1] = -nu\n\nA[0,0]=1\nA[0,1]=0\n\nA[-1,-1]=1+nu\nA[-1,-2]=-nu\n\nA_inv=np.linalg.inv(A)\n\nfor i in range(0,N_t-1):\n    \n    new_sol=A_inv@(c[i,:].T).T\n    # interior nodes\n    c[i+1,:]=new_sol\n    c[i+1,0]=c_0 # enforce the dirichlet bc\n## Visualise solution\n\nfig,ax=plt.subplots(2,2,figsize=(10,10))\n\nax[0,0].imshow(c,extent=[0,L,0,T],origin='lower')\nax[0,0].set_xlim([0,L])\nax[0,0].set_ylim([0,T])\nax[0,0].set_xlabel('$x$')\nax[0,0].set_ylabel('$t$')\nax[0,0].set_title('Solution surface in 3D')\n\nax[0,1].plot(x,c[0,:])\nax[0,1].set_xlim([0,L])\nax[0,1].set_xlabel('$x$')\nax[0,1].set_title('Initial condition')\n\n\nax[1,0].plot(t,c[:,0])\nax[1,0].set_xlim([0,T])\nax[1,0].set_ylim([0,c_0*1.3])\n\nax[1,0].set_xlabel('$t$')\nax[1,0].set_ylabel('$c$')\nax[1,0].set_title('B.C. at x=0')\n\nflux_x_L=(c[:,-1]-c[:,-2])/Delta_x\nax[1,1].plot(t,flux_x_L)\nax[1,1].set_xlim([0,T])\nax[1,1].set_xlabel('$t$')\nax[1,1].set_title('B.C. at x=L')\nax[1,1].set_ylabel('Flux')\n\n\n\n#plt.axis(\"equal\")  # Ensures square axes\nplt.show()\n\n\n\n\n\n\n(600, 30)\n(30,)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.2",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Numerical methods in Python</span>"
    ]
  },
  {
    "objectID": "linearstablityanalysis.html",
    "href": "linearstablityanalysis.html",
    "title": "9  Linear stability analysis of a system of nonlinear ODES",
    "section": "",
    "text": "Consider a system of ODEs\n\\[\\begin{equation*}\n\\frac{du}{dt} = f(u) \\quad \\text{ with } \\quad u \\in \\mathbb R^m\\quad  \\text{ and }\\quad  t \\in \\mathbb R.\n\\end{equation*}\\]\nAs an example consider \\(m=2\\): \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{du_1}{dt} =F(u_1, u_2) ,\\\\\n\\dfrac{du_2}{dt} =G(u_1, u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.1}\\]\n\\((u_1, u_2) = (u^\\ast_1, u^\\ast_2)\\) is the steady state of the system Equation 9.1, i.e. \\[\n\\dfrac{du_1}{dt} = 0\n\\] and \\[\n\\dfrac{du_2}{dt} = 0\n\\].\nTo determine the behaviour of the solution near a steady state we consider \\[\nu_1(t) = u^\\ast_1 + \\bar u_1(t), \\quad  u_2(t) = u^\\ast_2 + \\bar u_2(t)\n\\] \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d(u^\\ast_1+ \\bar u_1)}{dt} =F(u^\\ast_1+ u_1, u^\\ast_2+ \\bar u_2) ,\\\\\n\\dfrac{d(u^\\ast_2+\\bar u_2)}{dt} =G(u^\\ast_1+u_1,u^\\ast_2+\\bar u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.2}\\]\nThen using the fact that \\((u^\\ast_1, u^\\ast_2)\\) is a steady state and applying Taylor series expansion about \\(( u^\\ast_1, u^\\ast_2)\\) and assuming that\n\\[\n\\sup_{t}|\\bar u_1(t)| \\ll 1, \\sup_{t}|\\bar u_2(t)|\\ll 1\n\\] (small perturbations of the steady state) we have \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d  \\bar u_1}{dt} =F(u^\\ast_1, u^\\ast_2) +\\dfrac{\\partial F}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial F}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\, \\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2) ,\\\\\n\\dfrac{d \\bar u_2}{dt} =G(u^\\ast_1,u^\\ast_2)+ \\dfrac{\\partial G}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial G}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\,\\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.3}\\]\nThus since \\((u^\\ast_1, u^\\ast_2)\\) is a steady state, i.e. \\(F(u^\\ast_1, u^\\ast_2) =0\\) and \\(G(u^\\ast_1, u^\\ast_2) =0\\) (ignoring negligibly small higher order terms) we obtain system of linearised equations \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{d  \\bar u_1}{dt} \\\\\n\\dfrac{d \\bar u_2}{dt}\n\\end{pmatrix} = J( u^\\ast_1, u^\\ast_2) \\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\end{aligned}\n\\tag{9.4}\\] where the Jacobian matrix \\(J(u^\\ast_1, u^\\ast_2)\\) is defined as \\[\nJ( u^\\ast_1, u^\\ast_2) = \\begin{pmatrix}\n\\dfrac{\\partial F(u^\\ast_1, u^\\ast_2) }{\\partial u_1}\\; \\; & \\dfrac{\\partial F(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\\\\\n\\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_1} & \\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\n\\end{pmatrix}\n\\] Therefore the behaviour of the nonlinear system Equation 9.1 near the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by solutions of system of linear ODEs Equation 9.4.\nSince Equation 9.4 is linear we can write the general solution of (eqsystem_ode14?) \\[\\begin{equation}\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix} = e^{\\lambda_1 t} \\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix}   +\ne^{\\lambda_2 t} \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\end{equation}\\] where \\(\\lambda_1\\) and \\(\\lambda_2\\) are eigenvalues of Jacobian matrix \\(J( u^\\ast_1, u^\\ast_2)\\) and \\[\n\\phi=\\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix} \\quad \\textrm{and} \\quad  \\psi= \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\] are corresponding eigenvectors.\nDenote \\[\\bar u=\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\].\nIf both \\(\\lambda_{1,2} \\neq 0\\) then the stability of the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by the real part of the eigenvalues \\(\\lambda_{1,2}\\).\n\nIf either \\(\\mathcal Re (\\lambda_1)&gt;0\\) or \\(\\mathcal Re (\\lambda_2)&gt;0\\) then\n\\(|\\bar u(t)| \\to +\\infty\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is unstable.\nIf \\(\\mathcal Re (\\lambda_1)&lt;0\\) and \\(\\mathcal Re (\\lambda_2)&lt;0\\) then\n\\(|\\bar u(t)| \\to 0\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is stable.\nIf \\(\\lambda_1=0\\) or \\(\\lambda_2=0\\) we have to consider higher order terms.\n\nDenote \\(\\beta = \\textrm{tr} (J( u^\\ast_1, u^\\ast_2))\\) and \\(\\gamma= \\det(J( u^\\ast_1, u^\\ast_2))\\). Then the characteristic (eigenvalue) equation for \\(J( u^\\ast_1, u^\\ast_2)\\) is \\[\n\\lambda^2 - \\beta \\lambda + \\gamma = 0 \\; , \\quad  \\lambda_{1,2} = \\frac{ \\beta \\pm \\sqrt{ \\beta^2 - 4 \\gamma}} 2.\n\\] Then\n\nIf \\(\\gamma &lt;0\\) we have two real eigenvalues with different signs, i.e. \\(\\lambda_1 &lt; 0 &lt; \\lambda_2\\). Thus \\((u^\\ast_1, u^\\ast_2)\\) is a saddle.\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 \\geq 4\\gamma\\) we have two real eigenvalues with the same sign. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a node.\n\nif \\(\\beta &gt;0\\) then \\(\\lambda_2 &gt; \\lambda_1 &gt;0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable node.\nif \\(\\beta &lt;0\\) then \\(\\lambda_1 &lt; \\lambda_2 &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable node.\n\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 &lt; 4\\gamma\\) we have two complex conjugate eigenvalues. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a focus (spiral).\n\nif \\(\\beta &gt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &gt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable focus\nif \\(\\beta &lt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable focus.\nIf \\(\\beta =0\\) then for linear system we have a centre, but in general we have no information on the behaviour of the nonlinear system near the steady state \\((u^\\ast_1, u^\\ast_2)\\).\n\n\n** Insert figure phase plane **",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear stability analysis of a system of nonlinear ODES</span>"
    ]
  }
]