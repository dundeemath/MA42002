[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA42002",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "conservationequations.html#introduction",
    "href": "conservationequations.html#introduction",
    "title": "1  Conservation equations",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nMany biological systems are spatio-temporal, i.e. concentrations of biochemicals, densities of cells etc. depend on spatial position as well time. To describe such cases we must relax a major assumption that was made in Mathematical Biology I (MA32009): spatial homogeneity. This leads us to describe biological system using partial differential equations."
  },
  {
    "objectID": "conservationequations.html#notation",
    "href": "conservationequations.html#notation",
    "title": "1  Conservation equations",
    "section": "1.2 Notation",
    "text": "1.2 Notation\nThroughout this course, we will study {} of biological systems and as such we will consider \\(x \\in \\mathbb R^n\\), \\(t \\in [0, \\infty)\\) and functions \\(c: \\mathbb R^n \\times [0, \\infty) \\to \\mathbb R\\), where \\(n=1,2,3\\). For example:\n\n\\(c(t,x)\\) - the density of a population [number per volume] at time \\(t\\) and position \\(x\\) (at \\((t,x)\\))\n\\(c(t,x)\\) - the concentration of a substance (chemicals, particles) [mass per volume] at time \\(t\\) and position \\(x\\) (at \\((t,x)\\))\n\\(c(t,x)\\) - the temperature at \\((t,x)\\)."
  },
  {
    "objectID": "conservationequations.html#derivation-of-conservation-equations",
    "href": "conservationequations.html#derivation-of-conservation-equations",
    "title": "1  Conservation equations",
    "section": "1.3 Derivation of conservation equations",
    "text": "1.3 Derivation of conservation equations\nA conservation equation is the most fundamental statement through which changes in the distribution of the density (or concentration, temperature) is described. \\[\n\\begin{pmatrix}\n\\text{rate of change}\\\\\n\\text{ in the population density}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{spatial movement}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{birth, growth, death},\\\\\n\\text{production or degradation}\\\\\n  \\text{due to chemical reactions}\n\\end{pmatrix}\n\\]\n\n1.3.1 Spatially homogeneous model\nIn this introductory first section, we neglect spatial movement and consider examples of growth/death and chemical reactions.\n\n1.3.1.1 Modelling the growth of bacteria in a petri dish (flask) containing nutrient medium\nBacteria are found to reproduce by undergoing successive cell divisions.\nDenote by \\(N(t)\\) - bacterial density observed at time \\(t\\) [number of cells per volume].\nOver a period of one unit time a single bacterial cell divides, then its daughter cells divide, and so forth, leading to a total of \\(K\\) new bacterial cells.\nDefine \\(K\\) - rate of reproduction per unit time, \\(K&gt;0\\), and \\[\n\\begin{aligned}\nN(t+\\Delta t) &=  \\quad N(t)   + \\quad  &K N(t) \\Delta t \\\\\n\\text{ density at time } t + \\Delta t & \\quad   \\text{ density at time } t  & &\\text{ increase in density due to}\\\\\n&& &\\text{reproduction during}\\\\\n&& &\\text{ the time interval } \\Delta t\n\\end{aligned}\n\\tag{1.1}\\] Assuming that \\(N\\) is differentiable, dividing Equation 1.1 by \\(\\Delta t\\) and tailing limit as \\(\\Delta t \\to 0\\) imply \\[\n\\frac{dN}{dt} = K N\n\\] {eq-n_2} The growth rate \\(K\\) can take several forms e.g.  * \\(K = \\text{constant}\\) * \\(K = K(t)\\) time-dependent * \\(K= K(N(t))\\) depends on bacterial density * \\(K= K(c(t)):= \\kappa c(t), \\;\\; (\\text{with} \\;\\; \\kappa &gt;0 \\;\\; \\text{a constant}\\)), which depends on the nutrient concentration \\(c(t)\\) at time \\(t\\) i.e. \\(K\\) depends on the available resources\n\n\n1.3.1.2 Logistic growth via depleting nutrient source\nWe denote by \\(\\alpha\\) the units of nutrients consumed during the production of one unit of population increment (Note: the quantity \\(Y= 1/\\alpha\\) is called the yield) and obtain \\[\n\\begin{aligned}\n\\frac{dN}{dt} &= K(c) N = \\kappa cN,  \\\\\n\\frac{ dc}{dt} &= - \\alpha \\frac{dN}{dt} = - \\alpha   \\kappa c N,  \n\\end{aligned}\n\\tag{1.2}\\] with initial conditions \\[\nN(0) = N_0 \\quad \\textrm{and}  \\quad  c(0)= c_0.\n\\]\nWe can determine the nutrient concentration by integrating the second of Equation 1.2 with respect to time and obtaining \\[\nc(t)  = - \\alpha N(t) + c(0)+ \\alpha N(0) = - \\alpha N(t) + \\beta,\n\\tag{1.3}\\] where \\(\\beta=c_0 +\\alpha N_0\\). Using Equation 1.3 in Equation 1.2 we obtain the logistic growth equation \\[\n\\frac{dN}{dt} = \\kappa ( \\beta- \\alpha N)  N, \\qquad  N(0)= N_0\\quad  \n\\tag{1.4}\\] Here we have \\(K=K(N) = \\kappa (\\beta - \\alpha N)\\).\nThe last equation can be rewritten as \\[  \n\\frac{dN}{dt} = \\rho  N \\,  (1 - \\frac N B)  \\qquad \\quad N(0)= N_0,\n\\tag{1.5}\\] where \\(\\rho = \\kappa \\beta\\) is the {} and \\(B = \\frac \\beta \\alpha\\) is the {}. The solution of ?eq-n_5 is given by \\[\nN(t)= \\frac{ N_0 K} { N_0 + (B-N_0) e^{-\\rho t}} \\; .\n\\]\n\n\n1.3.1.3 Death/decay\nIn addition to growth, we may assume that cells die at rate \\(d\\) and the simple growth ?eq-n_2 can be generalised to \\[\n\\frac{dN}{dt} = KN - d N,\n\\] where \\(d\\) is the mortality (death) rate.\n\n\n1.3.1.4 Competition\nThe fact that individuals compete for food, habitat (i.e. space) or any limited resources, means that an increase in the net mortality of the population may be observed under crowded conditions \\[\n\\frac{dN}{dt} = KN - d_1 N^2 ,\n\\] where \\(d=d_1N\\) is the mortality (death) rate and is proportional to the population density.\n\n\n1.3.1.5 Chemical reactions\n\nMost biochemical reactions involve proteins called {} which act as catalysts of chemical reactions. Enzymes react selectively on specific compounds called {}.\nA substrate \\(S\\) reacts, in a {}, with an enzyme \\(E\\) to form a complex \\(SE\\) or \\(C\\), which in turn is converted into a product \\(P\\). This may be described as follows:\n\n\n\n\nflowchart LR\n  S[S]--+--&gt; E(E)\n  E --&gt; C{C}\n  C --&gt; E\n  C --&gt; D[E]\n  D --&gt; P[P]\n\n\n\n\n\n\nwhere \\(k_{-1}, k_1\\) and \\(k_2\\) are rate constants (\\(&gt;0\\)) determining the rate of the reaction i.e. how fast the reaction proceeds.\nThe law of mass action states that the rate of a reaction is proportional to the product of the concentrations of the reactants. (Note: The law of mass action is only an approximation, but it is a very good one for dilute solutions of the chemical concerned.)\nWe denote the concentrations $ [ ; ]$ as follows: \\[\ns=[S], \\quad e=[E], \\quad c = [SE], \\quad p =[P]\n\\] and obtain \\[\n\\begin{aligned}\n\\frac{ds}{dt}& = - k_1 es + k_{-1} c, \\qquad && s(0) = s_0, \\\\\n\\frac{de}{dt} &= - k_1 es + k_{-1} c + k_2 c, \\qquad && e(0) = e_0, \\\\\n\\frac{dc}{dt} &=  k_1 es - k_{-1} c - k_2 c, \\qquad && c(0) = 0,\\\\\n\\frac{dp}{dt} &=  k_{2} c, \\qquad && p(0) = p_0.\n\\end{aligned}\n\\] A study of this system is given in Homework 1.\n\n\n\n1.3.2 Spatial movement\nConsider a spatial domain \\(V\\). A conservation equation can be written either in terms of the mass or number of particles of a species as follows:\n\\[\n\\begin{pmatrix}\n\\text{rate of change of}\\\\\n\\text{number of particles} \\\\\n\\text{per unit time }\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{rate of entry of}\\\\\n\\text{particles into $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n- \\begin{pmatrix}\n\\text{rate of exit of }\\\\\n\\text{particles from $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{rate of degradation}\\\\\n\\text{or creation of particles }\\\\\n  \\text{in $V$ per unit time}\n\\end{pmatrix}\n\\]\n\n1.3.2.1 One-dimensional conservation equations\nAssume\n\nmotion takes place in a one-dimensional domain (e.g. a long very thin tube)\nthe tube has a constant cross-section area\n\nLet \\(x\\) be the distance along the tube relative to an origin. We shall consider the interval \\((x, x+\\Delta x)\\), for some \\(\\Delta x &gt;0\\), and a domain \\(V= (x, x+ \\Delta x) \\times S\\), where \\(S\\) is the cross-section of the tube with the constant area \\(A=|S|\\).\n\n\\(c(t,x)\\) - concentration of particles (number of particles per unit volume) at time, \\(t\\), and position, \\(x\\)\n\\(J(t,x)\\) - flux of particles per unit time and unit area (number of particles crossing a unit area in the positive \\(x\\)-direction per unit time)\n\\(f(t,x,c(t,x))\\) - source/sink (number of particles created or destroyed per unit volume and unit time)\n\nWe consider \\(S\\) to be very small and \\(c(t,x)\\) is assumed to be constant in \\(S\\) (independent of \\(y\\) and \\(z\\)). We also assume that \\(c\\) is continuously differentiable with respect to \\(t\\).\nThe volume of \\(V\\) is \\(A \\Delta x\\) and number of particles is given by \\[\n\\int_x^{x+\\Delta x} c(t, \\tilde x) \\,  d \\tilde x A.\n\\]\nThen the conservation equation for the number of particles in the volume \\(V\\) is given by \\[\n\\frac{\\partial}{\\partial t} \\int_x^{x+\\Delta x} c(t,\\tilde x) A d\\tilde x = J(t,x) \\, A  - J(t,x+\\Delta x) \\, A +\\int_x^{x + \\Delta x}  f(t,\\tilde x,c(t, \\tilde x))\\,  A \\, d \\tilde x.\n\\tag{1.6}\\]\ni.e. the flux that changes the total population in \\(V\\) is that entering through the cross-section at \\(x\\) and leaving through the cross-section at \\(x+\\Delta x\\) (it is assumed that there no flux through the external surface of the tube). Assuming \\(c\\) and \\(f\\) to be sufficiently smooth (continuous in \\(x\\)) and applying The Mean Value Theorem in Equation 1.6, we obtain \\[\n\\frac{\\partial}{\\partial t} c(t,\\xi) A \\Delta x = J(t,x) \\, A  - J(t,x+\\Delta x) \\, A +  f(t,\\eta,c(t, \\eta))\\,  A \\Delta x, \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.7}\\]\nDividing Equation 1.6 by \\(A \\, \\Delta x\\) yields \\[\n\\frac{\\partial}{\\partial t} c(t,\\xi)  = - \\frac  {J(t,x+\\Delta x) - J(t,x)} { \\Delta x} + f(t,\\eta,c(t,\\eta)), \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.8}\\] Assuming that \\(J\\) is differentiable with respect to \\(x\\) and taking the limit as \\(\\Delta x \\to 0\\) (and using the definition of partial derivatives) we obtain a one-dimensional conservation (balance) equation: \\[\n\\frac{\\partial}{\\partial t} c(t,x)  = - \\frac  {\\partial} { \\partial x} J(t,x) + f(t,x,c(t,x)).\n\\tag{1.9}\\]\n\n\n1.3.2.2 Conservation equations in \\(\\mathbb R^n\\)\nLet \\(V \\subset \\mathbb R^n\\) be an arbitrary bounded domain (i.e. satisfying the conditions of the divergence theorem) and let \\(S\\) be the surface enclosing \\(V\\), i.e \\(S = \\partial V\\).\n\n\\(c(t,x)\\) – concentration of particles at \\(x\\in V\\) and \\(t&gt;0\\) (number of particles per unit volume)\n\\(J(t,x)\\) – flux vector of particles across \\(V\\) (number of particles per unit area and per unit time entering or leaving through \\(S\\) (the boundary of \\(V\\)).\n\\(f(t,x,c(t,x))\\) - source/sink term (number of particles created or destroyed per unit volume and per unit time)\n\nThen the conservation equation reads \\[\n\\frac{\\partial}{\\partial t} \\int_V c(t,x) \\, dx = - \\int_{S} J(t,x) \\cdot {\\mathbf{n}} \\, d\\sigma + \\int_V f(t,x,c),\n\\] where \\(\\mathbf{n}\\) is the outward normal vector to \\(S\\). The normal component of the flux \\(J\\) on \\(S\\) leads to a change of number of particles (of mass) in \\(V\\). Applying the divergence theorem, i.e. \\[\n\\int_S J \\cdot {\\mathbf{n}} \\, d\\sigma = \\int_V \\text{ div} J \\, dx,\n\\] and using the fact that \\(V\\) is independent of time \\(t\\) we obtain \\[\n\\int_V \\Big(\\frac{\\partial}{\\partial t} c(t,x) + \\nabla \\cdot  J(t,x) -  f(t,x,c)\\Big) dx.\n\\] Since \\(V\\) can be chosen arbitrary we get the conservation equation in \\(\\mathbb R^n\\) (or a subdomain \\(\\Omega \\subset \\mathbb R^n\\))\n\\[\n\\frac{\\partial}{\\partial t} c(t,x) =  - \\nabla \\cdot  J(t,x)+  f(t,x,c), \\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0.\n\\tag{1.10}\\]\n\n\n1.3.2.3 Types of flux terms\n\nFickian Diffusion\nDiffusion is an important and ‘’metabolically cheap’’ transport mechanism in biological systems. It can be also viewed as the random motion of individual molecules.\n\\[\n{\\mathbf{J}} = - D\\nabla c,\n\\tag{1.11}\\] where \\(D\\) is the diffusion coefficient. \\(D\\) depends on the size of the particles, the type of solvent, the temperature, .\nThen applying Equation 1.11 in Equation 1.10 we obtain reaction-diffusion equation \\[\n\\frac{\\partial}{\\partial t} c =  - \\nabla\\cdot ( - D \\nabla c(t,x))+  f(t,x,c) = \\nabla \\cdot ( D \\nabla c) + f(t,x,c),\n\\quad x\\in \\mathbb R^n, \\,  \\, t &gt;0.\n\\tag{1.12}\\]\n\nIf \\(D\\) is a constant we can write \\[\n  \\frac{\\partial}{\\partial t} c(t,x) =  D \\Delta c(t,x) + f(t,x,c),\n  \\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0,\n\\]\nwhere \\[\n\\Delta c = \\sum\\limits_{j=1}^n \\dfrac{\\partial^2 c}{\\partial x_j^2}.\n\\]\n\nNonlinear diffusion \\[\nD = D(c) , \\qquad \\text{ e.g. }\\,   D(c)= D_0 c^m, \\quad D_0 &gt;0,\n\\] and \\[\n  \\frac{\\partial}{\\partial t} c = D_0 \\nabla\\cdot (c^m \\nabla c) + f(t,x,c),\n\\quad x\\in \\mathbb R^n,  \\quad t &gt;0.\n\\tag{1.13}\\]\nConvection or Advection \\[\nJ = \\textbf{v} c,\n\\] where \\(\\textbf{v}\\) is a velocity vector. Hence \\[\n\\frac{\\partial}{\\partial t} c(t,x) = - \\nabla\\cdot (\\textbf{v}(t,x) c(t,x))  + f(t,x,c),\n\\quad x\\in \\mathbb R^n,   \\quad t &gt;0.\n\\tag{1.14}\\]\nIf \\(\\textbf{v}\\) is constant or \\(\\nabla \\cdot \\textbf{v} = 0\\), then \\[\n\\frac{\\partial}{\\partial t} c = - \\textbf{v} \\nabla c  + f(t,x,c)\n\\quad x\\in \\mathbb R^n, \\,  \\quad t &gt;0.\n\\]\nTaxis - directed movement in response to an external chemical or physical signal.\n\nchemotaxis - movement directed by a chemical gradient\nhaptotaxis - movement directed by a gradient in density, adhesion\n\nIn the presence of some chemoattractant \\(a(t,x)\\) we have \\[\n  {\\mathbf{J}} = \\chi(a) c \\nabla a,  \n  \\] where \\(\\chi(a)\\) is a `model-specific’ function of \\(a\\) defining the sensitivity to the signal, and the conservation equation reads \\[\n  \\frac{\\partial}{\\partial t} c(t,x) = -\\nabla \\cdot (\\chi(a) c(t,x) \\nabla a )  + f(t,x,c),\n  \\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n   \\tag{1.15}\\]\n\nWe can have any combination of fluxes, depending on the biological system. For example, chemotaxis and diffusion\n\\[\n\\frac{\\partial}{\\partial t} c = D \\Delta c -\\nabla \\cdot (\\chi(a) c \\nabla a )  + f(t,x,c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0,\n\\tag{1.16}\\] which can be augmented by an equation for the (diffusible) chemoattractant \\(a\\) \\[\n\\frac{\\partial}{\\partial t} a = D \\nabla^2 a + g(t,x,a, c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n\\tag{1.17}\\] Equation 1.16 and Equation 1.17 form a system of equations, a so-called chemotaxis system.\n\n\n\n1.3.3 Boundary conditions (B.C.)\n\nInfinite domain (e.g. \\((-\\infty, \\infty)\\), \\(\\mathbb R^2\\), \\(\\mathbb R^3\\) ):\n\nthe density is not influenced by the boundary \\[\nc(t,x) \\to 0 \\qquad \\text{ as } \\qquad \\|x\\| \\to \\infty \\quad  \\text{decay at infinity}\n\\]\n\nPeriodic B.C.\n\n\\(L\\)-periodic function: \\(c(t,x) = c(t,x+L)\\) for any \\(x\\) in the domain\nConsider a domain \\((0,L)\\). \\[\nc(t,0) = c(t,L) \\qquad  \\text{ periodic boundary conditions}\n\\]\n\nDirichlet B.C.\n\ndensity (concentration) is fixed at the boundary\nIn the \\(1\\)-dim domain \\((0,L)\\) \\[\nc(t,0) = c_1, \\quad  c(t,L) = c_2\n\\] can consider two reservoirs placed at the ends of the domain, that are held at constant densities (concentrations) \\(c_1\\) and \\(c_2\\), respectively.\nFor a domain \\(\\Omega\\subset \\mathbb R^n\\) we have \\[\nc(t,x) = c_D(t,x) \\qquad  x\\in  \\partial \\Omega, \\, \\, t\\geq 0 \\; .\n\\]\n\nNo-flux (homogeneous Neumann) B.C.\n\nparticles cannot escape from the domain\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c  \\cdot {\\mathbf{n}}  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] In one-dimensional domain \\((0,L)\\) \\[\n\\frac{\\partial c(t,x)}{\\partial x} = 0 \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Neumann B.C.\n\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c \\cdot {\\mathbf{n}} = g(t,x)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with a given function \\(g\\) ( \\(g\\) can also be a constant).\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(t,x)}{\\partial x} = g(t,x)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nHomogeneous Robin B.C. \\[\nD\\nabla c(t,x)  \\cdot {\\mathbf{n}}  + k c(t,x)  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(t,x)}{\\partial x}  + k c(t,x) = 0  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Robin B.C. \\[\nD\\nabla c(t,x)  \\cdot {\\mathbf{n}}  + k c(t,x)  = g(t,x)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\) and given function \\(g\\) ( \\(g\\) can also be a constant).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(t,x)}{\\partial x}  + k c(t,x) = g(t,x)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\nRemark We can also have different types of boundary conditions at different parts of the boundary of the considered domain.\n\n\n1.3.4 Initial conditions\nFor a conservation equation defined in a domain \\(\\Omega \\subset \\mathbb R^n\\), \\(n=1,2,3\\), additionally to boundary conditions we need to define an initial concentration, i.e. initial condition \\[\nc(0,x) = c_0(x) , \\qquad x \\in \\Omega  \\; .\n\\]\n\n\n1.3.5 Formulating a model\nThe models that we will consider will comprise one or more partial differential equations together with boundary and initial conditions. The right-hand side of the PDEs willbe dervied based upon assumptions about a particular biological system under study. We will consider exploratory numerical solutions and then study qualitative behaviours of the solutions using analyses familiar from MA32009 (e.g. steady state analysis, linear stability analysis).\n\n\n1.3.6 Nondimensionalization\nThe variables and parameters in a biological or physical model have units:\n\n\\(\\#\\textrm{velocity} = \\dfrac{\\#\\text{length }}{\\#\\text{time}}\\)\n\\(\\# \\textrm{concentration} = \\dfrac{ \\text{num.moles}}{\\#\\text{volume}}\\)\n\\(\\#\\text{density} = \\dfrac{\\text{number of particles}}{\\# \\text{volume}}\\)\n\\(\\#\\text{diffusion coefficient} = \\dfrac{\\#\\text{length}^2}{\\#\\text{time}}\\)\n\\(\\#\\text{source/sink (reaction term)} = \\dfrac{\\#\\text{concentration (or density)}}{\\#\\text{time}}\\)\n\\(\\#\\text{flux} = \\dfrac{\\text{mass (number) of particles}}{\\#\\text{area} \\times \\# \\text{time}}\\)\n\nIt is standard to non-dimensionalize a system of differential equations by scaling or non-dimensionalizing both the dependent and independent variables in the model."
  },
  {
    "objectID": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "href": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "2.1 One-dimensional diffusion equations",
    "text": "2.1 One-dimensional diffusion equations\nIn order to provide some insight into the structure of solutions of reaction-diffusion equations, we make an initial simplifying assumption i.e. we assume \\(f(c)=0\\), and obtain the linear diffusion equation (or heat equation):\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2},   \\quad x\\in \\mathbb R, \\, \\, t &gt;0,\n\\tag{2.1}\\] This equation is used to model the evolution of the concentration of a chemical in a long thin tube, or the temperature of a long thin rod.\nWe assume that the initial condition for our species \\(c\\) is located in one point \\(x=0\\) i.e.  \\[\nc(x_0 , 0) = \\delta_0(x)\\qquad x \\in \\mathbb R,\n\\tag{2.2}\\] where \\(\\delta_0\\) is a Dirac delta distribution (Dirac measure) satisfying \\[\n\\int_{-\\infty}^{+\\infty} \\delta_0(x) = 1 \\quad \\text{ and } \\quad \\int_{-\\infty}^{+\\infty} f(x) \\delta_0(x) = f(0) , \\text{ for continuous } f.\n\\]\n\n2.1.1 Fundamental solution\nIt can be shown that the sequence of functions \\(\\{ \\phi_\\varepsilon(x) \\}\\) given by \\[\n\\frac 1{\\varepsilon \\sqrt{\\pi} } e^{ - \\frac{x^2}{ \\varepsilon^2}}\n\\] converges to \\(\\delta_0(x)\\) as \\(\\varepsilon \\to 0\\) (in the sense of distributions or generalized functions).\nThen for the diffusion Equation 2.1 with initial condition Equation 2.2, it can be shown that the explicit (analytic) solution is given by \\[\nc(t,x) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ x^2}{ 4Dt} \\right).\n\\tag{2.3}\\] This is known as the fundamental solution of the diffusion equation in \\(\\mathbb R\\).\nWe also have, for general initial condition \\(c(x, 0) = c_0(x)\\) for \\(x\\in \\mathbb R\\): \\[\nc(t,x) = \\int_{-\\infty}^{+\\infty} \\frac{c_0(y)}{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ (x-y)^2}{ 4Dt} \\right) dy.\n\\]\nThis result can be generalized to \\(\\mathbb R^n\\times (0,\\infty)\\) where the fundamental solution has the form \\[\nc(x,t) =  \\frac 1{(4 \\pi D t)^{n/2}} \\exp \\left( - \\frac{ (x_{1}^{2} + x_{2}^{2} + \\ldots + x_{n}^{2})}{ 4Dt} \\right).\n\\]\n\n\n2.1.2 Numerical solution\nIn Figure 2.1 we compute a numerical solution of the diffusion equation and compare it with the exact solution given by Equation 2.3.\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=10\nL=10\n\nN_x=100\nN_t=120\n\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\n\nD=1.5\nepsilon=0.1\n\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef diffusionPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n\n\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    i=N_x-1\n\n    f[i]=D/dx**2*(u[i-1]-u[i])\n    return f  \n\nsol=odeint(diffusionPDErhs,u_0,t)\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62542/4177307358.py:42: RuntimeWarning: divide by zero encountered in divide\n  c_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62542/4177307358.py:42: RuntimeWarning: invalid value encountered in multiply\n  c_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\n\n\n\n\n(a) Numerical solution of diffusion equation\n\n\n\n\n\n\n\n(b)\n\n\n\nFigure 2.1: ?(caption)\n\n\n\n\n2.1.3 Key properties of the (linear) diffusion equation (heat equation)\n\nThe solution is infinitely smooth.\nThe solution \\(c(x,t)\\) stays positive for all \\(t &gt;0\\) and \\(x \\in \\mathbb R\\) if \\(c(x,0) &gt;0\\) for \\(x \\in \\mathbb R\\).\nThe solution ``propagates’’ with infinite speed i.e. for any \\(t &gt; 0\\), the solution is everywhere in \\(\\mathbb R\\).\nIf we change the initial data \\(c(x,0)\\) (continuously) then the solution also changes (continuously).\n\n\n\n2.1.4 Diffusive transit time\nWe now demonstrate the connection between time and space in diffusion equations. Consider a domain \\(V \\subset \\mathbb R^n \\;, n = 1,2,3.\\), and particles that are entering \\(V\\) and are being removed from \\(V\\). Define\n\\(N\\) - total number of particles in \\(V\\)\n\\(F\\) - total number of particles entering \\(V\\) per unit time\n\\(\\lambda\\) - average removal rate of particles from \\(V\\)\n\\(\\tau = \\frac 1\\lambda\\) - transit time or average time of residency in \\(V\\)\nRegardless of spatial variations, we can make the following general statement regarding the total number of particles in \\(V\\), where we assume a constant entry rate \\(F\\) and a constant removal rate \\(\\lambda\\) at some sink in \\(V\\):\n\\[\n\\frac{dN}{dt} = \\text{entry rate} - \\text{removal rate} = F - \\lambda N.\n\\]\nAt steady state (\\(dN/dt = 0\\)) we obtain \\[\nMissing content here. Check notes!\n\\]\nConsider particles of concentration \\(c(x,t)\\) diffusing with constant diffusion \\(D\\) in a one-dimensional domain \\((0,L)\\), with a constant concentration at one boundary and removed by a sink at the other boundary. At steady-state, the equation governing the concentration is given by:\n\\[\nD \\frac{ d^2 c}{dx^2} = 0  \\quad \\text{ in } (0,L), \\quad c(0) = C_0, \\, c(L) = 0 .\n\\]\nThe solution (Exercise) is: \\[\nc(x) = C_0 \\left( 1- \\frac x L\\right).\n\\] Then the number of particles entering at \\(x=0\\) due to diffusive flux (Fickian diffusion) is: \\[\nJ = - D \\frac{ dc}{ dx} = D \\frac{ C_0} L,  \n\\]\nand the total number of particles is given by: \\[\nN = \\int_0^L c(x) \\, dx = \\frac 12 L C_0 .\n\\] If we assume a cross-section of unit area at \\(x=0\\), then \\[\nF = \\text{flux}\\times\\text{area} = J\\times 1 = D \\frac{ C_0} L\n\\] and \\[\n\\tau =  \\frac N F = \\frac { C_0 L}{2} \\frac L{ DC_0} = \\frac 12 \\frac{L^2}{D}.\n\\] Thus the average time it takes a particle to diffuse a distance, \\(L\\), is \\[\n\\tau = \\dfrac{L^2}{2D}\n\\] or viewed another way, the average distance through which diffusion transports a particle in a time \\(\\tau\\) is \\(L= \\sqrt{ 2D\\tau}\\).\n\n\n2.1.5 Diffusion as the limit of a random walk\nConsider the random walk of particles in a one-dimensional domain. Suppose that the particles move randomly a distance, \\(\\Delta x\\), every time step, \\(\\Delta t\\). Assume that the particles move left with probability \\(\\lambda_L\\) and right with probability \\(\\lambda_R\\).\nIn Figure Figure 2.2 a simulation of 400 random walking particles is presented. Each particle is initialised at the origin and can move one step left or right with equal probability at every time step of the simulation. As time evolves the particle density (histogram) disperses. The normalised particle density appears to be well described by the solution of the diffusion equation (solid lines, Equation 2.3).\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\nN_particles=400\n\nL=50\nN_x=200\n\nT=500\nN_t=25000\nD=0.1\n\ndt=T/N_t\n\nmove_probability=D*dt/dx**2\n\nx=np.linspace(0,L,N_x)-L/2\nt=np.linspace(dt,T,N_t)\n\nparticle_positions=np.zeros((N_t,N_particles),dtype=float)\n\n# loop over time\nfor i in range(1,N_t):\n  # loop over particles\n  for j in range(N_particles):\n\n    r=random.random()\n    # move particle j right\n    new_particle_position=particle_positions[i-1,j]\n    if r&lt;move_probability:\n      new_particle_position+=dx\n    # move particle j left  \n    elif r&lt;2*move_probability:\n      new_particle_position-=dx\n    particle_positions[i,j]=new_particle_position\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\n\nfig,ax=plt.subplots(2,2)\nax[0,0].hist(particle_positions[5,:],density=True)\nax[0,0].plot(x, c_exact[5,:], 'r')\nax[0,0].set_title('$t=$'+str(t[5]))\n\nax[0,1].hist(particle_positions[500,:],density=True)\nax[0,1].plot(x, c_exact[500,:], 'm')\nax[0,1].set_title('$t=$'+str(t[500]))\n\nax[1,0].hist(particle_positions[1000,:],density=True)\nax[1,0].plot(x, c_exact[1000,:], 'b')\nax[1,0].set_title('$t=$'+str(t[1000]))\n\nax[1,1].hist(particle_positions[1500,:],density=True)\nax[1,1].plot(x, c_exact[1500,:], 'k')\nax[1,1].set_title('$t=$'+str(t[1500]))\n\nax[0,0].set_xlim([-L/2,L/2])\nax[0,1].set_xlim([-L/2,L/2])\nax[1,0].set_xlim([-L/2,L/2])\nax[1,1].set_xlim([-L/2,L/2])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 2.2: Numerical implementation of random walk\n\n\n\n\nConcider the concentration of particles \\(c(x,t)\\) at spatial location \\(x\\) and time \\(t\\), (or more precisely, the probability density function of the position of a particle performing a random walk) we have: \\[\nc(x, t+ \\Delta t) = c(x, t)  + \\lambda_R c(x- \\Delta x, t) - \\lambda_R c(x, t) + \\lambda_L c(x+ \\Delta x, t) - \\lambda_L c (x,t).\n\\] If we assume that \\(\\lambda_R+ \\lambda_L =1\\) then \\[\nc(x, t+ \\Delta t) =  \\lambda_R c(x- \\Delta x, t) + \\lambda_L c(x+ \\Delta x, t).\n\\] Applying a Taylor series expansion about \\((x,t)\\) implies\n\\[\nc(t,x) + \\frac{ \\partial c}{\\partial t} \\Delta t + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} (\\Delta t )^2  + h.o.t. =\n\\lambda_R \\Big( c(t,x) - \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t. \\Big)\\\\ +\n\\lambda_L \\Big( c(t,x) + \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t. \\Big).\n\\]\nUsing \\(\\lambda_R+ \\lambda_L =1\\) and assuming \\(\\lambda_L = \\lambda_R = \\frac 12\\) we obtain\n\\[\n\\frac{ \\partial c}{\\partial t} \\Delta t + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} (\\Delta t )^2  + h.o.t. =\n\\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t.\n\\] Dividing by \\(\\Delta t\\) gives\n\\[\n\\frac{ \\partial c}{\\partial t}  + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} \\Delta t   + h.o.t. =\n   \\frac{ \\partial^2 c}{\\partial^2 x} \\frac{(\\Delta x )^2 }{2\\Delta t} + h.o.t.\n\\]\nConsidering the limit \\(\\Delta t \\to 0\\) and \\(\\Delta x \\to 0\\) in such way that\n\\[\n\\frac{(\\Delta x )^2 }{2\\Delta t} \\to D,\n\\]\nyields the (one-dimensional) diffusion equation\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}.\n\\]\nThis approach can be extended to consider other types of movement e.g. convection. For example, if we assume that\n\\[\n\\lambda_R+ \\lambda_L =1,\n\\] and \\[\n\\lambda_L - \\lambda_R = \\varepsilon,\n\\] the motion of the particles is biased and we may derive an appropriate reaction-diffusion-convection equation (see tutorial).\nFinally we note that there is a connection between diffusion and the normal distribution function.\nRecall The normal distribution function in one-dimension with zero mean and variance \\(\\sigma^2\\) is given by @#eq-fund_sol.\n\\[\nN(0, \\sigma^2) \\sim \\frac 1 { \\sqrt{ 2 \\pi \\sigma^2}} \\exp \\left( - \\frac{x^2}{ 2 \\sigma^2}\\right).\n\\] Examining the formula for the fundamental solution of the diffusion Equation 2.3 in one-dimension, we see by inspection that the probability density function of the position of a particle performing a random walk in one-dimension starting at the origin is normally distributed with mean zero and variance \\[\n\\sigma^2 = 2 D t.\n\\]"
  },
  {
    "objectID": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "href": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "2.2 Linear reaction-diffusion equations",
    "text": "2.2 Linear reaction-diffusion equations\nConsider now the linear reaction term: \\(f(c) = \\rho c\\), so that our reaction-diffusion equation is: \\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}   + \\rho \\, c, \\quad x\\in \\mathbb R, \\, \\, t &gt;0,\n\\tag{2.4}\\] where \\(\\rho \\in \\mathbb R\\) is a constant.\nOnce again we consider the initial condition to be concentrated at the origin: \\[\nc(0,x) = \\delta_0(x).\n\\tag{2.5}\\]\n\n2.2.1 Exact solution\nBy considering a separation of variables approach, i.e. making the ansatz \\[\nc(x,t) = w(t) \\tilde c(t,x),\n\\] it can be shown (Exercise) that the explicit solution for the linear reaction-diffusion Equation 2.4 with initial condition Equation 2.5 is given by\n\\[\nc(t,x) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left(\\rho t - \\frac{x^2}{ 4Dt} \\right).\n\\]\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=10\nL=10\n\nN_x=100\nN_t=120\n\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\n\nD=0.5\nrho=1.0\nepsilon=0.1\n\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n\n\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    i=N_x-1\n\n    f[i]=D/dx**2*(u[i-1]-u[i])\n\n    reac=rho*u\n    f=f+reac\n    return f  \n\nsol=odeint(logisticPDErhs,u_0,t)\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(rho*t_mesh-x_mesh**2/(4*D*t_mesh))\n\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62542/3455521560.py:46: RuntimeWarning: divide by zero encountered in divide\n  c_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(rho*t_mesh-x_mesh**2/(4*D*t_mesh))\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62542/3455521560.py:46: RuntimeWarning: invalid value encountered in multiply\n  c_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(rho*t_mesh-x_mesh**2/(4*D*t_mesh))\n\n\n\n\n\n(a) Numerical solution of linear reaction diffusion equation\n\n\n\n\n\n\n\n(b)\n\n\n\nFigure 2.3: ?(caption)\n\n\n\n\n2.2.2 Speed of a wave of invasion\nMuskrats which were introduced in 1905 in Bohemia initially spread rapidly throughout Europe through a combination of random movement and proliferation (initially there were no predators and proliferation was rapid). A model for the initial spread can therefore be given by a two-dimensional diffusion equation combined with exponential growth and assuming that \\(M\\) individuals were released at the origin (i.e. in Bohemia). Considering the density of muskrats \\(u({\\mathbf{x}} , t)\\), the equation is\n\\[\n\\frac{\\partial u}{\\partial t} = D \\left(\\frac{\\partial^2 u}{\\partial x_1^2} +  \\frac{\\partial^2 u}{\\partial x_2^2}\\right)  + \\rho \\, u, \\quad {\\mathbf{x}} = (x_1 , x_2) \\in \\mathbb R^2, \\, \\, t &gt;0,\n\\tag{2.6}\\] \\[\nu({\\mathbf{x}}, 0) = M \\delta_0({\\mathbf{x}}), \\quad {\\mathbf{x}} \\in \\mathbb R^2.\n\\tag{2.7}\\]\nThe solution of Equation 2.6 with initial conditions Equation 2.7 is equal to:\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ |{\\mathbf{x}} |^2}{ 4Dt} \\right)\\; = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ (x_{1}^{2} + x_{2}^{2})}{4Dt} \\right).\n\\]\nTransforming to polar coordinates \\(x_1 = r \\cos\\varphi\\), \\(x_2 = r \\sin \\varphi\\) we obtain\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r^2}{ 4Dt} \\right).\n\\]\nFrom the properties of the fundamental solution, the wave of invasion extends all the way to infinity if \\(t&gt;0\\). Thus, for practical purposes, somehow we have to define the front of the wave.\nConsider that there is some detection threshold for the muskrats i.e. some predetermined small value of the density \\(u_1\\), say, such that any changes in density for \\(u &lt;u_1\\) cannot be detected.\nBecause of the symmetry of the problem, then the leading edge of the invading wave front of muskrats is the circle of radius \\(r=r_1(t)\\) where \\(u=u_1\\), i.e. from the explicit solution of Equation 2.6,\n\\[\nu_1({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r_1^2}{ 4Dt} \\right).\n\\]\nRearranging and solving for \\(r_1\\), using the fact that \\[\n\\lim\\limits_{t\\to \\infty} \\dfrac {\\ln t} t =0,\n\\] we obtain for large \\(t\\) that \\[\nr_1(t) \\approx 2 \\sqrt{ \\rho D} t.\n\\]\nHence, the speed of invasion of the leading edge of the muskrats is given by: \\[\nv = \\frac{r_1(t)}{t} =  2 \\sqrt{ \\rho D}.\n\\]"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#numerical-solutions",
    "href": "nonlinearreactiondiffusion.html#numerical-solutions",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.1 Numerical solutions",
    "text": "3.1 Numerical solutions\nIn Figure 3.1 we have computed a numerical solution to Equation 3.2 together with no-flux boundary conditions. See Python code for further details. The key point to note is that the numerical solutions appear to be a travelling wave, at successive times the solution is translated along the \\(x\\) axis. At long times the solution tends to \\(u\\sim1\\) (behind the wavefront). Ahead of the front, the solution is \\(u\\sim0\\).\n\nCan we prove this is a travelling wave (e.g. the solution could be dynamic on a very slow time scale that is not captured by the numeircal solution)?\nCan we derived a form for the travelling wave profile?\nWill we see a travelling wave for any initial data?\nHow does the wave speed relate to model parameters?\n\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=100\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\n\nu_0=0.5*(1+np.tanh(-0.1*(x-20)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1])+u[i]*(1-u[i])  \n\n\n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1])+u[i]*(1-u[i]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])+u[i]*(1-u[i]) \n    return f  \n\nsol=odeint(logisticPDErhs,u_0,t)\n\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[4,:], 'b')\nplt.plot(x, sol[8,:], 'm')\nplt.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\nFigure 3.1: Numerical solution of logistic PDE"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#travelling-waves",
    "href": "nonlinearreactiondiffusion.html#travelling-waves",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.2 Travelling waves",
    "text": "3.2 Travelling waves\nIt is known that the Fisher Equation 3.2 exhibits what are known as travelling wave solutions.\n\nDefinition 3.1 A travelling wave is a solution of a partial differential equation with a constant profile (shape) and a constant propagation speed.\n\n\n3.2.1 Types of travelling waves\n\nTravelling pulse: \\(u(x,t) \\to a\\), as \\(x \\to \\pm \\infty\\).\nTravelling front : \\(u(x,t) \\to a\\), as \\(x \\to - \\infty\\), \\(u(t,x) \\to b\\), as \\(x \\to + \\infty\\) and \\(a\\neq b\\) (this is what we see in Figure 3.1)\nTravelling train: \\(u(x,t)\\) is a periodic function in \\(x\\).\n\nA travelling wave solution of a PDE can be written in the form \\(u(x,t) = W(z)\\), where \\(z = x - vt\\). We shall consider \\(v&gt;0\\), which describes a wave moving from left to right.\nConsider first the spatially uniform (homogeneous) solution of Equation 3.2\n\\[\n\\frac{\\partial u}{\\partial t} =    u(1-u), \\qquad   \\, \\, t &gt;0.\n\\tag{3.3}\\]\nSteady states of Equation 3.3 are \\[\nu=u_1 =1\n\\] and \\[\nu=u_2 =0.\n\\] To analyse the stability we consider \\[\nf(u)=u(1-u) \\quad \\textrm{and} \\quad \\frac{ df}{du}(u)= 1 - 2u\n\\] Then \\[\n\\frac{ df}{du}(u_1)= -1 \\quad \\textrm{and} \\quad \\frac{ df}{du}(u_2)= 1\n\\] Thus \\(u_1=1\\) is stable and \\(u_2=0\\) is unstable.\nThis stability analysis suggests that for the spatially dependent situation we can have a travelling wave solution that connects the two steady states \\(u_1\\) and \\(u_2\\) i.e. a travelling front.\nConsidering the travelling wave ansatz\n\\[\nu(x,t)= W(z) = W(x-vt)\n\\] in Equation 3.2 and using\n\\[\n\\begin{aligned}\n\\frac{ \\partial u}{\\partial t} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial t} &= - v   \\frac{ dW}{dz}, \\\\\n\\frac{ \\partial u}{\\partial x} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial x} &=\\frac{ dW}{dz}, \\\\\n\\frac{ \\partial^2 u}{\\partial x^2} &= \\frac{ d^2W}{dz^2} \\left(\\frac{\\partial z}{\\partial x} \\right)^2 +  \\frac{ dW}{dz} \\frac{\\partial^2 z}{\\partial x^2} &=\\frac{ d^2W}{dz^2},\n\\end{aligned}\n\\]\nwe obtain a second order ordinary differential equation for \\(W\\)\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + W(1-W)  = 0,\n\\tag{3.4}\\] where \\[\nW(z) \\to 1 \\quad \\text{ as } \\quad z \\to  - \\infty, \\quad\nW(z) \\to 0 \\quad \\text{ as } \\quad z \\to  +\\infty,\n\\tag{3.5}\\] and \\[\nW(z) \\in [0,1].\n\\tag{3.6}\\]\nWe can rewrite Equation 3.4 as a system of two first order ODEs\n\\[\n\\begin{aligned}\n\\frac{ dW}{dz}& = P  = F(W,P), \\\\\n\\frac{ d P}{dz}&= -  v P - W(1-W)  = G(W,P).  \n\\end{aligned}\n\\tag{3.7}\\]\n\n\n3.2.2 Numerical solutions\nIn Figure 3.2 we plot the numerical solution to equations Equation 3.7 for different values of the wavespeed \\(v\\). Note that when the wavespeed is too small the solution spirals in towards the origin. This solution cannot be valid as it implies that \\(u&lt;0\\) for some \\(z\\).\nNote that some problem will not have a travelling wave solution. In this situation we could still make the travelling wave ansatz but this would usually result in a contradiction. In such a case this tells us that a travelling wave solution is not possible.\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=300\n\na=0.2\nN_z=5000\n\nz=np.linspace(1,T,N_z)\n\nu_0=[0.99,-0.0001]\n\nc_1=2.0\nc_2=8.6\nc_3=0.5\n\ndef fisherTrWaveODErhs(u, t, c):\n    f=np.zeros_like(u)\n    reaction=u[0]*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-c*u[1]-reaction\n    return f  \n\nsol=odeint(fisherTrWaveODErhs,u_0,z, args=(c_1,))\nsol2=odeint(fisherTrWaveODErhs,u_0,z, args=(c_2,))\nsol3=odeint(fisherTrWaveODErhs,u_0,z, args=(c_3,))\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(sol[:,0],sol[:,1], 'r')\nax[0].plot(sol2[:,0],sol2[:,1], 'b')\nax[0].plot(sol3[:,0],sol3[:,1], 'k')\nax[0].set_xlim([-0.5, 1.05])\nax[0].set_xlabel('$u$')\nax[0].set_ylabel('$du/dz$')\n\nax[1].plot(z,sol[:,0], 'r')\nax[1].plot(z,sol2[:,0], 'b')\nax[1].plot(z,sol3[:,0], 'k')\nax[1].set_xlim([-0.5, 100])\n\nax[1].set_xlabel('$z$')\nax[1].set_ylabel('$u$')\nplt.legend(['c='+str(c_1),'c='+str(c_2), 'c='+str(c_3)])\nplt.grid()\nplt.show()\n\n\n\n\nFigure 3.2: Proposed numerical solution of Equation 3.7 with prospective values of wavespeed \\(c\\).\n\n\n\n\n\n\n3.2.3 Steady state analysis\nThe steady states of Equation 3.7 are \\((W_1, P_1) = (0,0)\\) and \\((W_2, P_2) = (1,0)\\).\nUsing \\[\n\\frac{dP}{dW} =  \\frac{dP}{dz} \\frac{dz}{dW} =\\frac{ \\frac{dP}{dz}}{ \\frac{dW}{dz}}\n\\] and Equation 3.7 we can write an equation for \\(P=P(W)\\): \\[\n\\frac{ dP}{dW} = - v - \\frac{ W(1-W)} P,\n\\tag{3.8}\\]\ntogether with \\[\nP(0) = 0, \\quad P(1) = 0,\n\\tag{3.9}\\] and \\[\nP(W) &lt; 0  \\quad \\textrm{or} \\quad   W \\in (0,1).\n\\tag{3.10}\\]\nThe condition Equation 3.10 is given by the form of travelling front, which we would like to show that it exists\n\nLemma 3.1 For every solution of Equation 3.4 satisfying Equation 3.5 and Equation 3.6 we have that \\(\\dfrac{dW(z)}{dz} &lt;0\\) for all finite \\(z\\), i.e.  \\[\nP(W) &lt; 0 \\quad  \\mathrm{for} \\quad  W \\in (0,1).\n\\]\n\nThus in phase-plane we shall look for a trajectory connecting \\((W_1, P_1)=(0,0)\\) and \\((W_2, P_2) = (1,0)\\) and \\(P&lt;0\\).\n\n\n3.2.4 Connection between sign of \\(P\\) and sign of speed \\(v\\)\nConsider equation Equation 3.8. Multiplying it by \\(P\\) and integrating over \\(W\\) from \\(0\\) to \\(1\\), we obtain \\[\n\\int_0^1 \\frac{dP}{dW}  P(W)\\, dW = - v \\int_0^1  P(W) dW - \\int_0^1 W(1-W) dW.\n\\] Using conditions Equation 3.9 we have \\[\n\\int_0^1 \\frac{dP}{dW} \\, P\\, dW = \\frac 12 \\int  \\frac{d}{dW} (P^2) dW = \\frac 12\\left( P^2(1) - P^2(0)\\right) = 0,\n\\] and \\[\n  v \\int_0^1  P(W) dW=  - \\int_0^1 W(1-W) dW &lt;0, \\quad \\text{ since } \\int_0^1 W(1-W) dW &gt;0.\n\\] Thus for \\(v&gt;0\\) we have \\(P= W^\\prime&lt;0\\) and for \\(v&lt;0\\) we have \\(P= W^\\prime&gt;0\\).\nNote: \\(u(x,t) = W(z)\\), where \\(z= x- vt\\) with \\(v&lt;0\\) and \\(\\frac{ dW}{dz} &gt;0\\) will also be a travelling wave for the Fisher Equation 3.2, i.e. a travelling wave front moving to the left.\nNote: Instead of \\(z = x - vt\\) we can also consider \\(z=x+ vt\\) . The sign of \\(v\\) determines the direction of movement: If \\(z = x - vt\\) for \\(v&gt;0\\) we have travelling wave moving to the right and for \\(v&lt;0\\) we have travelling wave moving to the left.\nIf \\(z = x + vt\\) for \\(v&gt;0\\) we have travelling wave moving to the left and for \\(v&lt;0\\) we have travelling wave moving to the right.\n\n\n3.2.5 Stability of steady states\nThe Jacobian matrix for Equation 3.7 is given by: \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n-1 + 2W & \\, - v\n\\end{pmatrix}.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) the eigenvalues of \\(J(0,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(0,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- 1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_1 = \\frac 12 ( - v \\pm \\sqrt{ v^2 - 4})\n\\] and we have for \\(v&gt;0\\) that \\({R} e(\\lambda_1^\\pm) &lt;0\\).\nTherefore at \\((0, 0)\\) \\[\n\\begin{cases}\n\\text{ stable node if }\\,   v^2 \\geq 4, \\\\\n\\text{ stable focus if } \\,  v^2 \\leq 4 \\quad (\\text{ complex eigenvalues})\n\\end{cases}\n\\] At \\((W_2, P_2)=(1,0)\\) the eigenvalues of \\(J(1,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(1,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1 \\\\\n1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda - 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_2 = \\frac 12 ( - v \\pm \\sqrt{ v^2 + 4})\n\\] and we have for \\(v&gt;0\\) that \\(\\lambda_2^{-} &lt;0 &lt; \\lambda_2^+\\). Therefore \\((1,0)\\) is a saddle.\nThe eigenvectors are defined by \\[\n- \\lambda W + P = 0.\n\\] Thus at \\((W_1, P_1)=(0,0)\\) we have \\[\n\\Phi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^- W\n\\end{pmatrix}, \\quad  \\Phi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_1^- \\leq \\lambda_1^+ &lt;0 \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\]\nAt \\((W_2, P_2)=(1,0)\\) we have \\[\n\\Psi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^- W\n\\end{pmatrix}, \\quad  \\Psi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_2^- &lt;0 &lt; \\lambda_2^+  \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\] The eigenvectors are sketched in the figure below.\nInsert eigenvector picture here\n\nDefinition 3.2 The trajectory that connects two different points is called a heteroclinic connection. The trajectory that connects a point with itself is called a homoclinic connection.\n\n\n\n3.2.6 Minimal wave speed\nIt can be shown that for \\(v&lt;2\\) a heteroclinic connection between \\((0,0)\\) and \\((1,0)\\) exists, but in this situation the steady state \\((0,0)\\) is a stable focus and corresponds to an oscillatory front.\nIn the context of a model of a biological process \\(W\\) is the profile of a population density and \\(W\\geq 0\\). Hence, for \\(v&lt;2\\) trajectories connecting \\((0,0)\\) and \\((1,0)\\) are not biologically realistic.\nThus we obtain the minimal speed \\(v^\\ast_\\text{min}=2\\) (non-dimensionalized) for which we have a travelling wave front solution for Fisher’s equation.\nIn the original dimensional variables we have: \\[\nz^\\ast= x^\\ast - v^\\ast t^\\ast = x \\sqrt{ \\frac \\rho D} - v^\\ast t \\rho , \\quad\n\\sqrt{ \\frac D \\rho } z^\\ast= x  - \\sqrt{D \\rho}  \\, v^\\ast\\,  t.\n\\] Thus for \\(z = x - vt\\) we have \\[\nv=  v^\\ast \\sqrt{D \\rho},\n\\] and \\[\nv_{\\text{min}}=  v^\\ast_{\\text{min}} \\sqrt{D \\rho} = 2  \\sqrt{D \\rho}.\n\\]\n\n3.2.6.1 The existence of a confined region\nTo show the existence of a travelling wave we will construct a confined region or confined set in \\(\\mathbb{R}^2\\), which contains both steady states such that, once inside this region solution trajectories cannot escape from it (also known as an invariant region or invariant set).\nConsider \\[\nT= \\{ (W,P) : \\, 0 \\leq W \\leq 1,\\, \\, P \\leq 0, \\, \\,  P \\geq \\mu W \\}\n\\] for some \\(\\mu &lt;0\\).\nConsider normal vectors at each boundary of \\(T\\): \\[\n\\text{ at } P = 0 \\, : \\, \\, n_1 = \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix}, \\quad\n\\text{ at } W= 1 \\, : \\, \\, n_2 = \\begin{pmatrix}\n-1\\\\ 0\n\\end{pmatrix}, \\quad\n\\text{ at } P = \\mu W \\, : \\, \\, n_3 = \\begin{pmatrix}\n-\\mu \\\\1\n\\end{pmatrix}.\n\\] Consider the scalar product between normal vectors and the flow vector \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\ \\\\  \\dfrac{dP}{dz}\n\\end{pmatrix},\n\\] of Equation 3.7.\nAt \\(P=0\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_1 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix} =  \\left(v P + W(1-W)\\right) \\Big|_{P=0} =  W(1-W) \\geq 0 , \\text{ for } W\\in [0,1].\n\\]\nAt \\(W=1\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_2 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-1 \\\\ 0\n\\end{pmatrix} =  -P  \\geq 0 , \\text{ since }P \\leq 0.\n\\]\nAt \\(P=\\mu W\\) \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 &= \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-\\mu \\\\ 1\n\\end{pmatrix} \\\\\n& =\\left(  - \\mu  P - vP -  W(1-W)\\right) \\Big|_{P=\\mu W}  \\\\\n&=   - \\mu^2 W - \\mu v W - W(1-W) = - W( \\mu^2 + \\mu v + 1) + W^2.\n\\end{aligned}\n\\] Thus\n\\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0,\n\\] if \\[\n\\mu^2 + \\mu v + 1 \\leq 0.\n\\] The last inequality is satisfied if we have real roots of the equation \\(\\mu^2 + \\mu v + 1 = 0\\). We have that\n\\[\n\\mu_{1,2} = \\frac{ - v \\pm \\sqrt{ v^2 -4}} 2\n\\]\nare real if \\(v^2 \\geq 4\\).\nThus, since \\(v &gt;0\\), for \\(v \\geq 2\\) and any \\[\n\\mu\\in \\left[ \\dfrac{ - v -\\sqrt{ v^2 -4}} 2, \\dfrac{ - v +\\sqrt{ v^2 -4}} 2 \\right]\n\\] we have \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0 \\qquad \\text{ at } \\quad P=\\mu W.\n\\]\nTherefore we have shown that at the boundaries of \\(T\\) the flow vector points in to the region \\(T\\) and any trajectory approaching the boundaries from inside of \\(T\\) will return to \\(T\\) without crossing any of the boundaries of \\(T\\). Thus we have constructed an invariant (trapping) triangular region containing the steady states \\((0,0)\\) and \\((1,0)\\).\nIf we can show that there no other steady states or periodic solutions of the system Equation 3.7, then a trajectory that leaves \\((1,0)\\) must approach \\((0,0)\\).\n\nTheorem 3.1 Bendixson’s Negative Criterion, Dulac’s Negative Criterion\nIf there exists a function \\(\\varphi(W,P)\\), with \\(\\varphi \\in C^1(\\mathbb R^2)\\), such that \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P},\n\\]\nhas the same sign \\((\\neq 0)\\) almost everywhere in a simply connected region (region without holes), then the system \\[\n\\begin{aligned}\n\\dfrac{ dW}{dz} &= F(W,P) \\; ,\n\\\\   \\dfrac{dP}{dz} &= G(W,P),\n\\end{aligned}\n\\] has no periodic solutions in this region.\n\nWe can apply Theorem 3.1 to our situation taking \\(\\varphi(W,P) = 1\\). Then using Equation 3.7 we have \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P} = - v &lt; 0\\; .\n\\] Thus we have no periodic solutions and also only two steady states \\((0,0)\\) and \\((1,0)\\) in the confined (invariant) simply-connected region \\(T\\). Therefore the trajectory that leaves \\((1,0)\\) will approach \\((0,0)\\).\nWe have therefore shown that for any \\(v\\geq 2\\) there exist a heteroclinic trajectory \\(P(W)\\) connecting \\((0,0)\\) and \\((1,0)\\).\n\nTheorem 3.2 For \\(P(W)\\) satisfying Equation 3.8, Equation 3.9 and \\(P(W) &lt; 0\\) for \\(W \\in (0,1)\\), there exists a solution \\(W(z)\\) of Equation 3.4 satisfying Equation 3.5 and Equation 3.6.\n\nThus for any wave speed \\(v\\) satisfying \\(v \\geq 2\\), we have the existence of travelling wave front \\(u(x,t)= W(x- vt)\\) of Fisher’s equation Equation 3.2.\n\n\n\n3.2.7 Initial conditions\nOne final key question is: For which initial conditions \\(u(x,0) = u_0(x)\\) does the solution evolve to a travelling wave solution?\nIf we start with a travelling wave shape initial condition, i.e. \\(u_0(x)= W(z)|_{t=0} = W(x)\\), then this simply propagates as a travelling wave. However if \\(u_0(x)\\neq W(x)\\), then it is not immediately obvious how the solution will evolve. This problem was considered by Kolmogorov et al. Kolmogorov, Petrovsky, and Piskunov (1937), who showed that for any initial data satisfying \\[\nu_0(x) \\geq 0, \\quad \\text{ with} \\quad  u_0(x) = \\begin{cases} 1 \\, \\text{ if } \\, x \\leq x_1, \\\\\n0 \\, \\text{ if } \\, x \\geq x_2,\n\\end{cases}\n\\] where \\(x_1 &lt; x_2\\) and \\(u_0\\) is continuous in \\([x_1, x_2]\\), the solution of Fisher’s Equation 3.2 evolves to a travelling wave with minimal speed \\[\nv_\\text{ min} = 2 \\sqrt{ \\rho D}\n\\] and \\[\nu(t,x) \\rightarrow 1 \\quad \\textrm{as} \\quad x\\rightarrow -\\infty, \\quad u(t,x) \\rightarrow 0 \\quad \\textrm{and} \\quad  x\\rightarrow +\\infty.\n\\]"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#travelling-waves-in-bistable-equations",
    "href": "nonlinearreactiondiffusion.html#travelling-waves-in-bistable-equations",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.3 Travelling waves in bistable equations",
    "text": "3.3 Travelling waves in bistable equations\nConsider now the reaction-diffusion equation: \\[\n\\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2} +   f(u)\\qquad x\\in \\mathbb R, \\, \\, t &gt;0,  \\\\\n\\tag{3.11}\\] with initial condition \\[\nu(x,0)=u_0(x)  \\qquad x\\in \\mathbb R,\n\\] where \\(f(0) = f(a) = f(1)= 0\\) and \\(0 &lt; a&lt;1\\). There are three spatially uniform steady states \\(u_1 =0\\), \\(u_2 =a\\), \\(u_3=1\\).\nThe stability of the steady states is given by the sign of \\(f^\\prime(u_j)\\) for \\(j =1,2,3\\).\nIf we have that \\(f^\\prime (0) &lt; 0\\), \\(f^\\prime(a) &gt;0\\) and \\(f^\\prime(1) &lt;0\\) then \\(u_1=0\\) and \\(u_3=1\\) are stable steady states and \\(u_2 =a\\) is an unstable steady state of Equation 3.11.\nAn example of such a function is \\(f\\) is \\(f=u(u-a)(1-u)\\) which arises in the study of nerve action potentials along nerve fibres and other problems in excitable media.\nThe existence of two stable steady states gives rise to the name ``bistable equation’’."
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#numerical-solutions-2",
    "href": "nonlinearreactiondiffusion.html#numerical-solutions-2",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.4 Numerical solutions",
    "text": "3.4 Numerical solutions\n\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=100\n\na=0.2\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\n\nu_0=6*0.5*(1+np.tanh(-1*(x-50)))*0.5*(1+np.tanh(1*(x-50)))\nu_0=0.5*(1+np.tanh(-1*0.2*(x-50)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\nfig, ax = plt.subplots(1)\nu_samp=np.linspace(0,1,100)\nreac=u_samp*(u_samp-a)*(1-u_samp)\nax.plot(u_samp,reac) \nplt.show()\n\n\ndef bistablePDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])\n\n    reaction=u*(u-a)*(1-u) \n    f= f+reaction \n    return f  \n\nsol=odeint(bistablePDErhs,u_0,t)\n\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[15,:], 'b')\nplt.plot(x, sol[30,:], 'm')\nplt.plot(x, sol[45,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n(a) Numerical solution of bistable PDE\n\n\n\n\n\n\n\n(b)\n\n\n\nFigure 3.3: ?(caption)"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#general-assumptions-on-f",
    "href": "nonlinearreactiondiffusion.html#general-assumptions-on-f",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.5 General assumptions on \\(f\\)",
    "text": "3.5 General assumptions on \\(f\\)\n\n\\(f(0)=f(a)=f(1)=0\\),\n\\(f(u) &lt; 0\\) in \\((0,a)\\), \\(f(u) &gt;0\\) in \\((a,1)\\)\n\\(f^\\prime (0) &lt; 0\\), \\(f^\\prime (1) &lt; 0\\)\n\nIn a similar manner to the previous sections, we look for a travelling wave solution of the form \\(u(x,t) = W(z)\\) with \\(z= x-vt\\), yielding\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + f(W)  = 0,  \\; .\n\\tag{3.12}\\]\nWe can rewrite Equation 3.12 as asystem of two 1st order ODEs \\[\n\\begin{aligned}\n\\frac{ dW}{dz} = P = F(W,P) , \\\\\n\\frac{ d P}{dz}= -  v P - f(W)  = G(W,P),  \n\\end{aligned}\n\\tag{3.13}\\]\n\n3.5.1 Stability of the steady states\nThe steady states of Equation 3.13 are \\((W_1, P_1) = (0,0)\\), \\((W_2, P_2) = (a,0)\\), \\((W_3, P_3) = (1,0)\\).\nThe Jacobian matrix is given by \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n- f^\\prime(W) & \\, - v\n\\end{pmatrix}\n\\]\nAt steady states \\((W_j, P_j)\\), the eigenvalues of \\(J(W_j,P_j)\\) are solutions of the characteristic polynomial \\[\n\\det(J(W_j,P_j) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- f^\\prime(W_j) & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + f^\\prime(W_j) = 0 .\n\\]\nTherefore:\n\\[\n\\lambda^{\\pm}_j = \\frac{ - v \\pm \\sqrt{ v^2 - 4 f^\\prime(W_j)}}2.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) since \\(f^\\prime(0) &lt;0\\) we obtain $ _1^{-} &lt;0&lt;_1^{+} $ and it is a saddle point. \\\nAt \\((W_2, P_2)=(a,0)\\) since \\(f^\\prime(a) &gt;0\\) we obtain \\[\n(a,0) - \\begin{cases}\n\\text{ focus} \\quad \\text{ if} \\, v^2 &lt; 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n  \\text{ node} \\quad \\text{ if} \\, v^2 \\geq 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n   \\text{centre } \\quad \\text{ if} \\, v=0 \\; . \\\\\n\\end{cases}\n\\] \\ At \\((W_3, P_3)=(1,0)\\) since \\(f^\\prime(1) &lt;0\\) we obtain $ _3^{-} &lt;0&lt;_3^{+} $ and it is a saddle point. \\\nEigenvectors are given by \\[\nP =\\lambda W\n\\] and at each steady state we have two eigenvectors \\[\n\\Psi_j^{\\pm} = \\begin{pmatrix}\nW\\\\\n\\lambda_j^\\pm W\n\\end{pmatrix} , \\qquad  j=1,2, 3.\n\\]\nAs we vary the wave speed \\(v\\), the stable and unstable manifolds move and we wish to show that for some \\(v\\) the unstable manifold leaving one saddle point coincides with the stable manifold entering the other saddle point, i.e. we can choose a value for the wave speed \\(v\\) such that a heteroclinic connection between \\((1,0)\\) and \\((0,0)\\) is obtained. We shall use a ``shooting argument’’ to prove this.\n** Insert fig3 here**\n\n\n3.5.2 Relation between sign of \\(v\\) and sign of \\(\\int\\limits_0^1 f(u) \\, du\\)\nConsider Equation 3.12, multiply it by \\(\\dfrac{dW}{dz}\\) and integrate over \\((-\\infty, + \\infty)\\): \\[\n\\int_{-\\infty}^{+ \\infty}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{-\\infty}^{+ \\infty}f(W)\\dfrac{dW}{dz} \\, dz =0.\n\\]\nThen \\[\n\\frac 12 \\int_{-\\infty}^{+ \\infty}  \\dfrac{d}{dz} \\left(\\left|\\dfrac{dW}{dz}\\right |^2\\right) \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{W(-\\infty)}^{W(+\\infty)}f(W) \\, dW =0\n\\] and since \\(W(z) \\to 1\\) as \\(z \\to - \\infty\\) and \\(W(z) \\to 0\\) as \\(z \\to + \\infty\\) we obtain\n\\[\n\\frac 12 \\left( \\left|\\dfrac{dW(+\\infty)}{dz}\\right |^2-   \\left|\\dfrac{dW(-\\infty)}{dz}\\right |^2\\right)  + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{1}^{0}f(W) \\, dW =0.\n\\] The fact that \\(W\\) is constant at \\(\\pm \\infty\\) implies that \\[\n\\dfrac{dW}{dz}\\Big|_{z=-\\infty} = \\dfrac{dW}{dz}\\Big|_{z=+\\infty}=0.\n\\] Thus we have\n\\[\nv\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  =  \\int\\limits_{0}^{1}f(W) dW\n\\] and \\[\nv= \\dfrac {\\int\\limits_{0}^{1}f(W) \\, dW}{\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz}.\n\\] Since \\(\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz &gt;0\\) we can conclude that \\[\n\\int_{0}^{1}f(u) \\, du &gt; 0  \\quad  \\Longrightarrow  \\quad v&gt; 0, \\\\\n  \\int_{0}^{1}f(u) \\, du =0 \\quad  \\Longrightarrow  \\quad v=0, \\\\\n   \\int_{0}^{1}f(u) \\, du &lt; 0  \\quad  \\Longrightarrow \\quad v &lt; 0.\n\\]\n\n\n3.5.3 The shooting method proof of a heteroclinic connection\n\n3.5.3.1 Numerical shooting method\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=300\n\na=0.2\nN_z=5000\n\nz=np.linspace(1,T,N_z)\n\nu_0=[0.99,-0.0001]\n\nc_1=2.0\nc_2=0.6\nc_3=0.425\n\ndef bistableTrWaveODErhs(u, t, c):\n    f=np.zeros_like(u)\n    reaction=u[0]*(u[0]-a)*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-c*u[1]-reaction\n    return f  \n\nsol=odeint(bistableTrWaveODErhs,u_0,z, args=(c_1,))\nsol2=odeint(bistableTrWaveODErhs,u_0,z, args=(c_2,))\nsol3=odeint(bistableTrWaveODErhs,u_0,z, args=(c_3,))\n\nfig, ax = plt.subplots(1)\nplt.plot(sol[:,0],sol[:,1], 'r')\nplt.plot(sol2[:,0],sol2[:,1], 'b')\nplt.plot(sol3[:,0],sol3[:,1], 'k')\nax.set_xlim([-0.05, 1.05])\n\nplt.xlabel('$u$')\nplt.ylabel('$du/dz$')\nplt.legend(['c='+str(c_1),'c='+str(c_2), 'c='+str(c_3)])\nplt.grid()\nplt.show()\n\n\n\n\nFigure 3.4: Numerical solution of bistable PDE\n\n\n\n\nAssume \\[\n\\int\\limits_{0}^{1}f(u) \\, du &gt; 0.\n\\] i.e. \\(v&gt;0\\).\n\nConsider first \\(v=0\\).\nFrom the equations in Equation 3.13 and the assumptions on the function \\(f\\) we have\n\nIf \\(W \\in (0,a)\\)\nUsing the fact that \\(f(W) &lt;0\\) for \\(W \\in (0,a)\\) and \\(P&lt;0\\) and \\(v=0\\) we have \\[        \n  \\begin{cases}\n  \\dfrac{dW}{dz} = P &lt;0, \\\\\n  \\dfrac{dP}{dz} = - f(W) &gt;0\n  \\end{cases}  \\quad  \\rightarrow \\quad \\dfrac{dP}{dW} &lt;0\n  \\] Thus the trajectory enters \\((0,0)\\) with \\[\n\\dfrac{dP}{dW} &lt;0,\n\\] along the stable manifold \\(\\textit{M}_s^{(0,0)}\\) and intersects the line \\(\\{ W=a\\}\\) at the point \\((a, P_0)\\).\nIf \\(W \\in (a,1)\\)\nUsing the fact that \\(f(W) &gt;0\\) for \\(W \\in (a,1)\\) and \\(P&lt;0\\) and \\(v=0\\) we have \\[\n  \\begin{cases}\n  \\dfrac{dW}{dz} = P &lt;0, \\\\\n  \\dfrac{dP}{dz} = - f(W) &lt;0\n  \\end{cases}  \\quad  \\rightarrow \\quad \\dfrac{dP}{dW} &gt;0\n  \\] Thus the trajectory leaves \\((1,0)\\) with \\[\n   \\dfrac{dP}{dW} &gt;0\n  \\] along the unstable manifold \\(\\textit{M}_u^{(1,0)}\\) and intersects the line \\(\\{ W=a\\}\\) at the point \\((a, P_1)\\).\n\n** Insert fig1 here **\nNow we shall compare \\(P_0\\) and \\(P_1\\). For this we consider again equation Equation 3.12, multiply by \\(\\dfrac{dW}{dz}\\) and integrate first over \\((-\\infty, z^\\ast)\\) and then over \\((z^\\ast, + \\infty)\\), where \\(z^\\ast \\in (-\\infty, + \\infty)\\) such that \\(W(z^\\ast)=a\\). Then since \\(v=0\\) we have first \\[    \n  \\int_{-\\infty}^{z^\\ast}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz   + \\int_{-\\infty}^{z^\\ast}f(W)\\dfrac{dW}{dz} \\, dz =0.\n  \\] and \\[\n      \\frac 12\\left|\\dfrac{dW}{dz}\\right|^2 \\Big|_{z=-\\infty}^{z=z^\\ast}  + \\int_{W(-\\infty)}^{W(z^\\ast)}f(W) dW=0 \\; .\n  \\] Since \\(W(-\\infty) =1\\) we are moving along the unstable manifold \\(M_u^{(1,0)}\\) and \\[\n  \\dfrac{dW(z^\\ast)}{dz}=P(z^\\ast+ 0) = P_1.\n  \\] Thus using that \\(\\dfrac{dW}{dz}\\Big|_{z= - \\infty} =0\\) we obtain\n\\[\n    \\frac 12 P^2_1  + \\int_{1}^{a}f(W) dW=0 \\; \\quad  \\Longrightarrow \\quad  P_1^2 = 2 \\int_{a}^{1}f(W) dW\n\\] Integration over \\((z^\\ast, + \\infty)\\) implies \\[\n\\int_{z^\\ast}^{+ \\infty}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz   + \\int_{z^\\ast}^{+ \\infty} f(W)\\dfrac{dW}{dz} \\, dz =0.\n\\] and \\[\n  \\frac 12 \\left|\\dfrac{dW(+ \\infty)}{dz}\\right|^2 -  \\frac 12 \\left|\\dfrac{dW(z^\\ast)}{dz}\\right|^2  + \\int_{W(z^\\ast)}^{W(+ \\infty)} f(W) \\, dW =0 \\; .\n\\] Since \\(W(+\\infty) =0\\) we are moving along the stable manifold \\(M_s^{(0,0)}\\) and \\(\\dfrac{dW(z^\\ast)}{dz}=P(z^\\ast- 0) = P_0\\). Thus using that \\(\\dfrac{dW}{dz}\\Big|_{z= + \\infty} =0\\) we obtain \\[\n  -\\frac 12 P^2_0  + \\int_{a}^{0}f(W) dW=0 \\;  \\quad  \\Longrightarrow \\quad  P_0^2 = - 2 \\int_{0}^{a}f(W) dW\\; .\n\\] Since \\[\n\\int\\limits_{0}^{1}f(u) \\, du &gt; 0\n\\] we obtain \\[\nP^2_1 - P_0^2=2 \\int\\limits_{0}^{1}f(W) \\, dW &gt; 0   \\quad  \\Longrightarrow \\quad P^2_1 &gt; P_0^2\n\\] Then since \\(P&lt;0\\) we have \\[\nP_1 &lt; P_0 \\; .\n\\]\nConsider \\(v&gt;0\\) large.\n\nFrom the equations in Equation 3.13 and the assumptions on the function \\(f\\) we have\n* If $W \\in (0,a)$\nUsing the fact that \\(f(W) &lt;0\\) for \\(W \\in (0,a)\\), \\(P&lt;0\\) and \\(v&gt;0\\) we have\n\\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{dW}{dz} &= P &lt;0, \\\\\n\\dfrac{dP}{dz} &= -vP- f(W) &gt;0\n\\end{cases}  \\quad  \\Longrightarrow \\quad \\dfrac{dP}{dW} &lt;0\n\\end{aligned}\n\\] Thus \\(P(W)\\) is always decreasing for \\(W \\in (0,a)\\). * If \\(W \\in (a,1)\\)\nUsing the fact that \\(f(W) &gt;0\\) for \\(W \\in (a,1)\\), \\(P&lt;0\\) and \\(v&gt;0\\) we have\n\\[\n\\begin{aligned}\n\\dfrac{dW}{dz} = P &lt;0, \\\\\n\\\\\n\\begin{cases}\n\\dfrac{dP}{dz} = -vP- f(W) &lt;0  \\quad \\text{ for small }  |P| \\textrm{ and }\n\\dfrac{dP}{dz} = -vP- f(W) &gt;0  \\quad \\text{ for large  } |P|.\n\\end{cases}\n\\end{aligned}\n\\]\nThus \\[\n\\begin{cases}\n\\dfrac{dP}{dW}   &gt;0 \\quad    \\text{ for small }  |P| ,\\\\\n\\\\\n\\dfrac{dP}{dW}  &lt;0  \\quad  \\text{ for large }  |P|\\; .\n\\end{cases}\n\\]\nTherefore if \\(v&gt;0\\) large we have that \\(P(W)\\) is monotone increasing for small \\(|P|\\) and monotone decreasing for large \\(|P|\\).\n** Insert fig2 here **\nThus since for \\(v=0\\) we have \\(P_1 &lt; P_0\\) and for \\(v&gt;0\\) we have that \\(P(W)\\) is monotone decreasing for large \\(|P|\\), due to the continuity of the phase trajectories with respect to the velocity \\(v\\) we obtain that there exists a travelling wave speed \\(v_0 &gt;0\\) such that \\(P_0= P_1\\) and we have a heteroclinic connection between \\((1,0)\\) and \\((0,0)\\) in the phase plane. Hence for \\(v=v_0\\) there exists a travelling wave front solution for the bistable Equation 3.11.\nWe can repeat the analysis for \\[  \n\\int\\limits_{0}^{1}f(u) \\, du &lt; 0\n\\] and obtain a travelling wave solution with \\(v_0 &lt;0\\).\nIf \\[\n\\int\\limits_{0}^{1}f(u) \\, du = 0,\n\\] then we have a standing wave with \\(v=0\\), since the calculations for \\(P_0\\) and \\(P_1\\) implies \\(P_0=P_1\\) and there exists a heteroclinic orbit between \\((1,0)\\) and \\((0,0)\\) in the phase space.\nNote: There exists a unique travelling wave velocity \\(v\\) for which we have a travelling wave solution for bistable Equation 3.11.\n\n\n\n\nKolmogorov, AN, IG Petrovsky, and NS Piskunov. 1937. “Investigation of the Equation of Diffusion Combined with Increasing of the Substance and Its Application to a Biology Problem.” Bull. Moscow State Univ. Ser. A: Math. Mech 1 (6): 1–25.\n\n\n“The Wave of Advance of Advantageous Genes.” 1937. Annals of Eugenics 7 (4): 355–69."
  },
  {
    "objectID": "LotkaVolteraPDE.html#nondimensionalization",
    "href": "LotkaVolteraPDE.html#nondimensionalization",
    "title": "4  Lotka Voltera model",
    "section": "4.1 Nondimensionalization",
    "text": "4.1 Nondimensionalization\nConsider the scaling \\[\nx^\\ast = x \\sqrt{\\frac \\rho {D_n}} , \\qquad t^\\ast = \\rho \\, t , \\quad u^\\ast = \\frac uK, \\quad n^\\ast = n \\frac \\alpha \\rho\n\\] in one dimension. Upon dropping the asteriked notation \\[\n\\begin{cases}\n  &\\dfrac{\\partial u}{\\partial t} =  u ( 1 - u - n)  + D \\dfrac{\\partial^2 u}{\\partial x^2}\\; = \\; f(u,n) + D\\dfrac{\\partial^2 u}{\\partial x^2} \\qquad x\\in \\mathbb R , t&gt;0 \\,,  \\\\\n& \\dfrac{\\partial n}{\\partial t} = a\\,  n(u -b) + \\dfrac{\\partial^2  n}{\\partial x^2}\\; =\\; \\;  g(u,n) + \\dfrac{\\partial^2  n}{\\partial x^2}\\;  \\qquad x\\in \\mathbb R , t&gt;0,\n\\end{cases}\n  \\tag{4.2}\\] where \\[\nD= \\dfrac{D_u}{D_n}, \\quad a = \\dfrac{\\beta K}\\rho, \\quad   b = \\dfrac \\gamma{ K \\beta}.\n\\]"
  },
  {
    "objectID": "LotkaVolteraPDE.html#numerical-solutions",
    "href": "LotkaVolteraPDE.html#numerical-solutions",
    "title": "4  Lotka Voltera model",
    "section": "4.2 Numerical solutions",
    "text": "4.2 Numerical solutions\n\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=150\n\na=0.2\nb=0.4\nD_u=0.10\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=b+(1-b)*0.5*(1+np.tanh(1*0.5*(x-50)))\nn_0=(1-b)*0.5*(1+np.tanh(-1*0.5*(x-50)))\n\nu_0=np.concatenate((u_0,n_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    n=sol[N_x:2*N_x]\n\n\n\n    f_u=np.zeros_like(u)\n    f_n=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=D_u/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f_u[i]=D_u/dx**2*(-u[i]+u[i+1]) \n    i=N_x-1\n    f_u[i]=D_u/dx**2*(u[i-1]-u[i])\n\n    for i in range(1,N_x-2):\n      f_n[i]=1/dx**2*(n[i-1]-2*n[i]+n[i+1]) \n    i=0\n    f_n[i]=1/dx**2*(-n[i]+n[i+1]) \n    i=N_x-1\n    f_n[i]=1/dx**2*(n[i-1]-n[i])\n\n    reaction_u=u*(1-u-n)\n    reaction_n=a*n*(u-b)\n\n    f_u=f_u+reaction_u\n    f_n=f_n+reaction_n\n\n    f= np.concatenate((f_u, f_n)) \n    return f  \n\nsol=odeint(LVPDErhs,u_0,t)\n\nu=sol[:,0:N_x]\nn=sol[:,N_x:2*N_x]\n\nprint(np.shape((u)))\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, n[0,:],'r--')\nax[1].plot(x, n[16,:],'b--')\nax[1].plot(x, n[32,:],'m--')\nax[1].plot(x, n[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$n$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n(100, 100)\n\n\n\n\n\nFigure 4.1: Numerical solution of LV model"
  },
  {
    "objectID": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "href": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "title": "4  Lotka Voltera model",
    "section": "4.3 Spatially homogeneous steady states",
    "text": "4.3 Spatially homogeneous steady states\nWe have for spatially homogeneous steady states \\[\nf(u,n) =0 , \\qquad g(u,n) = 0\n\\] Thus \\[\n\\begin{aligned}\n&u(1-u-n) = 0,  \\quad  u =0, \\quad u+n=1,\\\\\n& an(u-b) = 0,  \\quad n =0, \\quad u =b.\n\\end{aligned}\n\\] Thus steady states are \\[\n(u_1^\\ast, n_1^\\ast)= (0,0), \\quad (u_2^\\ast, n_2^\\ast)= (1,0), \\quad (u_3^\\ast, n_3^\\ast)= (b,1-b), \\, 0\\leq b &lt;1\n\\]\nStability of steady states to spatially homogeneous perturbations \\[\n\\begin{aligned}\nJ(u_j^\\ast, n^\\ast_j) =\n\\begin{pmatrix}\n1-2u -n & -u \\\\\nan &a(u-b)\n\\end{pmatrix}_{(u^\\ast_j, n^\\ast_j)}, \\quad j = 1,2,3.\n\\end{aligned}\n\\]\nFor \\[\n(u_1^\\ast, n_1^\\ast)= (0,0)\n\\]\n\\[\n\\det(J (0,0) - \\lambda I) = - (1- \\lambda)(\\lambda+ ab) = 0\n\\]\nand \\[\n\\lambda_1^+ = 1, \\quad \\lambda_1^- = - ab &lt;0.\n\\] Thus \\((0,0)\\) is a saddle point.\nFor \\[\n(u_2^\\ast, n_2^\\ast)= (1,0)\n\\]\n\\[\n\\det(J (1,0) - \\lambda I) = - (1+ \\lambda)(a(1-b)- \\lambda) = 0\n\\] and \\[\n\\lambda_2^- =- 1, \\quad \\lambda_2^+ = a(1-b) &gt;0 \\; \\text{ for } \\; 0 \\leq b &lt;1.\n\\] Thus \\((1,0)\\) is a saddle point.\nFor \\((u_3^\\ast, n_3^\\ast)= (b,1-b)\\) \\[\n\\det(J (b,1-b) - \\lambda I) =\\lambda^2 + b \\lambda + ab(1-b) = 0\n\\] and \\[\n\\begin{aligned}\n\\text{ If } \\;  4 ab (1-b) \\leq b^2 \\qquad \\lambda_3^{\\pm} &lt; 0 \\quad \\text{ stable node } \\\\\n  \\text{ If }   \\; 4 ab (1-b) &gt; b^2 \\qquad Re(\\lambda_3{\\pm}) &lt; 0 , \\;  Im(\\lambda_3^{\\pm}) \\neq 0\\quad \\text{ stable focus (spiral) } , \\\\\n\\text{ for } b&gt;0, \\; 1-b&gt;0 \\text{ spiral oscillations  are biologically realistic as long } u&gt;0, \\; n&gt;0\\; .\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "href": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "title": "4  Lotka Voltera model",
    "section": "4.4 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)",
    "text": "4.4 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)\nConsider travelling wave solutions \\[\n\\begin{aligned}\nu(t,x) &= W(x+ vt) = W(z) , \\quad v&gt;0, \\\\\nn(t,x) &= N( x + vt) = N(z) , \\quad v &gt;0.\n\\end{aligned}\n\\] and \\[\n\\begin{aligned}\nu(t,x) \\to 1 \\; \\text{ as } x \\to - \\infty,  & \\; \\qquad  W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad\\\\\nu(t,x) \\to b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad   W(z)\\to b \\; \\text{ as } z \\to + \\infty \\\\\nn(t,x) \\to 0 \\;  \\text{ as } x \\to - \\infty ,  &\\qquad  \\;  N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad \\\\\nn(t,x) \\to 1-b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty\n\\end{aligned}\n\\]\nThe system Equation 4.2 becomes \\[\n\\begin{aligned}\n&v \\frac{dW}{dz} = D \\frac{d^2W}{dz^2} + W(1-W-N),\\\\\n& v \\frac{dN}{dz} =  \\frac{d^2N}{dz^2} + a N(W-b),\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n& W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad W(z)\\to b \\; \\text{ as } z \\to + \\infty, \\\\\n& N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty\\; .\n  \\end{aligned}\n\\tag{4.3}\\]\nWe shall suppose that the prey species moves much more slowly than the predator species, i.e.  \\[\nD= D_u/D_n \\ll 1\n\\] and simplify Equation 4.3 as\n\\[\n\\begin{aligned}\n&v \\frac{dW}{dz} =  W(1-W-N) ,\\\\\n& v \\frac{dN}{dz} =  \\frac{d^2N}{dz^2} + a N(W-b),\n\\end{aligned}\n\\tag{4.4}\\]\nWe can rewrite Equation 4.4 as a system of 1st order ODEs: \\[\n\\begin{aligned}\n& \\frac{dW}{dz} = \\frac 1 v W(1-W-N) &= F(W,N,P),\\\\\n&\\frac{dN}{dz} = P  &= G(W, N,P)\\\\\n&  \\frac{dP}{dz} = v P - a N(W-b)  &= R(W,N,P).\n\\end{aligned}\n\\tag{4.5}\\] Steady states of Equation 4.4 are \\[\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) = (0,0,0), \\quad (W^\\ast_2, N^\\ast_2, P^\\ast_2) = (1,0,0), \\quad (W^\\ast_3, N^\\ast_3, P^\\ast_3) =(b, 1-b, 0).\n\\] Stability of steady states \\[\nJ(W,N,P) = \\begin{pmatrix}\n\\dfrac 1 v - \\dfrac{2W} v - \\dfrac Nv & - \\dfrac Wv & 0 \\\\\n0 & 0 & 1 \\\\\n- aN & a(b-W) & v\n\\end{pmatrix}\n\\] At \\[\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) = (0,0,0)\n\\] we have \\[\n\\det(J(0,0,0) - \\lambda I)= \\left( \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v - ab) =0\n\\] and \\[\n\\lambda_1^1= \\frac 1 v &gt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 + 4 ab} } 2\n\\] Thus \\((0,0,0)\\) is a saddle point with a \\(2\\)-dim unstable manifold\nAt \\((W^\\ast_2, N^\\ast_2, P^\\ast_2) = (1,0,0)\\) we have \\[\n\\det(J(1,0,0) - \\lambda I)= \\left(- \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v + a(1-b)) =0\n\\] and \\[\n\\lambda_1^1= -\\frac 1 v &lt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 - 4 a(1-b)} } 2\n\\] Thus since, \\(0\\leq b &lt; 1\\) and \\(4(1-b)&gt;0\\), \\[\n\\begin{aligned}\n\\text{If } &&  v^2 \\geq  4 a(1-b) \\quad (1,0,0) \\text{ is a saddle with $2$-dim unstable manifold},\\\\\n\\text{If } &&  v^2 &lt;  4 a(1-b) \\quad (1,0,0) \\text{ is an unstable focus}\n\\end{aligned}\n\\]\nFor a travelling wave with \\(W\\geq 0\\) and \\(N \\geq 0\\) to exist we requite \\(v^2 \\geq 4 a(1-b)\\) and obtain a minimal wave speed \\[v_\\text{min}=2\\sqrt{a(1-b)}   \\quad \\text{ with } \\quad  0\\leq b&lt;1.\\]\nAt \\((W^\\ast_3, N^\\ast_3, P^\\ast_3) =(b, 1-b, 0)\\) we have \\[\n\\det(J(b,1-b,0) - \\lambda I)= \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b) = p(\\lambda) =0\n\\] To analyse \\(p(\\lambda)\\) we observe that local min and max of \\(p(\\lambda)\\) are independent of \\(a\\): \\[\np^\\prime(\\lambda) = 3 \\lambda^2 - 2 \\lambda \\left( v - \\frac b v\\right) - b = 0\n\\] and \\[\n\\lambda_{m,M}= \\frac 13 \\left[ \\left(v - \\frac bv \\right) \\pm \\sqrt{ \\left(v - \\frac bv\\right) ^2 + 3 b } \\right]\n\\] If \\(a=0\\) then we have eigenvalues \\[\n\\lambda_3^1 = 0, \\quad \\lambda_3^\\pm = \\frac 12 \\left( v - \\frac bv \\pm \\sqrt{\\left(v - \\frac bv\\right)^2 + 4 b} \\right)\\; .\n\\] Thus there exists a critical value \\(a^\\ast&gt;0\\) such that * for \\(a \\in (0, a^\\ast)\\) we obtain \\(2\\) real negative eigenvalues and \\(1\\) positive real eigenvalue and \\((b, 1-b, 0)\\) is a saddle with \\(2\\)-dim stable manifold and \\(1\\)-dim unstable manifold\n\nfor \\(a&gt;a^\\ast\\) we will have a pair of complex conjugate eigenvalues with negative real part and one real positive eigenvalue corresponding to \\(1\\)-dim unstable manifold.\n\nThis can be easily seen from a sketch of the cubic equation:\n\\[p(\\lambda) = \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b).\\]\nThus we have a possible heteroclinic connection between \\((1,0,0)\\) and \\((b, 1-b, 0)\\), i.e. between \\(2\\)-dim unstable manifold at \\((1,0,0)\\) and \\(2\\)-dim stable manifold at \\((b, 1-b, 0)\\), and therefore an existence of a travelling wave front solution for Equation 4.2 with\n\\[\n\\begin{aligned}\nu(t,x) \\to 1 \\; \\text{ as } x \\to - \\infty,  \\quad &\nu(t,x) \\to b \\; \\text{ as } x \\to +\\infty,  \\\\\nn(t,x) \\to 0 \\;  \\text{ as } x \\to - \\infty ,  \\quad &\nn(t,x) \\to 1-b \\; \\text{ as } x \\to +\\infty.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "BacterialChemotaxis.html#model-derivation",
    "href": "BacterialChemotaxis.html#model-derivation",
    "title": "5  Aggregation via Chemotaxis",
    "section": "5.1 Model derivation",
    "text": "5.1 Model derivation\nWe consider a model for the aggregation of Dictyostelium discoideum through the secretion of and chemotactic response to cAMP. We denote by \\(n({\\mathbf{x}}, t)\\) the density of amoebae and \\(a({\\mathbf{x}}, t)\\) the concentration of cAMP. The general conservation equation for the amoebae can be written:\n\\[\n\\frac{\\partial n}{\\partial  t} + \\nabla \\cdot {\\mathbf{J}} = f(n,a),\n\\]\nwhere \\(f(n,a)\\) models any reaction terms for the amoebae e.g. proliferation, and the flux is given by\n\\[\n{\\mathbf{J}} = {\\mathbf{J}}_{diffusion} + {\\mathbf{J}}_{chemotaxis}\n\\]\nAssuming Fickian diffusion and the general chemotactic flux stated earlier, the general * reaction-diffusion-chemotaxis*model for the amoebae responding to cAMP is given by:\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  \\underbrace{D_n \\nabla^2 n}_{diffusion} - \\underbrace{\\nabla \\cdot \\left( \\chi(a) n \\nabla a \\right)}_{chemotaxis} + f(n,a),   \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a + g(n,a),\n\\end{aligned}\n\\]\nwhere we have assumed Fickian diffusion for the cAMP and \\(g(a,n)\\) represents the kinetics i.e. source/sink terms, of cAMP.\nOne simple model has the following assumptiond:\n\\[f(n,a) = 0, \\;\\;\\; g(n,a) = \\mu n - \\delta a, \\;\\;\\; \\chi (a) = \\chi_0\\]\ni.e. \n\nthere are no kinetics for the amoebae - they simply move randomly via diffusion and undergo chemotaxis in response to cAMP;\nproliferation is neglected; - this is a reasonable assumption given the timescales involved, since they amoebae move on a faster timescale than they proliferate;\nthe amoebae are assumed to produce cAMP in proportion to their density, which means the more amoebae there are, the more cAMP (a reasonable first approximation);\nthe chemotactic function is taken to be a constant, again a reasonable first approximation;\n\\(D_a &gt; D_n\\) since chemicals diffuse faster than cells move randomly.\n\nUnder such assumption we obtain the model equation\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} & =  D_n \\nabla^2 n - \\chi_0 \\nabla \\cdot \\left( n \\nabla a \\right), \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a +  \\mu n - \\delta a,\n\\end{aligned}\n\\]\nwhich becomes, when considering a 1-dimensional domain \\([0,L]\\):\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  D_n \\frac{\\partial ^2 n}{\\partial x^2} - \\chi_0 \\frac{\\partial}{\\partial x} \\left( n \\frac{\\partial a}{\\partial x} \\right), \\\\\n  & & \\hspace{4.5cm} ( \\dagger ) \\\\\n\\frac{\\partial a}{\\partial  t} &=  D_a \\frac{\\partial ^2 a}{\\partial x^2}  +  \\mu n - \\delta a,\n\\end{aligned}\n\\tag{5.1}\\]\nwith zero flux boundary conditions:\n\\[\n\\begin{aligned}\nD_a \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L, \\\\\nD_n \\frac{\\partial n}{\\partial  x} - \\chi_0 n \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L,\n\\end{aligned}\n\\]\nwhich in this case reduce to:\n\\[\n\\frac{\\partial a}{\\partial  x} = \\frac{\\partial n}{\\partial  x} = 0, \\;\\;\\; x = 0,L\n\\]"
  },
  {
    "objectID": "BacterialChemotaxis.html#numerical-solutions",
    "href": "BacterialChemotaxis.html#numerical-solutions",
    "title": "5  Aggregation via Chemotaxis",
    "section": "5.2 Numerical solutions",
    "text": "5.2 Numerical solutions\nIn Figure 5.1 we plot numerical solution of @#eq-chemotaxis1d together with no-flux boundary condition. The initial data are uniformly sampled. Note the emergence of periodic spatial structure in both variables. These correspond to peaks and troughs of cell density. The cells produce chemoattractant, \\(a\\), and the this induces a chemtactic flux up the gradient in \\(a\\). Hence more cells move towards regions where \\(a\\) is high, more chemoattractant is produced in this region etc.\n\nWhat is the long-time behaviour of these solutions\nFor which parameters do we expect to see pattern formation?\nHow does spatial pattern depend on the initial data?\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\n\nT=80\nL=150\n\nmu=1.2\ndelta=0.1\nD_n=2.50\nD_a=2.5\nchi_0=1.4\n\nN_x=200\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=np.ones_like(x)+0.01*np.random.uniform(low=0.0, high=0.1, size=(N_x,))\nn_0=np.ones_like(x)\n\nu_0=np.concatenate((u_0,n_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    n=sol[0:N_x]\n    a=sol[N_x:2*N_x]\n\n\n\n    f_n=np.zeros_like(n)\n    f_a=np.zeros_like(n)\n\n    for i in range(1,N_x-2):\n      f_n[i]=D_n/dx**2*(n[i-1]-2*n[i]+n[i+1]) - chi_0*n[i]*1/dx**2*(a[i-1]-2*a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i-1])*(n[i+1]-n[i-1])\n\n    i=0\n    f_n[i]=D_n/dx**2*(-n[i]+n[i+1]) - chi_0*n[i]*1/(2*dx)**2*(-a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i])*(n[i+1]-n[i])\n\n    i=N_x-1\n    f_n[i]=D_n/dx**2*(n[i-1]-n[i])- chi_0*n[i]*1/(2*dx)**2*(a[i-1]-a[i])-chi_0/(2*dx)**2*(a[i]-a[i-1])*(n[i]-n[i-1])\n\n\n    for i in range(1,N_x-2):\n      f_a[i]=D_a/dx**2*(a[i-1]-2*a[i]+a[i+1]) \n    i=0\n    f_a[i]=D_a/dx**2*(-a[i]+a[i+1]) \n    i=N_x-1\n    f_a[i]=D_a/dx**2*(a[i-1]-a[i])\n\n    reaction_n=0\n    reaction_a=mu*n-delta*a\n\n    f_n=f_n+reaction_n\n    f_a=f_a+reaction_a\n\n    f= np.concatenate((f_n, f_a)) \n    return f  \n\nsol=odeint(LVPDErhs,u_0,t)\n\nn=sol[:,0:N_x]\na=sol[:,0:N_x]\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,n[0,:],'r')\nax[0].plot(x,n[16,:],'b')\nax[0].plot(x,n[32,:],'m')\nax[0].plot(x,n[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$n$')\n\nax[1].plot(x, a[0,:],'r--')\nax[1].plot(x, a[16,:],'b--')\nax[1].plot(x, a[32,:],'m--')\nax[1].plot(x, a[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$a$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.1: Numerical solution of bacterial chemtaxis model"
  },
  {
    "objectID": "BacterialChemotaxis.html#spatially-homogeneous-steady-states",
    "href": "BacterialChemotaxis.html#spatially-homogeneous-steady-states",
    "title": "5  Aggregation via Chemotaxis",
    "section": "5.3 Spatially Homogeneous Steady States",
    "text": "5.3 Spatially Homogeneous Steady States\nThe spatially homogeneous steady state \\((n^* , a^* )\\) satisfies:\n\\[\\mu n^* = \\delta a^*\\]\nand we now undertake a linear stability analysis to determine whether this is stable or unstable. If the above spatially homogeneous steady state is unstable, this will indicate that aggregation patterns may arise in the system."
  },
  {
    "objectID": "BacterialChemotaxis.html#stability-analysis",
    "href": "BacterialChemotaxis.html#stability-analysis",
    "title": "5  Aggregation via Chemotaxis",
    "section": "5.4 Stability Analysis",
    "text": "5.4 Stability Analysis\nIn a similar manner to previous stability analyses, we consider small perturbations around the spatially homogeneous steady state \\((n^* , a^* )\\), i.e.\n\\[\nn(x,t) = n^* + \\tilde{n}(x,t), \\;\\;\\; a(x,t) = a^* + \\tilde{a}(x,t)\n\\]\nwhere \\(\\tilde{n}(x,t)\\) and \\(\\tilde{a}(x,t)\\) are ``small” so that higher order terms can be neglected.\nNOTE Unlike previous stability analysis, these perturbations are both time and space dependent.\nSubstituting the above perturbations into equations \\(( \\dagger )\\), we neglect higher order terms and retain only linear terms. This is largely straightforward, but we provide some detail for the linearization of the chemotactic term i.e. \n\\[\\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial}{\\partial x} \\left( a^* + \\tilde{a} \\right) \\right] = \\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial \\tilde{a}}{\\partial x}  \\right] \\approx n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}\\]\nThe fully linearized system is then given by:\n\\[\n\\begin{aligned}\n\\frac{\\partial \\tilde{n}}{\\partial  t} & =  D_n \\frac{\\partial ^2 \\tilde{n}}{\\partial x^2} - \\chi_0 n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2} \\\\\n\\frac{\\partial \\tilde{a}}{\\partial  t} & =   D_a \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}  +  \\mu \\tilde{n} - \\delta \\tilde{a}.\n\\end{aligned}\n\\tag{5.2}\\]\nAlthough the above equations are linear, an explicit solution is non-trivial and we are required to make a further ansatz. We use the``separation of variables ” approach where \\[\n\\tilde{n}(t,x) = u(t) \\phi_1(x)\n\\] and \\[\n\\tilde a (t,x) = v(t) \\phi_2(x)\n\\]\n\\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}  \\phi_1  =   D_n  u\\frac{\\partial ^2 \\phi_1}{\\partial x^2} - \\chi_0 n^*  v\\frac{\\partial ^2 \\phi_1}{\\partial x^2} \\\\\n& \\frac{v}{\\partial  t}  \\phi_2=     D_a v \\frac{\\partial ^2  \\phi_2}{\\partial x^2}  +  \\mu u \\,  \\phi_1 - \\delta v\\,  \\phi_2, \\\\\n& u \\frac{\\partial \\phi_1}{\\partial x} = 0, \\quad   v \\frac{\\partial \\phi_2}{\\partial x} = 0 \\quad \\text{ for } \\; x = 0, \\; x=L.\n\\end{aligned}\n\\]\nWe assume that\n\\[\n\\phi_1 = \\phi_2 = \\phi,\n\\] where \\(\\phi_1\\) is the solution of the elliptic problem \\[\n\\begin{aligned}\n\\frac{d^2 \\phi}{dx^2} &= - k^2 \\phi && \\text{ in } \\; (0,L), \\\\\n\\frac{d \\phi}{dx} &= 0  && \\text{ for } \\; x=0, \\; x=L.\n\\end{aligned}\n\\] We can compute that solution of the equation for \\(\\phi\\) are of the form \\[\n\\phi(x) = A \\cos(kx) + B\\sin(kx).\n\\] Since \\(\\phi\\) satisfied zero Neumann boundary conditions we have that \\(\\phi(x) = A \\cos(kx)\\), with an arbitrary const \\(A\\), and \\(k = \\dfrac {m \\pi} L\\), ; \\(m \\in \\mathbb N\\).\nThen we have \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}  \\phi  =   - k^2 D_n  u \\phi +  \\chi_0 n^* k^2\\,  v \\, \\phi,  \\\\\n& \\frac{v}{\\partial  t} \\phi =   - k^2 D_a  \\, v \\phi  +  \\mu u \\,  \\phi - \\delta v\\,  \\phi,\n\\end{aligned}\n\\] and since \\(\\phi\\) is not identically zero on \\((0,L)\\) we obtain a system of linear ODEs for \\((u(t),v(t))\\) \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}    =   - k^2 D_n  u  +  \\chi_0 n^* k^2\\,  v,  \\\\\n& \\frac{v}{\\partial  t} =   - k^2 D_a  \\, v  +  \\mu u  - \\delta v.\n\\end{aligned}\n\\]\nWe know that solutions of linear ODEs have the form \\[\nu(t) = C_1 e^{\\lambda t} \\quad \\textrm{and} \\quad v(t) = C_2 e^{\\lambda t}\n\\] for some constant \\(C_1\\), \\(C_2\\) and \\(\\lambda\\) are eigenvalues of the corresponding matrix.\nThus we obtain \\[\n\\begin{aligned}\n\\lambda C_1 & =  - D_n k^2 C_1  + \\chi_0 n^* k^2 C_2,  \\\\\n\\lambda C_2 & = - D_a k^2 C_2 +  \\mu C_1 - \\delta C_2,\n\\end{aligned}\n\\] which can be written\n\\[\n\\left(\n\\begin{array}{cc}\n- D_n k^2 - \\lambda &  \\chi_0 n^* k^2 \\\\\n\\mu & - D_a k^2 -\\delta -\\lambda\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\nC_1 \\\\\nC_2\n\\end{array}\n\\right) = \\mathbf{0} .\n\\]\nRemark Notice that we obtained that \\(\\tilde n\\) and \\(\\tilde a\\) are of the form \\[\\tilde{n}(x,t) = C_1 e^{\\lambda t} e^{ikx}, \\;\\;\\; \\tilde{a}(x,t) = C_2 e^{\\lambda t} e^{ikx}.\\]\nFor a non-trivial solution (for non-trivial perturbations \\(\\tilde n\\), \\(\\tilde a\\)), i.e. \\(C_1 \\neq 0\\) and \\(C_2 \\neq 0\\), the determinant of the above matrix must be zero, and this leads to the following quadratic equation to be solved for \\(\\lambda\\):\n\\[\n\\lambda^2 + \\left( D_n k^2 + D_a k^2 + \\delta \\right) \\lambda + D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 = 0.\n\\]\nThis is of the form \\[\n\\lambda^2 + \\alpha \\lambda + \\beta = 0,\n\\]\nand so has roots: \\[\n\\lambda = \\frac{-\\alpha \\pm \\sqrt{\\alpha^2 - 4 \\beta}}{2}.\\]\nNOTE This has two real roots, since \\[\n\\alpha^2 - 4 \\beta &gt; 0\n\\] (see Exercise/Tutorial).\nFor stability, we require both roots to be negative. Since both roots are real, this leads to:\n\\[\n\\lambda &lt; 0  \\Leftrightarrow \\alpha &gt; 0 \\;\\;\\; \\text{and} \\;\\;\\; \\beta &gt;0.\n\\]\nNow \\[\\alpha = D_n k^2 + D_a k^2 + \\delta &gt; 0,\n\\] and so for stability, we require \\(\\beta &gt; 0\\) i.e. \n\\[\n\\begin{aligned}\n& & D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 &gt; 0 \\\\\n& & \\Rightarrow \\mu \\chi_0 n^* &lt;  D_n  \\left( D_a k^2 + \\delta \\right)\n\\end{aligned}\n\\] Hence, we will have instability when this condition is not satisfied i.e.  \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a k^2 + \\delta \\right).\n\\]\nThe precise value of \\(k^2\\) can be determined from the zero-flux boundary conditions i.e. \\[\nk  =  \\frac{m \\pi}{L}, \\;\\;\\; m = 1,2, \\dots\n\\] if we look for non-constant \\(\\phi\\).\nHence, we will have instability whenever \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a \\frac{m^2 \\pi^2}{L^2} + \\delta \\right), \\;\\;\\; m = 1,2, \\dots\n\\]\nIt can be shown (see Exercise/Tutorial), that \\(\\lambda (k^2)\\) ( or \\(\\lambda (m^2)\\)) is monotonic decreasing and hence the fastest growing mode is \\(m=1\\) i.e. we have an instability as long as \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( \\frac{D_a \\pi^2}{L^2} + \\delta \\right).\n\\]\nIn general, from the above inequality, we can say that there is a likelihood of instability (amoebae aggregation) if:\n\n\\(D_a\\), \\(D_n\\) and \\(\\delta\\) are all ``small’’\nL is ``large’’\n\\(\\chi_0 , \\mu , n^*\\) are ``large’’\n\nConsidering all other parameters to be fixed, in theory the above result states that it is possible to find a large enough value for the chemotactic coefficient \\(\\chi_0\\) to satisfy the instability condition i.e. chemotaxis induces instability and leads to aggregation of the amoebae."
  },
  {
    "objectID": "BacterialChemotaxis.html#exercise",
    "href": "BacterialChemotaxis.html#exercise",
    "title": "5  Aggregation via Chemotaxis",
    "section": "5.5 Exercise",
    "text": "5.5 Exercise\nFrom the results we have obtained we deduce that * chemotaxis has a destabilizing effect \\ * diffusion has a stabilizing effect on spatially homogeneous solutions\nIf this is true then one might expect the numerical results presented in Figure 5.1 to have spatially homogeneous solutions if the diffusion coefficient is made sufficiently large. * Can you test this by running the code for larger values of the parameter \\(D\\)? * Alternatively, what happens if you make the chemotaxic coefficient \\(\\chi_0\\) smaller? * what kind of aggregation patterns do you see if the system is solved in two spatial dimensions?\nHowever, there is one type of system where diffusion also has a destabilizing effect…\n\n\n\n\nDurston, AJ. 2013. “Dictyostelium: The Mathematician’s Organism.” Current Genomics 14 (6): 355–60."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion-mechanisms",
    "href": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion-mechanisms",
    "title": "6  Diffusion driven instability",
    "section": "6.1 Spatial Pattern Formation via Reaction-Diffusion Mechanisms",
    "text": "6.1 Spatial Pattern Formation via Reaction-Diffusion Mechanisms\n** Insert human embryogenesis image **\n\n6.1.1 Pattern in Developmental Biology\nEmbryology or developmental biology is that part of biology which is concerned with the formation, growth and development of the embryo from fertilization until birth. From the very moment of conception the embryo undergoes a process of dynamic change, brought about largely by cells responding to various chemical signalling cues e.g. migration, differentiation, proliferation. Figure \\(\\ref{embryogenesis}\\) shows some of the major changes in embryonic development which occur up to a few weeks after fertilization. Many of the processes occurring at this early stage are vital for the successful subsequent development of the embryo and also lay down basic structures (e.g. somites) that form the foundation of major body structures later on (e.g. the vertebrae of the spine) cf. Professor Lewis Wolpert: ‘It is not birth, marriage, or death, but gastrulation which is truly the most important time in your life.’\n\nThere are two main theories which describe how pattern arises during embryogenesis - one is the Turing pre-pattern theory, the other is the mechano-chemical theory. In the Turing pre-pattern theory, chemicals, or morphogens, react together and, if certain conditions concerning their reaction kinetics and diffusion rates are satisfied (to be derived in the next section), then a ## pre-pattern## of varying chemical concentrations is set up in the spatial domain. This means that throughout the spatial domain, the concentration levels of the chemicals will vary i.e. there will be a ##heterogeneous## distribution of chemical concentrations which is known as a pre-pattern. Any cells in the domain which subsequently encounter these varying levels of morphogens will then respond by, for example, proliferating differentially throughout the domain. In this way, the domain will then contain a {spatially heterogeneous} distribution of cell densities (i.e. a cellular pattern) which have responded to the morphogen pre-pattern. This pre-pattern theory was first proposed by Alan Turing (of Enigma Code fame) in his seminal 1952 paper, The chemical basis of morphogenesis Turing (1990). This was developed in more detailed manner by Alfred Gierer and Hans Meinhardt in another ground-breaking paper in 1972, A theory of biological pattern formation “A Theory of Biological Pattern Formation” (1972), where they introduced the concept of activating chemicals and inhibiting chemicals. J.D. Murray then applied the theory as an explanation for the generation of patterns observed on animal coats J. Murray (1981).\nIn the mechano-chemical theory, cells interact with their surroundings and by exerting forces perturb their local environment. The combination of cell migration/proliferation and cell-generated forces is sufficient in certain circumstances to create a spatially heterogeneous distribution of cell densities i.e. the pattern is generated simultaneously with the cell migration/proliferation. This alternative pattern formation theory was proposed by Murray and Oster J. D. Murray and Oster (1984) and is particularly appropriate for patterns generated in early embryogenesis by mesenchymal cells such as fibroblasts."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "href": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "title": "6  Diffusion driven instability",
    "section": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms",
    "text": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms\nWe now consider our general (dimensional) reaction-diffusion model for two chemicals or morphogens with concentrations \\(A({\\mathbf{x}}, t)\\) and \\(B({\\mathbf{x}}, t)\\) which react together and diffuse in some spatial domain:\n\\[\n\\begin{aligned}\n\\frac{\\partial A}{\\partial  t} & =  F(A,B)  + D_A \\nabla^2 A, \\\\\n\\frac{\\partial B}{\\partial  t} & =  G(A,B)  + D_B \\nabla^2 B,\n\\end{aligned}\n\\]\nwhere \\(F(A,B)\\) and \\(G(A,B)\\) describe the reaction kinetics between the two morphogens and \\(D_A, D_B &gt; 0\\) are the diffusion coefficients. Turing’s theory (Turing, 1952) The chemical basis of morphogenesis proposed that it was the diffusion of the substances \\(A, B\\) which led to the evolution of a spatially heterogeneous solution to arise i.e. a spatial pattern. This has given rise to the phrase diffusion-driven instability. This was a rather revolutionary and counter-intuitive proposal, since, as we have seen, diffusion normally has the opposite tendency i.e. to smooth or average out spatial heterogeneities, and to give rise to spatially homogeneous solutions.\nVarious forms can be considered for the kinetic functions \\(F\\) and \\(G\\). However, we will focus mainly on three specific classes as follows:\n\n6.2.1 Schnackenberg Kinetics\n\\[\nF(A,B) = k_1 - k_2 A + k_3 A^2 B, \\;\\;\\;\\; G(A,B) = k_4 - k_3 A^2 B\n\\]\n\\(k_1, k_2, k_3, k_4 &gt;0\\). The term \\(k_3 A^2 B\\) is autocatalytic, since the species \\(A\\) is involved in its own production. \n\n\n6.2.2 Activator-inhibitor kinetics cf. Gierer-Meinhardt system; Gierer & Meinhardt, 1972\n\\[\nF(A,B) = k_1 - k_2 A + \\frac{k_3 A^2}{B}, \\;\\;\\;\\; G(A,B) = k_4 A^2 - k_5 B\n\\]\n\\(k_1, k_2, k_3, k_4 , k_5 &gt; 0\\). Again, the term \\(k_3 A^2 / B\\) is autocatalytic.\n\n\n6.2.3 Substrate-inhibition system (Thomas, 1975)\n\\[F(A,B) = k_1 - k_2 A - H(A,B), \\;\\;\\;\\; G(A,B) = k_4 A^2 - k_4 B -H(A,B), \\]\n\\[H(A,B) = \\frac{k_5 AB}{k_6 + k_7 + k_8 A^2}\\;,\\]\n\\(k_i &gt; 0\\). In the original paper of Thomas (1975), \\(A\\) represents the concentration of oxygen (substrate) and \\(B\\) the concentration of uricase (enzyme). Substrate inhibition is evident in the term \\(k_8 A^2\\)."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#non-dimensionalization",
    "href": "DiffusionDrivenInstability.html#non-dimensionalization",
    "title": "6  Diffusion driven instability",
    "section": "6.3 Non-dimensionalization",
    "text": "6.3 Non-dimensionalization\nBefore proceeding with our analysis, it is prudent to non-dimensionalize each of the above systems. We illustrate this process for the Schnakenberg kinetics. Using the scaling,\n\\[\nu = A \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\;\\;\\;\\; v = B \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\;\\;\\;\\; t^* = \\frac{D_A t}{L^2}, \\;\\;\\;\\; x^* = \\frac{x}{L},\n\\]\nwhere \\(L\\) is a typical length scale, the dimensionless reaction-diffusion system with Schnakenberg kinetics becomes (upon dropping the \\(*\\)):\n\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma ( a - u + u^2 v ) + \\nabla^2 u = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma ( b - u^2 v ) + d \\nabla^2 v = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\tag{6.1}\\]\nwhere \\[\nd = \\frac{D_B}{D_A}, \\quad a = \\frac{k_1}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad b = \\frac{k_4}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad \\gamma = \\frac{L^2 k_2}{D_A}.\n\\]\nThe Gierer-Meinhardt and Thomas kinetics can be non-dimensionalized as follows:\n\\[\n\\begin{aligned}\nf(u, v) & =  a - b u + \\frac{u^2}{v},\ng(u,v) &= u^2 - v, \\\\\n\\end{aligned}\n\\] and \\[\n\\begin{aligned}\nf(u,v) & =  a - u - h(u,v), \\\\\ng(u,v) &= \\alpha (b - v) - h(u,v), \\\\\nh(u,v) & =  \\frac{\\rho u v}{1 + u + K u^2},\n\\end{aligned}\n\\] respectively, where \\(a , b, \\alpha, \\rho , K\\) are positive parameters (Exercise/Tutorial).\nAny reaction-diffusion system can be non-dimensionalized and scaled following the above procedure to take the following general form:\n\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\]\nwhere the parameter \\(d\\) is the ratio of the diffusion coefficients from the dimensional system and the parameter \\(\\gamma\\) can be interpreted in any one of the following ways:\n\n\\(\\gamma^{1/2}\\) is proportional to the linear size of the spatial domain in one-dimension. In two-dimensions, \\(\\gamma\\) is proportional to the area.\n\\(\\gamma\\) represents the relative strength of the reaction terms – an increase in \\(\\gamma\\) may represent an increase in the activity of some rate-limiting step in the reaction sequence.\nAn increase in \\(\\gamma\\) is equivalent to a decrease in the diffusion coefficient \\(d\\).\n\nNote that in the case where the parameter \\(d &gt; 1\\), this means that the original diffusion coefficients are not equal. Specifically, in the case of the Gierer-Meinhardt activator-inhibitor system, \\(d &gt;1\\) implies that the inhibitor diffuses more quickly than the activator [\\(d &gt; 1 \\Rightarrow D_B &gt; D_A\\) ]. The spatial implications of this are shown in figure \\(\\ref{AI}\\) – the inhibitor diffuses a greater distance than the activator, giving rise to what is known as local activation, long-range inhibition.\n** Insert activator_inhibitor here **"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#numerical-solution",
    "href": "DiffusionDrivenInstability.html#numerical-solution",
    "title": "6  Diffusion driven instability",
    "section": "6.4 Numerical solution",
    "text": "6.4 Numerical solution\nIn Figure Figure 6.1 we plot numerical solutions of Equation 6.1 with no flux boundary conditions.\nIn this numerical solution the initial condition are the spatially homogeneous steady state perturbed by uniformly sampled noise. As time evolves a spatial pattern emerges. The main idea from a biological perspeftive is that an unpatterned region of an embryo could undergo chemical reactions, with the result being a patterned chemcial field.\nSOme question that might arise:\n\nHow does pattern formation depend on model parameters?\nHow does pattern formation depend on domain size?\nHow does the pattern wavelength depend on model parameters?\nHow does the pattern depend on the initial conditions?\nHow can we numerically solve the reaction diffusion PDEs?\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\nT=3\nL=1\n\ngamma=650.0\na=0.2\nb=1.3\nd=30.0\n\nN_x=80\nN_t=50\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\n\nu_0=np.concatenate((u_0,v_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef ShcnackPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    v=sol[N_x:]\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n\n    i=0\n    f_u[i]=1/dx**2*(-u[i]+u[i+1])\n\n    i=N_x-1\n    f_u[i]=1/dx**2*(u[i-1]-u[i])\n\n\n    for i in range(1,N_x-2):\n      f_v[i]=d/dx**2*(v[i-1]-2*v[i]+v[i+1]) \n    i=0\n    f_v[i]=d/dx**2*(-v[i]+v[i+1]) \n    i=N_x-1\n    f_v[i]=d/dx**2*(v[i-1]-v[i])\n\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n    f= np.concatenate((f_u,f_v)) \n    return f  \n\nsol=odeint(ShcnackPDErhs,u_0,t)\n#soln = solve_ivp(ShcnackPDErhs,(0, T), u_0, method='Radau')\n\nu=sol[:,0:N_x]\nv=sol[:,N_x:]\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, v[0,:],'r--')\nax[1].plot(x, v[16,:],'b--')\nax[1].plot(x, v[32,:],'m--')\nax[1].plot(x, v[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$v$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 6.1: DDI with Schnackenberg kinetics\n\n\n\n\nIn Figure Figure 6.2 we consider a numerical solution of the Schnackenberg model on a 2D square domain with no-flux boundary conditions. Note\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\nT=5\nL=1\n\ngamma=650.0\na=0.2\nb=1.3\nd=25.0\n\nN_x=20\nN_t=30\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ny=np.linspace(0,L,N_x)\n\n[x,y]=np.meshgrid(x,y)\n\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\n\nu_0=np.concatenate((np.ravel(u_0),np.ravel(v_0)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\n\ndef ShcnackPDErhs2d(sol,t):\n\n    num_nodes=int(np.ceil(len(sol)/2))\n\n    u=sol[0:num_nodes]\n    v=sol[num_nodes:]\n\n\n    u=np.reshape(u,(N_x,N_x))\n    v=np.reshape(v,(N_x,N_x))\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n \n\n    for i in range(1,N_x-2):\n      for j in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-4*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-4*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n\n    i=0 \n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(-3*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(-3*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n\n    i=N_x-1\n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i,j+1]+v[i,j-1])   \n\n    j=0\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j+1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j+1]) \n\n    j =N_x-1\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j-1])  \n\n    i=0\n    j=0\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j+1]) \n\n    i=0\n    j=N_x-1\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j-1]) \n\n    i=N_x-1\n    j=0\n\n    f_u[i,j]=1/dx**2*(u[i-1,j]-2*u[i,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(v[i-1,j]-2*v[i,j]+v[i,j+1]) \n    \n    i=N_x-1\n    j=N_x-1\n\n\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i-1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i-1,j]+v[i,j-1]) \n\n\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n\n\n    f= np.concatenate((np.ravel(f_u),np.ravel(f_v))) \n    return f  \n\nsol=odeint(ShcnackPDErhs2d,u_0,t)\n#soln = solve_ivp(ShcnackPDErhs,(0, T), u_0, method='Radau')\n\n\nu_0=sol[0,0:N_x**2]\nv_0=sol[0,N_x**2:]\nu_0=np.reshape(u_0,(N_x,N_x))\nv_0=np.reshape(v_0,(N_x,N_x))\n\nu_m=sol[20,0:N_x**2]\nv_m=sol[20,N_x**2:]\nu_m=np.reshape(u_m,(N_x,N_x))\nv_m=np.reshape(v_m,(N_x,N_x))\n\nu=sol[-1,0:N_x**2]\nv=sol[-1,N_x**2:]\nu=np.reshape(u,(N_x,N_x))\nv=np.reshape(v,(N_x,N_x))\n\nfig, ax = plt.subplots(2,3)\nax[0,0].imshow(u_0)\nax[1,0].imshow(v_0)\nax[0,1].imshow(u_m)\nax[1,1].imshow(v_m)\nax[0,2].imshow(u)\nax[1,2].imshow(v)\n\n'''\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, v[0,:],'r--')\nax[1].plot(x, v[16,:],'b--')\nax[1].plot(x, v[32,:],'m--')\nax[1].plot(x, v[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$v$')\n'''\n\nplt.xlabel('$x$')\nplt.show()\n\n\n\n\n\nFigure 6.2: DDI with Schnackenberg kinetics in 2D"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#linear-stability-analysis-and-evolution-of-spatial-pattern-general-conditions-for-diffusion-driven-instability",
    "href": "DiffusionDrivenInstability.html#linear-stability-analysis-and-evolution-of-spatial-pattern-general-conditions-for-diffusion-driven-instability",
    "title": "6  Diffusion driven instability",
    "section": "6.5 Linear Stability Analysis and Evolution of Spatial Pattern: General Conditions for Diffusion-driven Instability",
    "text": "6.5 Linear Stability Analysis and Evolution of Spatial Pattern: General Conditions for Diffusion-driven Instability\nLet \\(\\Omega\\subset \\mathbb R^n\\) be a domain with smooth (sufficiently regular) boundary \\(\\partial \\Omega\\), with outward unit normal \\({\\mathbf{n}}\\). Our general, non-dimensional reaction-diffusion system is then:\n\\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t} = \\gamma\\, f(u,v)  +  \\nabla^2 u, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\\frac{\\partial v}{\\partial  t} = \\gamma\\, g(u,v)  + d \\nabla^2 v, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\n\\end{aligned}\n\\tag{6.2}\\] \\[\n\\begin{aligned}\n\\nabla u \\cdot {\\mathbf{n} } = 0, \\qquad \\nabla v \\cdot {\\mathbf{n} } = 0, \\qquad x\\in \\partial \\Omega, \\quad t&gt;0, \\\\\nu(x,0)  = u_0(x), \\qquad  v(x,0)  = v_0(x), \\qquad x\\in \\Omega\\; .\n\\end{aligned}\n\\tag{6.3}\\]\nA spatially homogeneous steady-state of the system Equation 6.2 satisfies \\[\nf(u,v) = 0 , \\qquad g(u,v) =0\n\\] and we denote it by \\((u_0, v_0)\\).\n\n6.5.1 Stability of spatially homogeneous steady states to spatially homogeneous perturbations\nBefore we consider the effect of the spatial terms in the system (i.e. diffusion), we first of all explore the stability of the underlying spatially homogeneous steady state, defined previously.\nConsider the following perturbations to the steady state \\((u_0 , v_0)\\): \\[\nu(x,t) = u_0 + \\tilde u(t), \\quad  v(x,t) = v_0 + \\tilde v(t), \\qquad \\|\\tilde u(t) \\| \\ll 1, \\quad  \\|\\tilde v(t) \\| \\ll 1.\n\\]\nSubstitute these into Equation 6.2 \\[\n\\begin{aligned}\n\\frac{d\\tilde u}{d t} = \\gamma\\, f(u_0 + \\tilde u,v_0 + \\tilde v) ,  \\\\\n\\frac{d \\tilde v}{d  t} = \\gamma\\, g(u_0 + \\tilde u,v_0 + \\tilde v) ,\n\\end{aligned}\n\\tag{6.4}\\]\nand using a Taylor expansion of \\(f\\) and \\(g\\) about \\((u_0, v_0)\\) we obtain the linearised system \\[\n\\begin{pmatrix}\n\\tilde u_t \\\\\n\\tilde v_t\n\\end{pmatrix}  = \\gamma J  \\begin{pmatrix}\n\\tilde u \\\\\n\\tilde v\n\\end{pmatrix},\n\\tag{6.5}\\] where \\[\nJ =J(u_0, v_0) =  \\begin{pmatrix}\nf_u & f_v  \\\\\ng_u & g_v\n\\end{pmatrix}_{(u_0 , v_0)} \\; .  \n\\]\nThe general solution of the above system of linear ODEs Equation 6.5 is\n\\[\n\\begin{pmatrix}\n\\tilde u(t) \\\\\n\\tilde v(t)\n\\end{pmatrix}   =  C_1 \\phi_1 e^{\\lambda_1 t} +  C_2 \\phi_2 e^{\\lambda_2 t}  ,\n\\] where \\(C_1\\), \\(C_2\\) are arbitrary constants, \\(\\lambda_1, \\lambda_2\\) are the eigenvalues of \\(\\gamma J\\), i.e. solutions of characteristic equation \\[\n\\det (\\gamma J - \\lambda I) = 0,\n\\] and \\(\\phi_1\\), \\(\\phi_2\\) are corresponding eigenvectors. It is easily seen that\n\\[\n\\lambda_{1,2} = \\frac \\gamma 2 \\left( \\text{tr} (J) \\pm \\sqrt{ \\text{tr}(J)^2 - 4 \\det(J)} \\right),\n\\]\nand thus a spatially homogeneous steady state \\((u_0, v_0)\\) is stable to spatially homogeneous perturbations if \\[\n{\\mathrm Re}( \\lambda_{1,2}) &lt;0,\n\\] i.e. if\n\\[\n\\begin{aligned}\n\\text{tr}(J) & = f_u + g_v &lt; 0, \\\\\n\\det(J) & = f_u g_v - f_v g_u &gt; 0.\n\\end{aligned}\n\\tag{6.6}\\]\nConditions Equation 6.6 provide restrictions on the parameters in the model equations Equation 6.2. We shall be interested only in such parameter values for which conditions Equation 6.6 are satisfied.\n\n\n6.5.2 Stability of spatially homogeneous steady states to spatially heterogeneous: spatially dependent, perturbations\nWe now consider perturbations about the spatially homogeneous steady state that are spatially dependent i.e.  \\[\nu(x,t) = u_0 + \\tilde u(x,t), \\quad  v(x,t) = v_0 + \\tilde v(x,t), \\qquad \\|\\tilde u(x,t) \\| \\ll 1, \\quad  \\|\\tilde v(x,t) \\| \\ll 1 .\n\\]\nOnce again substitute into Equation 6.2 and apply a Taylor expansion about \\((u_0, v_0)\\) to \\(f\\) and \\(g\\) to obtain the linearised problem\n\\[\n\\begin{aligned}\n\\frac{\\partial \\tilde u(x,t)}{\\partial t} = \\gamma\\, \\left(f_u \\tilde u(x,t) + f_v \\tilde v(x,t)\\right) + \\nabla^2 \\tilde u(x,t)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{\\partial \\tilde v(x,t)}{\\partial   t} = \\gamma\\,  \\left(g_u  \\tilde u(x,t) + g_v \\tilde v(x,t)\\right) +d \\nabla^2 \\tilde v(x,t)  ,  \\quad x\\in \\Omega, \\;  t &gt;0,  \\\\\n{\\mathbf{n}} \\cdot \\nabla \\tilde u (x,t) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla \\tilde v (x,t)  = 0, \\qquad   x\\in   \\partial \\Omega, \\; t &gt;0\n\\end{aligned}\n\\tag{6.7}\\]\nDefining \\[\nV(x,t) = \\begin{pmatrix}\n\\tilde u(x,t) \\\\\n\\tilde v(x,t)\n\\end{pmatrix}\n\\] we can rewrite Equation 6.7 as \\[\n\\frac{\\partial}{\\partial t}  V(x,t) = \\gamma J  V(x,t) + D \\nabla^2   V(x,t),\n\\]\nwhere\n\\[\nD =  \\begin{pmatrix}\n1 & 0 \\\\\n0 & d\n\\end{pmatrix}\\;.\n\\]\nWe shall consider a separation of variables approach i.e. \\[\nV(x,t) =\\begin{pmatrix}  \n\\bar u(t)  \\varphi_1(x)\n\\\\\n\\bar v(t)  \\varphi_2(x)\n\\end{pmatrix}\\;\n\\] and obtain \\[\n\\begin{aligned}\n\\frac{d \\bar u(t)}{d t}\\varphi_1(x) = \\gamma\\, \\left(f_u \\bar u(t) \\varphi_1(x) + f_v \\bar v(t) \\varphi_2(x)\\right) +\\bar u(t)  \\nabla^2 \\varphi_1(x)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{d \\bar v(t)}{d t}\\varphi_2(x) = \\gamma\\,  \\left(g_u  \\bar u(t) \\varphi_1(x) + g_v \\bar v(t) \\varphi_2(x)\\right) +  d \\bar v(t) \\nabla^2  \\varphi_2(x)  ,  \\quad x\\in \\Omega, \\;  t &gt;0,  \\\\\n{\\mathbf{n}} \\cdot \\nabla \\varphi_1(x) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla\\varphi_2 (x) = 0, \\qquad   x\\in   \\partial \\Omega, \\; t &gt;0\n\\end{aligned}\n\\tag{6.8}\\] with \\[\n\\bar u(t)\\, / \\hspace{-0.35 cm}\\equiv 0 \\quad \\textrm{and} \\quad  \\bar v(t)\\, / \\hspace{-0.35 cm}\\equiv 0\n\\] for \\(t&gt;0\\).\n\nLemma 6.1 Consider the spatial eigenvalue problem for the Laplacian \\(\\nabla^2\\) with zero-Neumann boundary conditions i.e.\n\\[\n\\begin{aligned}\n\\nabla^2 \\psi(x) = -k^2 \\psi(x) , \\qquad x \\in \\Omega ,  \\\\\n{\\mathbf{n}} \\cdot \\nabla \\psi(x) = 0 , \\qquad x\\in \\partial \\Omega \\; .\n\\end{aligned}\n\\tag{6.9}\\]\nFor a bounded domain \\(\\Omega\\) there exists a discrete set of eigenvalues \\[\n0 \\leq k^2_1&lt; k_2^2\\leq k_3^2\\leq \\ldots \\leq k_j^2\\leq \\ldots,\n\\] with \\[\nj \\in \\mathbb N, \\quad  \\textrm{and} \\quad k_j^2 \\to \\infty \\quad \\textrm{as}  \\quad j \\to \\infty.\n\\]\nMoreover, the eigenfunctions \\(\\{\\psi_k(x) \\}\\) form an orthogonal set of basis functions of the corresponding functional space (i.e. \\(L^2(\\Omega)\\), \\(H^1(\\Omega)\\)).\n\nThus we can look for the spatial component of the solution as follows: \\[\n\\varphi(x) = \\begin{pmatrix}  \n\\varphi_1(x) \\\\\n\\varphi_2(x)\n\\end{pmatrix} = \\sum_k C_k \\psi_k(x), \\qquad C_k =  \\begin{pmatrix}  C_k^1 \\\\ C_k^2 \\end{pmatrix} \\in \\mathbb R^2 \\;\n\\] and \\[\n\\begin{aligned}\nV(x,t) =\\sum_k \\hat V_k(t) \\psi_k(x), \\qquad \\textrm{ where}\n\\quad \\hat V_k(t)=\n\\begin{pmatrix}  \nC_k^1 \\; \\bar u(t)\n\\\\\nC_k^2 \\; \\bar v(t)\n\\end{pmatrix}.\n\\end{aligned}\n\\tag{6.10}\\]\nThen since \\(\\nabla^2 \\psi_k(x) = - k^2 \\psi_k(x)\\) we obtain\n\\[\nD \\nabla^2  V(x,t) = D \\nabla^2 \\left[ \\sum_k \\hat V_k(t) \\psi_k(x) \\right]   = \\sum_k D \\hat V_k(t) \\nabla^2 \\psi_k(x)=\n- \\sum_k k^2 D \\hat V_k(t)  \\psi_k(x)\n\\]\nand hence\n\\[\n\\sum_k \\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n  \\sum_k \\gamma J \\hat V_k(t) \\psi_k(x) -  \\sum_k k^2  D \\hat V_k(t) \\psi_k(x).\n\\]\nSince \\(\\{\\psi_k(x) \\}\\) is a orthogonal basis we obtain that\n\\[\n\\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n   \\gamma J  \\hat V_k(t) \\psi_k(x) -  k^2  D \\hat V_k(t) \\psi_k(x),\n\\] for each \\(k\\). Finally, since \\[\n\\psi_k(x)\\;  /\\hspace{-0.35 cm }\\equiv 0\n\\] in \\(\\Omega\\) this implies for each \\(k\\) a system of ODEs:\n\\[\n\\begin{aligned}\n\\frac{d}{d t}  \\hat V_k(t)   &=   \\left(\\gamma J  -  k^2  D\\right) \\hat V_k(t) &= \\tilde J\\hat V_k(t) ,\n\\end{aligned}\n\\tag{6.11}\\]\nwhere \\(\\tilde J\\) is a ``modified’’ Jacobian:\n\\[\n\\tilde{J} =  \\begin{pmatrix}\n\\gamma f_u - k^2 & \\gamma f_v \\\\\n\\gamma g_u & \\gamma g_v - d k^2\n\\end{pmatrix}\\;.\n\\]\nNow solutions of Equation 6.11 are of the form \\[\n\\hat V_k(t) = e^{\\lambda t} P_k\n\\] with \\(P_k \\in \\mathbb R^2\\), where, since \\(P_k\\neq 0\\) (looking for nontrivial solutions), we find that \\(\\lambda\\) are the eigenvalues of \\(\\tilde J\\) , i.e. \nsolutions of the characteristic equation \\[\n\\det(\\tilde J - \\lambda I) = \\det ( \\gamma J - k^2 D - \\lambda I) =0.\n\\tag{6.12}\\]\nEvaluating the above determinant, we arrive at the equation: \\[\n\\lambda^2 + [ k^2 (1 + d) - \\gamma (f_u + g_v) ] \\lambda + h(k^2) = 0,\n\\tag{6.13}\\] where \\[\nh(k^2) = dk^4 - \\gamma (df_u + g_v) k^2 + \\gamma^2 | J | .\n\\tag{6.14}\\]\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# genera\nk_sq=np.linspace(0,25,100)\n\n\ngamma=10\nd_1=0.02\nd_2=3\nd_3=6\n\n\nf_u=0.2\ng_v=-0.5\nterm1=d*f_u+g_v\nJ=1.0 # positive determinant\n\n\n\ndef Computeh(k_sq,d):\n  h=d*k_sq**2-gamma*(term1)*k_sq+ gamma**2*J\n  return h\n\ndef SolveReLambda(k_sq,d):\n   # a lam^2 + b * lam +c\n    a=1\n    b= k_sq*(1+d)-gamma*(f_u+g_v)\n    c= Computeh(k_sq,d)\n    lambda_m= (-b-np.sqrt(b**2-4*a*c))/(2*a)\n    lambda_p= (-b+np.sqrt(b**2-4*a*c))//(2*a)\n    return lambda_m,lambda_p\n\ndef TestDDIconditions(d):\n\n    cond_1=f_u+g_v\n    cond_2 = J\n    cond_3 = d*f_u+g_v\n    cond_4 = (d*f_u+g_v)**2-4*d*J\n\n    cond_true=np.zeros((4,1),dtype=bool)\n    cond_true[0]=(cond_1&lt;0) \n    cond_true[1]= (cond_2&gt;0) \n    cond_true[2]= (cond_3&gt;0)\n    cond_true[3]=(cond_4&lt;0)\n\n\n    return cond_true\n\nh_1=Computeh(k_sq,d_1)\nh_2=Computeh(k_sq,d_2)\nh_3=Computeh(k_sq,d_3)\n\nl_1_m, l_1_p = SolveReLambda(k_sq,d_1)\nl_2_m, l_2_p = SolveReLambda(k_sq,d_2)\nl_3_m, l_3_p = SolveReLambda(k_sq,d_3)\n\nconditions_satisfied1=TestDDIconditions(d_1)\nconditions_satisfied2=TestDDIconditions(d_2)\nconditions_satisfied3=TestDDIconditions(d_3)\n\nprint(conditions_satisfied1,conditions_satisfied2,conditions_satisfied3)\n\nfig, ax=plt.subplots()\nax.plot(k_sq,h_1,'r',k_sq,h_2,'k',k_sq,h_3,'m')\nplt.grid()\nax.set_xlabel('$k^2$')\nax.set_ylabel('$h$')\nax.legend(['d='+str(d_1),'d='+str(d_2),'d='+str(d_3)])\nplt.show()\n\nfig, ax=plt.subplots()\nax.plot(k_sq,np.real(l_1_m),'r',k_sq,np.real(l_2_m),'k',k_sq,np.real(l_3_m),'m')\nax.plot(k_sq,np.real(l_1_p),'r--',k_sq,np.real(l_2_p),'k--',k_sq,np.real(l_3_p),'m--')\n\nplt.grid()\nax.set_xlabel('$k^2$')\nax.set_ylabel('$\\Re{\\lambda}$')\nax.set_ylim([-20,5])\n\nax.legend(['d='+str(d_1),'d='+str(d_2),'d='+str(d_3)])\nplt.show()\n\n\n[[ True]\n [ True]\n [False]\n [False]] [[ True]\n [ True]\n [ True]\n [ True]] [[ True]\n [ True]\n [ True]\n [ True]]\n\n\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62695/2851046048.py:30: RuntimeWarning: invalid value encountered in sqrt\n  lambda_m= (-b-np.sqrt(b**2-4*a*c))/(2*a)\n/var/folders/m_/vc0kz_0x6ls5n4qnksq052jw0000gp/T/ipykernel_62695/2851046048.py:31: RuntimeWarning: invalid value encountered in sqrt\n  lambda_p= (-b+np.sqrt(b**2-4*a*c))//(2*a)\n\n\n\n\n\n(a) A plot of \\(h(k^2)\\) against k^2.\n\n\n\n\n\n\n\n(b)\n\n\n\nFigure 6.3: ?(caption)\n\n\nNOTE: From Equation 6.12, Equation 6.13 we can recover the characteristic equation for the spatially homogeneous perturbation when \\(k=0\\), i.e.  \\[\n\\tilde J \\Big|_{k=0} = ( \\gamma J - k^2 D )\\Big|_{k=0} = \\gamma J.\n\\]\nThus the steady state \\((u_0, v_0)\\) is unstable to spatially heterogeneous perturbations iff \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\text{and/or } \\quad {\\mathrm Re}(\\lambda_2) &gt;0,\n\\] where \\(\\lambda_{1,2}\\) are solutions of Equation 6.12, Equation 6.13.\nNow for \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\text{and/or } \\quad {\\mathrm Re}(\\lambda_2) &gt;0\n\\] to be satisfied we require \\[\n\\text{tr}(\\tilde J) &gt; 0 \\quad \\text{ or } \\quad \\det(\\tilde J) &lt;0 \\; .\n\\]\nConsider first \\({\\mathrm tr} (\\tilde{J})\\). We have \\[\n\\text{tr}(\\tilde J) = \\gamma ( f_u+ g_v) - k^2(1+d) &lt; 0, \\hspace{4 cm}  \n\\] since \\(\\gamma &gt; 0\\) and \\[\nf_u+ g_v &lt; 0\n\\] by the stability condition for the spatially homogeneous perturbation Equation 6.6.\nThus instability to the spatially heterogeneous perturbation can only occur if \\[\n\\det(\\tilde J) &lt; 0\n\\] and so we require: \\[\n\\det(\\tilde J) = h(k^2) = dk^4  - \\gamma ( d\\,  f_u + g_v) k^2 + \\gamma^2 \\det(J) &lt; 0.\n\\] From the spatially homogeneous stability conditions Equation 6.6 we have \\(\\det(J) &gt;0\\). Thus \\(h(k^2)&lt;0\\) is possible only if \\[\nd f_u + g_v &gt;0.\n\\tag{6.15}\\] However, once again, due to Equation 6.6, we have \\(f_u+ g_v &lt;0\\), and so we can conclude that \\(d\\neq 1\\) and \\(f_u\\) and \\(g_v\\) must have opposite signs.\nCondition Equation 6.15 is necessary but not sufficient to ensure \\(h(k^2) &lt;0\\). In order to guarantee that \\(h(k^2) &lt; 0\\), the minimum value \\(h_{{\\mathrm min}}\\) must be negative. Differentiating Equation 6.14 w.r.t. \\(k^2\\), we find that:\n\\[\nk^2_{m} = \\gamma \\frac{d f_u + g_v}{2d} \\;\\; \\Rightarrow \\;\\; h_{{\\mathrm min}} = \\gamma^2 \\left[ | J | - \\frac{(df_u + g_v)^2}{4d} \\right].\n\\tag{6.16}\\]\nThus the condition that \\(h(k^2) &lt; 0\\) for some \\(k^2\\) is:\n\\[\n\\frac{(df_u + g_v)^2}{4d} &gt; |J|.\n\\]\nThe transition from stability to instability i.e. bifurcation, occurs when \\(h_{{\\mathrm min}} = 0\\). From Equation 6.16, this means at bifurcation we have \\[\n|J| = \\frac{(df_u + g_v)^2}{4d}.\n\\tag{6.17}\\]\nFor a fixed set of kinetics parameters, this means that we have a critical diffusion coefficient \\(d_c \\;(&gt;1)\\), which, after re-arranging Equation 6.17, is the appropriate root of\n\\[\nq(d_c) = d^2_c f_u^2 + 2( 2 f_v g_u - f_u g_v) d_c + g_v^2 =0.\n\\tag{6.18}\\]\nFinally, we note that using Equation 6.16, Equation 6.17, the critical wave number can be written: \\[\nk_c^2 =\\gamma  \\frac{( d_c f_u + g_v)} { 2 d_c} = \\gamma \\left[ \\frac {|J|}{d_c} \\right]^{1/2} = \\gamma \\left[ \\frac{f_u g_v - f_v g_u}{d_c} \\right]^{1/2}.\n\\tag{6.19}\\]\nFigure 6.3 (a) shows a schematic diagram of the (quadratic) function \\(h(k^2)\\) for three different values of the diffusion coefficient \\(d\\):\n\n\\(d &lt; d_c, \\; h(k^2) &gt; 0\\), and there is no pattern;\n\\(d = d_c, \\; h_{{\\mathrm{min}}} = 0\\), critical case;\n\\(d &gt; d_c, \\; h(k^2) &lt; 0\\), and there is pattern.\n\nHence we can see from Equation 6.13 that whenever \\(h(k^2) &lt; 0\\) the curve \\(\\lambda(k^2)\\) is positive for the same range of wavenumbers that make \\(h(k^2)\\) negative. The range of unstable wavenumbers \\[\nk^2_1 &lt; k^2 &lt; k^2_2\n\\] can be found from the roots of Equation 6.14, \\(h(k^2) = 0\\):\n\\[\n\\begin{aligned}\nk^2_1 &= \\gamma \\frac{(df_u + g_v) - \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2} }{2d} &lt; k^2  \\\\\n&&lt; \\gamma \\frac{(df_u + g_v) +  \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2}}{2d} = k^2_2\n\\end{aligned}\n\\tag{6.20}\\]\nFigure 6.3 (b) shows a schematic diagram of \\({\\mathrm Re}\\lambda (k^2)\\) for three different values of the diffusion coefficient \\(d\\): * $d &lt; d_c, ; \\({\\mathrm Re}\\lambda (k^2)\\) &lt; 0, k^2 $, and there is no pattern; * \\(d = d_c, \\; k^2_c = 0\\), critical case;\nThe expression \\(\\lambda = \\lambda (k^2)\\) is known as the dispersion relation and the plot of \\({\\mathrm Re} \\lambda\\) against \\(k^2\\) is known as the dispersion curve.\nFrom the previous analysis, within the unstable range of wavenumbers \\((k^2_1 , k^2_2)\\), \\({\\mathrm Re}\\lambda (k^2) &gt; 0\\) has a maximum value at wavenumber \\(k^2_m\\) given by Equation 6.16 when \\(d &gt; d_c\\). This implies that there is a fastest growing mode in the solution Equation 6.10 of our linearised system Equation 6.8.\nRecalling Equation 6.10,\n\\[\nV(x,t) = \\sum_k C_k e^{\\lambda(k^2) t} \\, \\psi_k(x),\n\\] and noting the above analysis, this implies that as \\(t\\to \\infty\\) the dominant contributions in the above sum are those for which \\({\\mathrm Re} \\lambda(k^2) &gt; 0\\), since all other modes will tend to zero exponentially fast as \\(t\\to \\infty\\). Thus, for large \\(t\\), the solution is effectively given by: \\[\nV(x,t) \\approx \\sum_{k_{1}}^{k_2} C_k e^{\\lambda(k^2) t} \\, \\psi_k(x) \\; .\n\\]\n%The critical value of \\(d=d_c\\) at which the bifurcation to instability occurs is defined by \\(h_{\\textrm{min}} =0\\), i.e. such value of \\(d\\) at which \\(h(k^2)=0\\) has a double root.\n** include figure dispersion **\n\n\nNOTE\nAll the previous calculations concern a linear stability analysis carried out about a spatially homogeneous steady state of the system Equation 6.2. This linear theory indicates that for \\(d &gt; d_c\\) there exists a finite number of linearly unstable spatial eigenfunctions which grow exponentially as \\(t \\to \\infty\\). However, this linear theory holds only when we are close to the steady state i.e. it only holds for small perturbations. In the full nonlinear system the exponentially growing (unbounded) modes will eventually be bounded by the nonlinear terms and so bounded, stable spatial patterns characterised by the corresponding wavenumbers will be formed.\nSummary\nWe have obtained conditions for the generation of spatial patterns via systems of reaction-diffusion equations of the general form Equation 6.2. Such systems involve two chemicals or morphogens reacting and diffusing together to generate a chemical pre-pattern that underlies a subsequent cellular pattern. The four conditions are as follows:\n\\[\n\\begin{aligned}\nf_u + g_v &&lt; 0, \\\\\nf_u g_v - f_v g_u &&gt; 0, \\\\\nd f_u + g_v &&gt; 0, \\\\\n(d f_u + g_v)^2 - 4d (f_u g_v - f_v g_u)^2 &&lt; 0 , \\nonumber\n\\end{aligned}\n\\tag{6.21}\\] with all partial derivatives being evaluated at the spatially homogeneous steady state \\((u_0 , v_0)\\).\nFrom the first and third conditions, \\(d \\neq 1\\) and \\(f_u\\) and \\(g_v\\) must be of different signs. For each of the reaction kinetics mentioned here (Schnakenberg, Gierer-Meinhardt, Thomas), we have that \\(f_u &gt; 0, g_v &lt; 0\\) and so this implies that \\(d &gt; 1\\).\nIf the conditions Equation 6.21 are satisfied, then there is a range of unstable wavenumbers given by Equation 6.20 which give rise to a spatial pattern. The spatial patterns which initially grow are those spatial eigenfunctions \\(\\psi_k(x)\\) whose wavenumbers \\(k\\) are such that \\(k_1 &lt; k &lt; k_2\\).\nIn most biological systems, the kinetic parameters and diffusion coefficients are fixed. This means that the only variable parameter in the system is \\(\\gamma\\) which as we have seen is related to the size of the domain under consideration. This has implications when considering patterns on finite domains, as will be seen in the next section."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#exercises",
    "href": "DiffusionDrivenInstability.html#exercises",
    "title": "6  Diffusion driven instability",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\nDemonstrate that the derived results are consistent with numerical solutions. Some predictions to test:\n\nNo patterning when diffusion coefficients are equal\nHow does spatial pattern formation change as you try values of parameters \\(a\\) and \\(b\\)?\nCan you correlate the observation of pattern to the conditions for DDI being satisfied?\nwhat about different kinetics (e.g. Gierer-Meinhardt, Thomas models)?"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#references",
    "href": "DiffusionDrivenInstability.html#references",
    "title": "6  Diffusion driven instability",
    "section": "6.7 References",
    "text": "6.7 References\n\n\n\n\n“A Theory of Biological Pattern Formation.” 1972. Kybernetik 12: 30–39.\n\n\nMurray, James D, and George F Oster. 1984. “Generation of Biological Pattern and Form.” Mathematical Medicine and Biology: A Journal of the IMA 1 (1): 51–75.\n\n\nMurray, JD610574. 1981. “A Pre-Pattern Formation Mechanism for Animal Coat Markings.” Journal of Theoretical Biology 88 (1): 161–99.\n\n\nTuring, Alan Mathison. 1990. “The Chemical Basis of Morphogenesis.” Bulletin of Mathematical Biology 52: 153–97."
  },
  {
    "objectID": "NumericalMethods.html#python-libraries",
    "href": "NumericalMethods.html#python-libraries",
    "title": "7  Numerical methods in Python",
    "section": "7.1 Python libraries",
    "text": "7.1 Python libraries\n\nmatplotlib\nnumpp\nscipy"
  },
  {
    "objectID": "NumericalMethods.html#single-pdes",
    "href": "NumericalMethods.html#single-pdes",
    "title": "7  Numerical methods in Python",
    "section": "7.2 Single PDEs",
    "text": "7.2 Single PDEs\n\n7.2.1 MOL\n\n\n7.2.2 Spatial discretisation\n\n\n7.2.3 odeint\n\n\n7.2.4 implementing boundary conditions\n\n\n7.2.5 Identifying parameters"
  },
  {
    "objectID": "NumericalMethods.html#systems-of-pdes",
    "href": "NumericalMethods.html#systems-of-pdes",
    "title": "7  Numerical methods in Python",
    "section": "7.3 Systems of PDEs",
    "text": "7.3 Systems of PDEs"
  },
  {
    "objectID": "linearstablityanalysis.html",
    "href": "linearstablityanalysis.html",
    "title": "8  Linear stability analysis of a system of nonlinear ODES",
    "section": "",
    "text": "Consider a system of ODEs\n\\[\\begin{equation*}\n\\frac{du}{dt} = f(u) \\quad \\text{ with } \\quad u \\in \\mathbb R^m\\quad  \\text{ and }\\quad  t \\in \\mathbb R.\n\\end{equation*}\\]\nAs an example consider \\(m=2\\): \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{du_1}{dt} =F(u_1, u_2) ,\\\\\n\\dfrac{du_2}{dt} =G(u_1, u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{8.1}\\]\n\\((u_1, u_2) = (u^\\ast_1, u^\\ast_2)\\) is the steady state of the system Equation 8.1, i.e. \\[\n\\dfrac{du_1}{dt} = 0\n\\] and \\[\n\\dfrac{du_2}{dt} = 0\n\\].\nTo determine the behaviour of the solution near a steady state we consider \\[\nu_1(t) = u^\\ast_1 + \\bar u_1(t), \\quad  u_2(t) = u^\\ast_2 + \\bar u_2(t)\n\\] \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d(u^\\ast_1+ \\bar u_1)}{dt} =F(u^\\ast_1+ u_1, u^\\ast_2+ \\bar u_2) ,\\\\\n\\dfrac{d(u^\\ast_2+\\bar u_2)}{dt} =G(u^\\ast_1+u_1,u^\\ast_2+\\bar u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{8.2}\\]\nThen using the fact that \\((u^\\ast_1, u^\\ast_2)\\) is a steady state and applying Taylor series expansion about \\(( u^\\ast_1, u^\\ast_2)\\) and assuming that\n\\[\n\\sup_{t}|\\bar u_1(t)| \\ll 1, \\sup_{t}|\\bar u_2(t)|\\ll 1\n\\] (small perturbations of the steady state) we have \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d  \\bar u_1}{dt} =F(u^\\ast_1, u^\\ast_2) +\\dfrac{\\partial F}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial F}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\, \\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2) ,\\\\\n\\dfrac{d \\bar u_2}{dt} =G(u^\\ast_1,u^\\ast_2)+ \\dfrac{\\partial G}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial G}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\,\\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2)\n\\end{cases}\n\\end{aligned}\n\\tag{8.3}\\]\nThus since \\((u^\\ast_1, u^\\ast_2)\\) is a steady state, i.e. \\(F(u^\\ast_1, u^\\ast_2) =0\\) and \\(G(u^\\ast_1, u^\\ast_2) =0\\) (ignoring negligibly small higher order terms) we obtain system of linearised equations \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{d  \\bar u_1}{dt} \\\\\n\\dfrac{d \\bar u_2}{dt}\n\\end{pmatrix} = J( u^\\ast_1, u^\\ast_2) \\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\end{aligned}\n\\tag{8.4}\\] where the Jacobian matrix \\(J(u^\\ast_1, u^\\ast_2)\\) is defined as \\[\nJ( u^\\ast_1, u^\\ast_2) = \\begin{pmatrix}\n\\dfrac{\\partial F(u^\\ast_1, u^\\ast_2) }{\\partial u_1}\\; \\; & \\dfrac{\\partial F(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\\\\\n\\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_1} & \\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\n\\end{pmatrix}\n\\] Therefore the behaviour of the nonlinear system Equation 8.1 near the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by solutions of system of linear ODEs Equation 8.4.\nSince Equation 8.4 is linear we can write the general solution of (eqsystem_ode14?) \\[\\begin{equation}\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix} = e^{\\lambda_1 t} \\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix}   +\ne^{\\lambda_2 t} \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\end{equation}\\] where \\(\\lambda_1\\) and \\(\\lambda_2\\) are eigenvalues of Jacobian matrix \\(J( u^\\ast_1, u^\\ast_2)\\) and \\[\n\\phi=\\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix} \\quad \\textrm{and} \\quad  \\psi= \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\] are corresponding eigenvectors.\nDenote \\[\\bar u=\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\].\nIf both \\(\\lambda_{1,2} \\neq 0\\) then the stability of the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by the real part of the eigenvalues \\(\\lambda_{1,2}\\).\n\nIf either \\(\\mathcal Re (\\lambda_1)&gt;0\\) or \\(\\mathcal Re (\\lambda_2)&gt;0\\) then\n\\(|\\bar u(t)| \\to +\\infty\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is unstable.\nIf \\(\\mathcal Re (\\lambda_1)&lt;0\\) and \\(\\mathcal Re (\\lambda_2)&lt;0\\) then\n\\(|\\bar u(t)| \\to 0\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is stable.\nIf \\(\\lambda_1=0\\) or \\(\\lambda_2=0\\) we have to consider higher order terms.\n\nDenote \\(\\beta = \\textrm{tr} (J( u^\\ast_1, u^\\ast_2))\\) and \\(\\gamma= \\det(J( u^\\ast_1, u^\\ast_2))\\). Then the characteristic (eigenvalue) equation for \\(J( u^\\ast_1, u^\\ast_2)\\) is \\[\n\\lambda^2 - \\beta \\lambda + \\gamma = 0 \\; , \\quad  \\lambda_{1,2} = \\frac{ \\beta \\pm \\sqrt{ \\beta^2 - 4 \\gamma}} 2.\n\\] Then\n\nIf \\(\\gamma &lt;0\\) we have two real eigenvalues with different signs, i.e. \\(\\lambda_1 &lt; 0 &lt; \\lambda_2\\). Thus \\((u^\\ast_1, u^\\ast_2)\\) is a saddle.\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 \\geq 4\\gamma\\) we have two real eigenvalues with the same sign. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a node.\n\nif \\(\\beta &gt;0\\) then \\(\\lambda_2 &gt; \\lambda_1 &gt;0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable node.\nif \\(\\beta &lt;0\\) then \\(\\lambda_1 &lt; \\lambda_2 &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable node.\n\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 &lt; 4\\gamma\\) we have two complex conjugate eigenvalues. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a focus (spiral).\n\nif \\(\\beta &gt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &gt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable focus\nif \\(\\beta &lt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable focus.\nIf \\(\\beta =0\\) then for linear system we have a centre, but in general we have no information on the behaviour of the nonlinear system near the steady state \\((u^\\ast_1, u^\\ast_2)\\).\n\n\n** Insert figure phase plane **"
  }
]