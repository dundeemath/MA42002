[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA42002",
    "section": "",
    "text": "Introduction\nWelcome to MA42002 Mathematical Biology II.\nMy name is Philip Murray and I am the module lead."
  },
  {
    "objectID": "index.html#how-to-contact-me",
    "href": "index.html#how-to-contact-me",
    "title": "MA42002",
    "section": "How to contact me?",
    "text": "How to contact me?\n\nemail: pmurray@dundee.ac.uk\noffice: G11, Fulton Building"
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "MA42002",
    "section": "Lecture notes",
    "text": "Lecture notes\nYou can find lecture notes for the module on this page. If you would like a pdf this can be easily generated by clicking on the pdf link on the top left of the webpages. I will occasionally edit/update the notes as we proceed through lectures. If you spot any errors/typos/inconsistencies/omissions etc. please let me know."
  },
  {
    "objectID": "index.html#reading",
    "href": "index.html#reading",
    "title": "MA42002",
    "section": "Reading",
    "text": "Reading\nMathematical Biology II, Murray (2003)"
  },
  {
    "objectID": "index.html#python-codes",
    "href": "index.html#python-codes",
    "title": "MA42002",
    "section": "Python codes",
    "text": "Python codes\nI have provided Python codes for most of the figures in the notes (you can unfold code section by clicking `Code’). Note that the Python code does not appear in the pdf.\nMany of you have taken the Introduction to Programming module at Level 2 and have therefore some experience using Python. I strongly encourage you to use the provided codes as a tool to play around with numerical solutions of the various models that we will be working on. The codes should run as standalone Python codes."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "MA42002",
    "section": "References",
    "text": "References\n\n\n\n\nMurray, James Dickson. 2003. Mathematical Biology: II: Spatial Models and Biomedical Applications. Vol. 3. Springer."
  },
  {
    "objectID": "conservationequations.html#sec-conservation",
    "href": "conservationequations.html#sec-conservation",
    "title": "1  Conservation equations",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nMany biological systems are spatio-temporal, i.e. concentrations of biochemicals, densities of cells etc. depend on spatial position as well time. To describe such cases we must relax a major assumption that was made in Mathematical Biology I (MA32009): spatial homogeneity. We now models biological system using partial differential equations.\nA conservation equation is the most fundamental statement through which changes in the distribution of the density (or concentration, temperature) is described. \\[\n\\begin{pmatrix}\n\\text{rate of change}\\\\\n\\text{ in the population density}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{spatial movement}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{birth, growth, death},\\\\\n\\text{production or degradation}\\\\\n  \\text{due to chemical reactions}\n\\end{pmatrix}\n\\]\n\n1.1.1 Notation\nWe will consider \\(x \\in \\mathbb R^n\\), \\(t \\in [0, \\infty)\\) and functions \\(c: \\mathbb R^n \\times [0, \\infty) \\to \\mathbb R\\), where \\(n=1,2,3\\). For example:\n\n\\(c(x,t)\\) - the density of a population [number per volume] at position \\(x\\) and time \\(t\\) (at \\((x,t)\\))\n\\(c(x,t)\\) - the concentration of a substance (chemicals, particles) [mass per volume] at position \\(x\\) and time \\(t\\) (at \\((x,t)\\))\n\\(c(x,t)\\) - the temperature at \\((x,t)\\)."
  },
  {
    "objectID": "conservationequations.html#spatially-homogeneous-models",
    "href": "conservationequations.html#spatially-homogeneous-models",
    "title": "1  Conservation equations",
    "section": "1.2 Spatially homogeneous models",
    "text": "1.2 Spatially homogeneous models\nIn this section, we neglect spatial movement and consider examples of growth/death and chemical reactions (i.e. revision from MA32009).\n\n1.2.1 Population dynamics\n\n1.2.1.1 Modelling the growth of bacteria in a petri dish (flask) containing nutrient medium\nAs an example let’s consider a population of bacteria growing in a bounded domain (e.g. a petri dish).\nBacteria reproduce by undergoing successive cell divisions.\nLet \\(N(t)\\) represent bacterial density at time \\(t\\) (i.e. number of cells per volume).\nLet \\(K\\) represent the per capita rate of reproduction. Over a period of time, \\(\\Delta t\\), \\(K N(t) \\Delta t\\) cells will be added. Hence \\[\n\\begin{aligned}\nN(t+\\Delta t) &=  \\quad N(t)   + \\quad  K N(t) \\Delta t.\n\\end{aligned}\n\\tag{1.1}\\] Assuming that \\(N\\) is differentiable, dividing Equation 1.1 by \\(\\Delta t\\) and taking the limit as \\(\\Delta t \\to 0\\) \\[\n\\frac{dN}{dt} = K N\n\\tag{1.2}\\]\nDepending on the biological context, the growth rate \\(K\\) may take several forms e.g. \n\n\\(K = \\textrm{constant}\\)\n\\(K = K(t)\\) time-dependent\n\\(K= K(N(t))\\) depends on bacterial density\n\\(K= K(c(t)):= \\kappa c(t), \\;\\; (\\text{with} \\;\\; \\kappa &gt;0 \\;\\; \\text{a constant}\\)), which depends on the nutrient concentration \\(c(t)\\) at time \\(t\\) i.e. \\(K\\) depends on the available resources.\n\n\n\n1.2.1.2 Logistic growth via nutrient depletion\nSuppose that the population growth rate depends on nutient availability. Suppose also that nutrient levels are depleted by population growth.\nLet \\(c(t)\\) represent the nutrient concentration at time, \\(t\\). Bawed on the above assumptions we derive \\[\n\\begin{aligned}\n\\frac{dN}{dt} &= K(c) N = \\kappa cN,  \\\\\n\\frac{ dc}{dt} &= - \\alpha \\frac{dN}{dt} = - \\alpha   \\kappa c N,  \n\\end{aligned}\n\\tag{1.3}\\] where \\(\\kappa\\) and \\(\\alpha\\) \\(\\in \\Re\\). Consider the initial conditions \\[\nN(0) = N_0 \\quad \\textrm{and}  \\quad  c(0)= c_0.\n\\]\nNoting the conserved quantity \\[\n\\frac{dN}{dt}+\\frac{dc}{dt}=0,\n\\] integration yields \\[\nc(t)  = - \\alpha N(t) + c(0)+ \\alpha N(0) = - \\alpha N(t) + \\beta,\n\\tag{1.4}\\] where \\(\\beta=c_0 +\\alpha N_0\\). Using Equation 1.4 in Equation 1.3 we obtain the logistic growth equation \\[\n\\frac{dN}{dt} = \\kappa ( \\beta- \\alpha N)  N, \\qquad  N(0)= N_0\\quad  \n\\tag{1.5}\\] Here we have \\(K=K(N) = \\kappa (\\beta - \\alpha N)\\).\nThe last equation can be rewritten as \\[  \n\\frac{dN}{dt} = \\rho  N \\,  (1 - \\frac N B)  \\qquad \\quad N(0)= N_0,\n\\tag{1.6}\\] where \\(\\rho = \\kappa \\beta\\) is the intrinsic growth rate and \\(B = \\frac \\beta \\alpha\\) is the carrying capacity. The solution of Equation 1.6 is given by \\[\nN(t)= \\frac{ N_0 K} { N_0 + (B-N_0) e^{-\\rho t}} \\; .\n\\]\n\n\n1.2.1.3 Death/decay\nIn addition to growth, we may assume that cells die at rate \\(d\\) and the simple growth Equation 1.2 can be generalised to \\[\n\\frac{dN}{dt} = KN - d N,\n\\] where \\(d\\) is the mortality (death) rate.\n\n\n1.2.1.4 Competition\nThe fact that individuals compete for food, habitat (i.e. space) or any limited resources, means that an increase in the net mortality of the population may be observed under crowded conditions. Hence we could obtain \\[\n\\frac{dN}{dt} = KN - d_1 N^2 ,\n\\] where \\(d=d_1N\\) is the mortality (death) rate and is proportional to the population density.\n\n\n\n1.2.2 SIR Model\nConsider a model of infectious diease in which a population is slit into three compartments:\n\nsusceptible\ninfected\nrecoveered\n\nSuppse that interaction between suspectible and infected results in infection of susceptible. Suppose also that infected people only remain infectious for a limited time.\nLet \\(S(t)\\), \\(I(t)\\) and \\(R(t)\\) represent the population densities of susceptible, infected and recoveered populations, respectively.\nConsider the governing ODE\n\\[\n\\begin{aligned}\n\\frac{d S}{ dt} &= -rIS, \\\\\n\\frac{d I}{ dt} &= rIS - aI, \\\\\n\\frac{d R}{ dt} &= aI,\n\\end{aligned}\n\\] where \\(r\\) is the infection rate and \\(a\\) is the recovery rate.\n\n\n1.2.3 Activator inhibitor kinetics\nConsider a pair of interacting biochemical species, A and B. Suppose that both A and B are produced at a constant rate and that A underfgoes linear degradation. Suppose also that A and B interact \\[\n2A+B \\rightarrow A.\n\\]\nApplying the law of mass action we obtain the ODEs \\[\n\\begin{aligned}\n\\frac{d A}{ dt} &= k_1 - k_2 A + k_3 A^2 B,  \\\\\n\\frac{d B}{ dt} &= k_4 - k_3 A^2 B,\n\\end{aligned}\n\\] where \\(k_1\\) and \\(k_4\\) are production rates, \\(k_2\\) is a degradation rate and \\(k_3\\) is the reaction rate for the A and B interaction."
  },
  {
    "objectID": "conservationequations.html#spatial-movement",
    "href": "conservationequations.html#spatial-movement",
    "title": "1  Conservation equations",
    "section": "1.3 Spatial movement",
    "text": "1.3 Spatial movement\nConsider a spatial domain \\(V\\). A conservation equation can be written either in terms of the mass or number of particles of a species as follows:\n\\[\n\\begin{pmatrix}\n\\text{rate of change of}\\\\\n\\text{number of particles} \\\\\n\\text{per unit time }\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\text{rate of entry of}\\\\\n\\text{particles into $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n- \\begin{pmatrix}\n\\text{rate of exit of }\\\\\n\\text{particles from $V$}\\\\\n\\text{per unit time}\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\text{rate of degradation}\\\\\n\\text{or creation of particles }\\\\\n  \\text{in $V$ per unit time}\n\\end{pmatrix}\n\\]\n\n1.3.1 One-dimensional conservation equations\nAssume\n\nmotion takes place in a one-dimensional domain (e.g. a long very thin tube)\nthe tube has a constant cross-section area\n\nLet \\(x\\) be the distance along the tube relative to an origin. We shall consider the interval \\((x+\\Delta x, t)\\), for some \\(\\Delta x &gt;0\\), and a domain \\(V= (x, x+ \\Delta x) \\times S\\), where \\(S\\) is the cross-section of the tube with the constant area \\(A=|S|\\).\n\n\\(c(x,t)\\) - concentration of particles (number of particles per unit volume) at time, \\(t\\), and position, \\(x\\)\n\\(J(x,t)\\) - flux of particles per unit time and unit area (number of particles crossing a unit area in the positive \\(x\\)-direction per unit time)\n\\(f(x,t ,c(x,t))\\) - source/sink (number of particles created or destroyed per unit volume and unit time)\n\nWe consider \\(S\\) to be very small and \\(c(x,t)\\) is assumed to be constant in \\(S\\) (independent of \\(y\\) and \\(z\\)). We also assume that \\(c\\) is continuously differentiable with respect to \\(t\\).\nThe volume of \\(V\\) is \\(A \\Delta x\\) and number of particles is given by \\[\n\\int_x^{x+\\Delta x} c(\\tilde x, t) \\,  d \\tilde x A.\n\\]\nThen the conservation equation for the number of particles in the volume \\(V\\) is given by \\[\n\\frac{\\partial}{\\partial t} \\int_x^{x+\\Delta x} c(\\tilde x, t) A d\\tilde x = J(x,t) \\, A  - J(x+\\Delta x,t) \\, A +\\int_x^{x + \\Delta x}  f(\\tilde x, t, c(\\tilde x, t))\\,  A \\, d \\tilde x.\n\\tag{1.7}\\]\ni.e. the flux that changes the total population in \\(V\\) is that entering through the cross-section at \\(x\\) and leaving through the cross-section at \\(x+\\Delta x\\) (it is assumed that there no flux through the external surface of the tube). Assuming \\(c\\) and \\(f\\) to be sufficiently smooth (continuous in \\(x\\)) and applying The Mean Value Theorem in Equation 1.7, we obtain \\[\n\\frac{\\partial}{\\partial t} c(\\xi, t) A \\Delta x = J(x,t) \\, A  - J(x+\\Delta x,t) \\, A +  f(\\eta,t,c(\\eta, t))\\,  A \\Delta x, \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.8}\\]\nDividing Equation 1.7 by \\(A \\, \\Delta x\\) yields \\[\n\\frac{\\partial}{\\partial t} c(\\xi, t)  = - \\frac  {J(x+\\Delta x,t ) - J(x,t)} { \\Delta x} + f(\\eta,t,c(\\eta, t)), \\qquad \\xi, \\eta \\in (x, x+ \\Delta x).\n\\tag{1.9}\\] Assuming that \\(J\\) is differentiable with respect to \\(x\\) and taking the limit as \\(\\Delta x \\to 0\\) (and using the definition of partial derivatives) we obtain a one-dimensional conservation (balance) equation: \\[\n\\frac{\\partial}{\\partial t} c(x,t)  = - \\frac  {\\partial} { \\partial x} J(x,t) + f(x,t ,c(x,t)).\n\\tag{1.10}\\]\n\n\n1.3.2 Conservation equations in \\(\\mathbb R^n\\)\nLet \\(V \\subset \\mathbb R^n\\) be an arbitrary bounded domain (i.e. satisfying the conditions of the divergence theorem) and let \\(S\\) be the surface enclosing \\(V\\), i.e \\(S = \\partial V\\).\n\n\\(c(x,t)\\) – concentration of particles at \\(x\\in V\\) and \\(t&gt;0\\) (number of particles per unit volume)\n\\(J(x,t)\\) – flux vector of particles across \\(V\\) (number of particles per unit area and per unit time entering or leaving through \\(S\\) (the boundary of \\(V\\)).\n\\(f(x,t ,c(x,t))\\) - source/sink term (number of particles created or destroyed per unit volume and per unit time)\n\nThen the conservation equation reads \\[\n\\frac{\\partial}{\\partial t} \\int_V c(x,t) \\, dx = - \\int_{S} J(x,t) \\cdot {\\mathbf{n}} \\, d\\sigma + \\int_V f(x,t ,c),\n\\] where \\(\\mathbf{n}\\) is the outward normal vector to \\(S\\). The normal component of the flux \\(J\\) on \\(S\\) leads to a change of number of particles (of mass) in \\(V\\). Applying the divergence theorem, i.e. \\[\n\\int_S J \\cdot {\\mathbf{n}} \\, d\\sigma = \\int_V \\text{ div} J \\, dx,\n\\] and using the fact that \\(V\\) is independent of time \\(t\\) we obtain \\[\n\\int_V \\Big(\\frac{\\partial}{\\partial t} c(x,t) + \\nabla \\cdot  J(x,t) -  f(x,t ,c)\\Big) dx.\n\\] Since \\(V\\) can be chosen arbitrary we get the conservation equation in \\(\\mathbb R^n\\) (or a subdomain \\(\\Omega \\subset \\mathbb R^n\\))\n\\[\n\\frac{\\partial}{\\partial t} c(x,t) =  - \\nabla \\cdot  J(x,t)+  f(x,t ,c), \\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0.\n\\tag{1.11}\\]\n\n\n1.3.3 Types of flux terms\n\nFickian Diffusion\nDiffusion is an important and ‘’metabolically cheap’’ transport mechanism in biological systems. It can be also viewed as the random motion of individual molecules.\n\\[\n{\\mathbf{J}} = - D\\nabla c,\n\\tag{1.12}\\] where \\(D\\) is the diffusion coefficient. \\(D\\) depends on the size of the particles, the type of solvent, the temperature, .\nThen applying Equation 1.12 in Equation 1.11 we obtain reaction-diffusion equation \\[\n\\frac{\\partial}{\\partial t} c =  - \\nabla\\cdot ( - D \\nabla c(x,t))+  f(x,t ,c) = \\nabla \\cdot ( D \\nabla c) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n, \\,  \\, t &gt;0.\n\\tag{1.13}\\]\nIf \\(D\\) is a constant we can write \\[\n\\frac{\\partial}{\\partial t} c(x,t) =  D \\Delta c(x,t) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n \\,  (\\text{or } x \\in \\Omega), \\quad t &gt;0,\n\\]\nwhere \\[\n\\Delta c = \\sum\\limits_{j=1}^n \\dfrac{\\partial^2 c}{\\partial x_j^2}.\n\\]\nNonlinear diffusion \\[\nD = D(c) , \\qquad \\text{ e.g. }\\,   D(c)= D_0 c^m, \\quad D_0 &gt;0,\n\\] and \\[\n  \\frac{\\partial}{\\partial t} c = D_0 \\nabla\\cdot (c^m \\nabla c) + f(x,t ,c),\n\\quad x\\in \\mathbb R^n,  \\quad t &gt;0.\n\\tag{1.14}\\]\nConvection or Advection \\[\nJ = \\textbf{v} c,\n\\] where \\(\\textbf{v}\\) is a velocity vector. Hence \\[\n\\frac{\\partial}{\\partial t} c(x,t) = - \\nabla\\cdot (\\textbf{v}(x,t) c(x,t))  + f(x,t ,c),\n\\quad x\\in \\mathbb R^n,   \\quad t &gt;0.\n\\tag{1.15}\\]\nIf \\(\\textbf{v}\\) is constant or \\(\\nabla \\cdot \\textbf{v} = 0\\), then \\[\n\\frac{\\partial}{\\partial t} c = - \\textbf{v} \\nabla c  + f(x,t ,c)\n\\quad x\\in \\mathbb R^n, \\,  \\quad t &gt;0.\n\\]\nTaxis - directed movement in response to an external chemical or physical signal.\n\nchemotaxis - movement directed by a chemical gradient\nhaptotaxis - movement directed by a gradient in density, adhesion\n\nIn the presence of some chemoattractant \\(a(x,t)\\) we have \\[\n  {\\mathbf{J}} = \\chi(a) c \\nabla a,  \n  \\] where \\(\\chi(a)\\) is a `model-specific’ function of \\(a\\) defining the sensitivity to the signal, and the conservation equation reads \\[\n  \\frac{\\partial}{\\partial t} c(x,t) = -\\nabla \\cdot (\\chi(a) c(x,t) \\nabla a )  + f(x,t ,c),\n  \\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n   \\tag{1.16}\\]\n\n\n\n1.3.4 Boundary conditions (B.C.)\n\nInfinite domain (e.g. \\((-\\infty, \\infty)\\), \\(\\mathbb R^2\\), \\(\\mathbb R^3\\) ):\n\nthe density is not influenced by the boundary \\[\nc(x,t) \\to 0 \\qquad \\text{ as } \\qquad \\|x\\| \\to \\infty \\quad  \\text{decay at infinity}\n\\]\n\nPeriodic B.C.\n\n\\(L\\)-periodic function: \\(c(x,t) = c(x,t +L)\\) for any \\(x\\) in the domain\nConsider a domain \\((0,L)\\). \\[\nc(t,0) = c(t,L) \\qquad  \\text{ periodic boundary conditions}\n\\]\n\nDirichlet B.C.\n\ndensity (concentration) is fixed at the boundary\nIn the \\(1\\)-dim domain \\((0,L)\\) \\[\nc(t,0) = c_1, \\quad  c(t,L) = c_2\n\\] can consider two reservoirs placed at the ends of the domain, that are held at constant densities (concentrations) \\(c_1\\) and \\(c_2\\), respectively.\nFor a domain \\(\\Omega\\subset \\mathbb R^n\\) we have \\[\nc(x,t) = c_D(x,t) \\qquad  x\\in  \\partial \\Omega, \\, \\, t\\geq 0 \\; .\n\\]\n\nNo-flux (homogeneous Neumann) B.C.\n\nparticles cannot escape from the domain\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c  \\cdot {\\mathbf{n}}  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] In one-dimensional domain \\((0,L)\\) \\[\n\\frac{\\partial c(x,t)}{\\partial x} = 0 \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Neumann B.C.\n\nFor a domain \\(\\Omega \\subset \\mathbb R^n\\) \\[\nD\\nabla c \\cdot {\\mathbf{n}} = g(x,t)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with a given function \\(g\\) ( \\(g\\) can also be a constant).\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x} = g(x,t)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nHomogeneous Robin B.C. \\[\nD\\nabla c(x,t)  \\cdot {\\mathbf{n}}  + k c(x,t)  = 0  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x}  + k c(x,t) = 0  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\n\nNon-homogeneous Robin B.C. \\[\nD\\nabla c(x,t)  \\cdot {\\mathbf{n}}  + k c(x,t)  = g(x,t)  \\quad \\text{ on } \\quad \\partial \\Omega, \\quad t &gt;0\n\\] with some constant \\(k \\in \\mathbb R\\) and given function \\(g\\) ( \\(g\\) can also be a constant).\n\nIn one-dimensional domain \\((0,L)\\) \\[\nD \\frac{\\partial c(x,t)}{\\partial x}  + k c(x,t) = g(x,t)  \\quad \\text{ at } \\quad x=0  \\text{ and } \\quad x= L, \\quad t &gt;0 \\; ,\n\\]\nRemark We can also have different types of boundary conditions at different parts of the boundary of the considered domain.\n\n\n1.3.5 Initial conditions\nFor a conservation equation defined in a domain \\(\\Omega \\subset \\mathbb R^n\\), \\(n=1,2,3\\), additionally to boundary conditions we need to define an initial concentration, i.e. initial condition \\[\nc(0,x) = c_0(x) , \\qquad x \\in \\Omega  \\; .\n\\]\n\n\n1.3.6 Formulating a model\nThe models that we will consider will comprise one or more partial differential equations together with boundary and initial conditions. The right-hand side of the PDEs willbe dervied based upon assumptions about a particular biological system under study. We will consider exploratory numerical solutions and then study qualitative behaviours of the solutions using analyses familiar from MA32009 (e.g. steady state analysis, linear stability analysis).\nWe can have any combination of fluxes, depending on the biological system. For example, chemotaxis and diffusion\n\\[\n\\frac{\\partial}{\\partial t} c = D \\Delta c -\\nabla \\cdot (\\chi(a) c \\nabla a )  + f(x,t ,c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0,\n\\tag{1.17}\\] which can be augmented by an equation for the (diffusible) chemoattractant \\(a\\) \\[\n\\frac{\\partial}{\\partial t} a = D \\nabla^2 a + g(x,t ,a, c),\n\\quad x\\in \\mathbb R^n \\,  \\quad t &gt;0.\n\\tag{1.18}\\] Equation 1.17 and Equation 1.18 form a system of equations, a so-called chemotaxis system.\n\n\n1.3.7 Nondimensionalization\nThe variables and parameters in a biological or physical model have units:\n\n\\(\\#\\textrm{velocity} = \\dfrac{\\#\\text{length }}{\\#\\text{time}}\\)\n\\(\\# \\textrm{concentration} = \\dfrac{ \\text{num.moles}}{\\#\\text{volume}}\\)\n\\(\\#\\text{density} = \\dfrac{\\text{number of particles}}{\\# \\text{volume}}\\)\n\\(\\#\\text{diffusion coefficient} = \\dfrac{\\#\\text{length}^2}{\\#\\text{time}}\\)\n\\(\\#\\text{source/sink (reaction term)} = \\dfrac{\\#\\text{concentration (or density)}}{\\#\\text{time}}\\)\n\\(\\#\\text{flux} = \\dfrac{\\text{mass (number) of particles}}{\\#\\text{area} \\times \\# \\text{time}}\\)\n\nIt is standard to non-dimensionalize a system of differential equations by scaling or non-dimensionalizing both the dependent and independent variables in the model."
  },
  {
    "objectID": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "href": "linearreactiondiffusion.html#one-dimensional-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "2.1 One-dimensional diffusion equations",
    "text": "2.1 One-dimensional diffusion equations\nIn order to provide some insight into the structure of solutions of reaction-diffusion equations, we make an initial simplifying assumption i.e. we assume \\(f(c)=0\\), and obtain the linear diffusion equation (or heat equation):\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2},   \\quad x\\in \\mathbb R, \\, \\, t &gt;0.\n\\tag{2.1}\\] This equation is used to model the evolution of the concentration of a chemical in a long thin tube, or the temperature of a long thin rod.\nWe assume that the initial condition for our species \\(c\\) is located in one point \\(x=0\\), i.e.  \\[\nc(x_0 , 0) = \\delta_0(x)\\qquad x \\in \\mathbb R,\n\\tag{2.2}\\] where \\(\\delta_0\\) is a Dirac delta distribution (Dirac measure) satisfying \\[\n\\int_{-\\infty}^{+\\infty} \\delta_0(x) = 1 \\quad \\text{ and } \\quad \\int_{-\\infty}^{+\\infty} f(x) \\delta_0(x) = f(0) , \\text{ for continuous } f.\n\\]\n\n2.1.1 Fundamental solution\nIt can be shown that the sequence of functions \\(\\{ \\phi_\\varepsilon(x) \\}\\) given by \\[\n\\frac 1{\\varepsilon \\sqrt{\\pi} } e^{ - \\frac{x^2}{ \\varepsilon^2}}\n\\] converges to \\(\\delta_0(x)\\) as \\(\\varepsilon \\to 0\\) (in the sense of distributions or generalized functions).\nThen for the diffusion Equation 2.1 with initial condition Equation 2.2, it can be shown that the explicit (analytic) solution is given by \\[\nc(x, t) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ x^2}{ 4Dt} \\right).\n\\tag{2.3}\\] This is known as the fundamental solution of the diffusion equation in \\(\\mathbb R\\).\nWe also have, for general initial condition \\(c(x, 0) = c_0(x)\\) for \\(x\\in \\mathbb R\\): \\[\nc(x, t) = \\int_{-\\infty}^{+\\infty} \\frac{c_0(y)}{\\sqrt{4 \\pi D t}} \\exp \\left( - \\frac{ (x-y)^2}{ 4Dt} \\right) dy.\n\\]\nThis result can be generalized to \\(\\mathbb R^n\\times (0,\\infty)\\) where the fundamental solution has the form \\[\nc(x,t) =  \\frac 1{(4 \\pi D t)^{n/2}} \\exp \\left( - \\frac{ (x_{1}^{2} + x_{2}^{2} + \\ldots + x_{n}^{2})}{ 4Dt} \\right).\n\\]\n\n\n2.1.2 Numerical solution\nIn Figure 2.2 we compute a numerical solution of the diffusion equation and compare it with the exact solution given by Equation 2.3.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=10\nL=10\n\nN_x=100\nN_t=120\n\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\n\nD=1.5\nepsilon=0.1\n\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef diffusionPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n\n\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    i=N_x-1\n\n    f[i]=D/dx**2*(u[i-1]-u[i])\n    return f  \n\nsol=odeint(diffusionPDErhs,u_0,t)\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 2.1: Numerical solution of diffusion equation.\n\n\n\n\n\n\n\nFigure 2.2: Exact solution of diffusion equation.\n\n\n\n\n\n\n2.1.3 Key properties of the (linear) diffusion equation (heat equation)\n\nThe solution is infinitely smooth.\nThe solution \\(c(x,t)\\) stays positive for all \\(t &gt;0\\) and \\(x \\in \\mathbb R\\) if \\(c(x,0) &gt;0\\) for \\(x \\in \\mathbb R\\).\nThe solution ``propagates’’ with infinite speed i.e. for any \\(t &gt; 0\\), the solution is everywhere in \\(\\mathbb R\\).\nIf we change the initial data \\(c(x,0)\\) (continuously) then the solution also changes (continuously).\n\n\n\n2.1.4 Diffusive transit time\nWe now demonstrate the connection between time and space in diffusion equations. Consider a domain \\(V \\subset \\mathbb R^n \\;, n = 1,2,3.\\), and particles that are entering \\(V\\) and are being removed from \\(V\\). Define\n\\(N\\) - total number of particles in \\(V\\)\n\\(F\\) - total number of particles entering \\(V\\) per unit time\n\\(\\lambda\\) - average removal rate of particles from \\(V\\)\n\\(\\tau = \\frac 1\\lambda\\) - transit time or average time of residency in \\(V\\)\nRegardless of spatial variations, we can make the following general statement regarding the total number of particles in \\(V\\), where we assume a constant entry rate \\(F\\) and a constant removal rate \\(\\lambda\\) at some sink in \\(V\\):\n\\[\n\\frac{dN}{dt} = \\text{entry rate} - \\text{removal rate} = F - \\lambda N.\n\\]\nAt steady state (\\(dN/dt = 0\\)) we obtain \\[\nMissing content here. Check notes!\n\\]\nConsider particles of concentration \\(c(x,t)\\) diffusing with constant diffusion \\(D\\) in a one-dimensional domain \\((0,L)\\), with a constant concentration at one boundary and removed by a sink at the other boundary. At steady-state, the equation governing the concentration is given by:\n\\[\nD \\frac{ d^2 c}{dx^2} = 0  \\quad \\text{ in } (0,L), \\quad c(0) = C_0, \\, c(L) = 0 .\n\\]\nThe solution (Exercise) is: \\[\nc(x) = C_0 \\left( 1- \\frac x L\\right).\n\\] Then the number of particles entering at \\(x=0\\) due to diffusive flux (Fickian diffusion) is: \\[\nJ = - D \\frac{ dc}{ dx} = D \\frac{ C_0} L,  \n\\]\nand the total number of particles is given by: \\[\nN = \\int_0^L c(x) \\, dx = \\frac 12 L C_0 .\n\\] If we assume a cross-section of unit area at \\(x=0\\), then \\[\nF = \\text{flux}\\times\\text{area} = J\\times 1 = D \\frac{ C_0} L\n\\] and \\[\n\\tau =  \\frac N F = \\frac { C_0 L}{2} \\frac L{ DC_0} = \\frac 12 \\frac{L^2}{D}.\n\\] Thus the average time it takes a particle to diffuse a distance, \\(L\\), is \\[\n\\tau = \\dfrac{L^2}{2D}\n\\] or viewed another way, the average distance through which diffusion transports a particle in a time \\(\\tau\\) is \\(L= \\sqrt{ 2D\\tau}\\).\n\n\n2.1.5 Diffusion as the limit of a random walk\nConsider the random walk of particles in a one-dimensional domain. Suppose that the particles move randomly a distance, \\(\\Delta x\\), every time step, \\(\\Delta t\\). Assume that the particles move left with probability \\(\\lambda_L\\) and right with probability \\(\\lambda_R\\).\nIn Figure Figure 2.3 a simulation of 400 random walking particles is presented. Each particle is initialised at the origin and can move one step left or right with equal probability at every time step of the simulation. As time evolves the particle density (histogram) disperses. The normalised particle density appears to be well described by the solution of the diffusion equation (solid lines, Equation 2.3).\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\nN_particles=400\n\nL=50\nN_x=200\n\nT=500\nN_t=25000\nD=0.1\n\ndt=T/N_t\n\nmove_probability=D*dt/dx**2\n\nx=np.linspace(0,L,N_x)-L/2\nt=np.linspace(dt,T,N_t)\n\nparticle_positions=np.zeros((N_t,N_particles),dtype=float)\n\n# loop over time\nfor i in range(1,N_t):\n  # loop over particles\n  for j in range(N_particles):\n\n    r=random.random()\n    # move particle j right\n    new_particle_position=particle_positions[i-1,j]\n    if r&lt;move_probability:\n      new_particle_position+=dx\n    # move particle j left  \n    elif r&lt;2*move_probability:\n      new_particle_position-=dx\n    particle_positions[i,j]=new_particle_position\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(-x_mesh**2/(4*D*t_mesh))\n\n\nfig,ax=plt.subplots(2,2)\nax[0,0].hist(particle_positions[5,:],density=True)\nax[0,0].plot(x, c_exact[5,:], 'r')\nax[0,0].set_title('$t=$'+str(t[5]))\n\nax[0,1].hist(particle_positions[500,:],density=True)\nax[0,1].plot(x, c_exact[500,:], 'm')\nax[0,1].set_title('$t=$'+str(t[500]))\n\nax[1,0].hist(particle_positions[1000,:],density=True)\nax[1,0].plot(x, c_exact[1000,:], 'b')\nax[1,0].set_title('$t=$'+str(t[1000]))\n\nax[1,1].hist(particle_positions[1500,:],density=True)\nax[1,1].plot(x, c_exact[1500,:], 'k')\nax[1,1].set_title('$t=$'+str(t[1500]))\n\nax[0,0].set_xlim([-L/2,L/2])\nax[0,1].set_xlim([-L/2,L/2])\nax[1,0].set_xlim([-L/2,L/2])\nax[1,1].set_xlim([-L/2,L/2])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 2.3: Numerical implementation of random walk\n\n\n\n\nConcider the concentration of particles \\(c(x,t)\\) at spatial location \\(x\\) and time \\(t\\), (or more precisely, the probability density function of the position of a particle performing a random walk) we have: \\[\nc(x, t+ \\Delta t) = c(x, t)  + \\lambda_R c(x- \\Delta x, t) - \\lambda_R c(x, t) + \\lambda_L c(x+ \\Delta x, t) - \\lambda_L c (x,t).\n\\] If we assume that \\(\\lambda_R+ \\lambda_L =1\\) then \\[\nc(x, t+ \\Delta t) =  \\lambda_R c(x- \\Delta x, t) + \\lambda_L c(x+ \\Delta x, t).\n\\] Applying a Taylor series expansion about \\((x,t)\\) implies\n\\[\nc(t,x) + \\frac{ \\partial c}{\\partial t} \\Delta t + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} (\\Delta t )^2  + h.o.t. =\n\\lambda_R \\Big( c(t,x) - \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t. \\Big)\\\\ +\n\\lambda_L \\Big( c(t,x) + \\frac{ \\partial c}{\\partial x} \\Delta x + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t. \\Big).\n\\]\nUsing \\(\\lambda_R+ \\lambda_L =1\\) and assuming \\(\\lambda_L = \\lambda_R = \\frac 12\\) we obtain\n\\[\n\\frac{ \\partial c}{\\partial t} \\Delta t + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} (\\Delta t )^2  + h.o.t. =\n\\frac 12  \\frac{ \\partial^2 c}{\\partial^2 x} (\\Delta x )^2  + h.o.t.\n\\] Dividing by \\(\\Delta t\\) gives\n\\[\n\\frac{ \\partial c}{\\partial t}  + \\frac 12  \\frac{ \\partial^2 c}{\\partial^2 t} \\Delta t   + h.o.t. =\n   \\frac{ \\partial^2 c}{\\partial^2 x} \\frac{(\\Delta x )^2 }{2\\Delta t} + h.o.t.\n\\]\nConsidering the limit \\(\\Delta t \\to 0\\) and \\(\\Delta x \\to 0\\) in such way that\n\\[\n\\frac{(\\Delta x )^2 }{2\\Delta t} \\to D,\n\\]\nyields the (one-dimensional) diffusion equation\n\\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}.\n\\]\nThis approach can be extended to consider other types of movement e.g. convection. For example, if we assume that\n\\[\n\\lambda_R+ \\lambda_L =1,\n\\] and \\[\n\\lambda_L - \\lambda_R = \\varepsilon,\n\\] the motion of the particles is biased and we may derive an appropriate reaction-diffusion-convection equation (see tutorial).\nFinally we note that there is a connection between diffusion and the normal distribution function.\nRecall The normal distribution function in one-dimension with zero mean and variance \\(\\sigma^2\\) is given by Equation 2.3.\n\\[\nN(0, \\sigma^2) \\sim \\frac 1 { \\sqrt{ 2 \\pi \\sigma^2}} \\exp \\left( - \\frac{x^2}{ 2 \\sigma^2}\\right).\n\\] Examining the formula for the fundamental solution of the diffusion Equation 2.3 in one-dimension, we see by inspection that the probability density function of the position of a particle performing a random walk in one-dimension starting at the origin is normally distributed with mean zero and variance \\[\n\\sigma^2 = 2 D t.\n\\]"
  },
  {
    "objectID": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "href": "linearreactiondiffusion.html#linear-reaction-diffusion-equations",
    "title": "2  Linear reaction diffusion equations",
    "section": "2.2 Linear reaction-diffusion equations",
    "text": "2.2 Linear reaction-diffusion equations\nConsider now the linear reaction term: \\(f(c) = \\rho c\\), so that our reaction-diffusion equation is: \\[\n\\frac{\\partial c}{\\partial t} = D \\frac{\\partial^2 c}{\\partial x^2}   + \\rho \\, c, \\quad x\\in \\mathbb R, \\, \\, t &gt;0,\n\\tag{2.4}\\] where \\(\\rho \\in \\mathbb R\\) is a constant.\nOnce again we consider the initial condition to be concentrated at the origin: \\[\nc(0,x) = \\delta_0(x).\n\\tag{2.5}\\]\n\n2.2.1 Exact solution\nBy considering a separation of variables approach, i.e. making the ansatz \\[\nc(x,t) = w(t) \\tilde c(t,x),\n\\] it can be shown (Exercise) that the explicit solution for the linear reaction-diffusion Equation 2.4 with initial condition Equation 2.5 is given by\n\\[\nc(t,x) = \\frac1{\\sqrt{4 \\pi D t}} \\exp \\left(\\rho t - \\frac{x^2}{ 4Dt} \\right).\n\\]\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=10\nL=10\n\nN_x=100\nN_t=120\n\nt=np.linspace(0,T,N_t)\nx=np.linspace(0,L,N_x)-L/2\n\nD=0.5\nrho=1.0\nepsilon=0.1\n\nu_0=1/(epsilon*np.sqrt(np.pi))*np.exp(-x**2/epsilon**2)\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=D/dx**2*(u[i-1]-2*u[i]+u[i+1])  \n\n\n    i=0\n    f[i]=D/dx**2*(-u[i]+u[i+1])\n    i=N_x-1\n\n    f[i]=D/dx**2*(u[i-1]-u[i])\n\n    reac=rho*u\n    f=f+reac\n    return f  \n\nsol=odeint(logisticPDErhs,u_0,t)\n\n\n[x_mesh,t_mesh]=np.meshgrid(x,t)\n\nc_exact=1/np.sqrt(4*np.pi*D*t_mesh)*np.exp(rho*t_mesh-x_mesh**2/(4*D*t_mesh))\n\nfig,ax=plt.subplots()\nax.plot(x, sol[1,:], 'r')\nax.plot(x, sol[4,:], 'b')\nax.plot(x, sol[8,:], 'm')\nax.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\nfig,ax=plt.subplots()\nax.plot(x, c_exact[1,:], 'r')\nax.plot(x, c_exact[4,:], 'b')\nax.plot(x, c_exact[8,:], 'm')\nax.plot(x, c_exact[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 2.4: Numerical solution of linear reaction diffusion equation\n\n\n\n\n\n\n\nFigure 2.5: Exact solution of linear reaction diffusion equation\n\n\n\n\n\n\n2.2.2 Speed of a wave of invasion\nMuskrats which were introduced in 1905 in Bohemia initially spread rapidly throughout Europe through a combination of random movement and proliferation (initially there were no predators and proliferation was rapid). A model for the initial spread can therefore be given by a two-dimensional diffusion equation combined with exponential growth and assuming that \\(M\\) individuals were released at the origin (i.e. in Bohemia). Considering the density of muskrats \\(u({\\mathbf{x}} , t)\\), the equation is\n\\[\n\\frac{\\partial u}{\\partial t} = D \\left(\\frac{\\partial^2 u}{\\partial x_1^2} +  \\frac{\\partial^2 u}{\\partial x_2^2}\\right)  + \\rho \\, u, \\quad {\\mathbf{x}} = (x_1 , x_2) \\in \\mathbb R^2, \\, \\, t &gt;0,\n\\tag{2.6}\\] \\[\nu({\\mathbf{x}}, 0) = M \\delta_0({\\mathbf{x}}), \\quad {\\mathbf{x}} \\in \\mathbb R^2.\n\\tag{2.7}\\]\nThe solution of Equation 2.6 with initial conditions Equation 2.7 is equal to:\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ |{\\mathbf{x}} |^2}{ 4Dt} \\right)\\; = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ (x_{1}^{2} + x_{2}^{2})}{4Dt} \\right).\n\\]\nTransforming to polar coordinates \\(x_1 = r \\cos\\varphi\\), \\(x_2 = r \\sin \\varphi\\) we obtain\n\\[\nu({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r^2}{ 4Dt} \\right).\n\\]\nFrom the properties of the fundamental solution, the wave of invasion extends all the way to infinity if \\(t&gt;0\\). Thus, for practical purposes, somehow we have to define the front of the wave.\nConsider that there is some detection threshold for the muskrats i.e. some predetermined small value of the density \\(u_1\\), say, such that any changes in density for \\(u &lt;u_1\\) cannot be detected.\nBecause of the symmetry of the problem, then the leading edge of the invading wave front of muskrats is the circle of radius \\(r=r_1(t)\\) where \\(u=u_1\\), i.e. from the explicit solution of Equation 2.6,\n\\[\nu_1({\\mathbf{x}}, t) = \\frac M{4 \\pi D t} \\exp \\left(\\rho t - \\frac{ r_1^2}{ 4Dt} \\right).\n\\]\nRearranging and solving for \\(r_1\\), using the fact that \\[\n\\lim\\limits_{t\\to \\infty} \\dfrac {\\ln t} t =0,\n\\] we obtain for large \\(t\\) that \\[\nr_1(t) \\approx 2 \\sqrt{ \\rho D} t.\n\\]\nHence, the speed of invasion of the leading edge of the muskrats is given by: \\[\nv = \\frac{r_1(t)}{t} =  2 \\sqrt{ \\rho D}.\n\\]"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#numerical-solutions",
    "href": "nonlinearreactiondiffusion.html#numerical-solutions",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.1 Numerical solutions",
    "text": "3.1 Numerical solutions\nIn Figure 3.1 we have computed a numerical solution to Equation 3.2 together with no-flux boundary conditions. See Python code for further details. The key point to note is that the numerical solutions appear to be a travelling wave, at successive times the solution is translated along the \\(x\\) axis. At long times the solution tends to \\(u\\sim1\\) (behind the wavefront). Ahead of the front, the solution is \\(u\\sim0\\).\n\nCan we prove this is a travelling wave (e.g. the solution could be dynamic on a very slow time scale that is not captured by the numeircal solution)?\nCan we derived a form for the travelling wave profile?\nWill we see a travelling wave for any initial data?\nHow does the wave speed relate to model parameters?\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=100\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\n\nu_0=0.5*(1+np.tanh(-0.1*(x-20)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\ndef logisticPDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1])+u[i]*(1-u[i])  \n\n\n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1])+u[i]*(1-u[i]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])+u[i]*(1-u[i]) \n    return f  \n\nsol=odeint(logisticPDErhs,u_0,t)\n\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[4,:], 'b')\nplt.plot(x, sol[8,:], 'm')\nplt.plot(x, sol[12,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 3.1: Numerical solution of Fisher’s equation."
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#travelling-waves",
    "href": "nonlinearreactiondiffusion.html#travelling-waves",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.2 Travelling waves",
    "text": "3.2 Travelling waves\nIt is known that the Fisher Equation 3.2 exhibits what are known as travelling wave solutions.\n\nDefinition 3.1 A travelling wave is a solution of a partial differential equation with a constant profile (shape) and a constant propagation speed.\n\n\n3.2.1 Types of travelling waves\n\nTravelling pulse: \\(u(x,t) \\to a\\), as \\(x \\to \\pm \\infty\\).\nTravelling front : \\(u(x,t) \\to a\\), as \\(x \\to - \\infty\\), \\(u(x,t) \\to b\\), as \\(x \\to + \\infty\\) and \\(a\\neq b\\) (this is what we see in Figure 3.1)\nTravelling train: \\(u(x,t)\\) is a periodic function in \\(x\\).\n\nA travelling wave solution of a PDE can be written in the form \\(u(x,t) = W(z)\\), where \\(z = x - vt\\). We shall consider \\(v&gt;0\\), which describes a wave moving from left to right.\nConsider first the spatially uniform (homogeneous) solution of Equation 3.2\n\\[\n\\frac{\\partial u}{\\partial t} =    u(1-u), \\qquad   \\, \\, t &gt;0.\n\\tag{3.3}\\]\nSteady states of Equation 3.3 are \\[\nu=u_1 =1\n\\] and \\[\nu=u_2 =0.\n\\] To analyse the stability we consider \\[\nf(u)=u(1-u) \\quad \\textrm{and} \\quad \\frac{ df}{du}(u)= 1 - 2u.\n\\] Then \\[\n\\frac{ df}{du}(u_1)= -1 \\quad \\textrm{and} \\quad \\frac{ df}{du}(u_2)= 1.\n\\] Thus \\(u_1=1\\) is stable and \\(u_2=0\\) is unstable.\nThis stability analysis suggests that for the spatially dependent situation we can have a travelling wave solution that connects the two steady states \\(u_1\\) and \\(u_2\\) i.e. a travelling front.\nConsider the travelling wave ansatz\n\\[\nu(x,t)= W(z) = W(x-vt),\n\\] where \\(v\\) is a constant. Changing variables in Equation 3.2 and using \\[\n\\begin{aligned}\n\\frac{ \\partial u}{\\partial t} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial t} = - v   \\frac{ dW}{dz}, \\\\\n\\frac{ \\partial u}{\\partial x} &= \\frac{ dW}{dz} \\frac{\\partial z}{\\partial x} =\\frac{ dW}{dz}, \\\\\n\\frac{ \\partial^2 u}{\\partial x^2} &= \\frac{ d^2W}{dz^2} \\left(\\frac{\\partial z}{\\partial x} \\right)^2 +  \\frac{ dW}{dz} \\frac{\\partial^2 z}{\\partial x^2} =\\frac{ d^2W}{dz^2},\n\\end{aligned}\n\\]\nwe obtain a second order ordinary differential equation for \\(W\\)\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + W(1-W)  = 0,\n\\tag{3.4}\\] where \\[\nW(z) \\to 1 \\quad \\text{ as } \\quad z \\to  - \\infty, \\quad\nW(z) \\to 0 \\quad \\text{ as } \\quad z \\to  +\\infty,\n\\tag{3.5}\\] and \\[\nW(z) \\in [0,1].\n\\tag{3.6}\\]\nWe can rewrite Equation 3.4 as a system of two first order ODEs\n\\[\n\\begin{aligned}\n\\frac{ dW}{dz}& = P  = F(W,P), \\\\\n\\frac{ d P}{dz}&= -  v P - W(1-W)  = G(W,P).  \n\\end{aligned}\n\\tag{3.7}\\]\n\n\n3.2.2 Numerical solutions\nIn Figure 3.2 we plot the numerical solution to equations Equation 3.7 for different values of the wavespeed, \\(v\\). Note that when the wavespeed is too small the solution spirals in towards the origin. This solution cannot be valid as it implies that \\(u&lt;0\\) for some \\(z\\).\nNote that some problem will not have a travelling wave solution. In this situation we could still make the travelling wave ansatz but this would usually result in a contradiction. In such a case this tells us that a travelling wave solution is not possible.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=300\n\na=0.2\nN_z=5000\n\nz=np.linspace(1,T,N_z)\n\nu_0=[0.99,-0.0001]\n\nc_1=2.0\nc_2=8.6\nc_3=0.5\n\ndef fisherTrWaveODErhs(u, t, c):\n    f=np.zeros_like(u)\n    reaction=u[0]*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-c*u[1]-reaction\n    return f  \n\nsol=odeint(fisherTrWaveODErhs,u_0,z, args=(c_1,))\nsol2=odeint(fisherTrWaveODErhs,u_0,z, args=(c_2,))\nsol3=odeint(fisherTrWaveODErhs,u_0,z, args=(c_3,))\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(sol[:,0],sol[:,1], 'r')\nax[0].plot(sol2[:,0],sol2[:,1], 'b')\nax[0].plot(sol3[:,0],sol3[:,1], 'k')\nax[0].set_xlim([-0.5, 1.05])\nax[0].set_xlabel('$u$')\nax[0].set_ylabel('$du/dz$')\n\nax[1].plot(z,sol[:,0], 'r')\nax[1].plot(z,sol2[:,0], 'b')\nax[1].plot(z,sol3[:,0], 'k')\nax[1].set_xlim([-0.5, 100])\n\nax[1].set_xlabel('$z$')\nax[1].set_ylabel('$u$')\nplt.legend(['c='+str(c_1),'c='+str(c_2), 'c='+str(c_3)])\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 3.2: Proposed numerical solution of Equation 3.7 with prospective values of wavespeed \\(c\\).\n\n\n\n\n\n\n3.2.3 Steady state analysis\nThe steady states of Equation 3.7 are \\((W_1, P_1) = (0,0)\\) and \\((W_2, P_2) = (1,0)\\).\nUsing \\[\n\\frac{dP}{dW} =  \\frac{dP}{dz} \\frac{dz}{dW} =\\frac{ \\frac{dP}{dz}}{ \\frac{dW}{dz}}\n\\] and Equation 3.7 we can write an equation for \\(P=P(W)\\): \\[\n\\frac{ dP}{dW} = - v - \\frac{ W(1-W)} P,\n\\tag{3.8}\\]\ntogether with \\[\nP(0) = 0, \\quad P(1) = 0,\n\\tag{3.9}\\] and \\[\nP(W) &lt; 0  \\quad \\textrm{or} \\quad   W \\in (0,1).\n\\tag{3.10}\\]\nThe condition Equation 3.10 is given by the form of travelling front, which we would like to show that it exists\n\nLemma 3.1 For every solution of Equation 3.4 satisfying Equation 3.5 and Equation 3.6 we have that \\(\\dfrac{dW(z)}{dz} &lt;0\\) for all finite \\(z\\), i.e.  \\[\nP(W) &lt; 0 \\quad  \\mathrm{for} \\quad  W \\in (0,1).\n\\]\n\nThus in phase-plane we shall look for a trajectory connecting \\((W_1, P_1)=(0,0)\\) and \\((W_2, P_2) = (1,0)\\) and \\(P&lt;0\\).\n\n\n3.2.4 Connection between sign of \\(P\\) and sign of speed \\(v\\)\nConsider Equation 3.8. Multiplying it by \\(P\\) and integrating over \\(W\\) from \\(0\\) to \\(1\\), we obtain \\[\n\\int_0^1 \\frac{dP}{dW}  P(W)\\, dW = - v \\int_0^1  P(W) dW - \\int_0^1 W(1-W) dW.\n\\] Using conditions Equation 3.9 we have \\[\n\\int_0^1 \\frac{dP}{dW} \\, P\\, dW = \\frac 12 \\int  \\frac{d}{dW} (P^2) dW = \\frac 12\\left( P^2(1) - P^2(0)\\right) = 0,\n\\] and \\[\n  v \\int_0^1  P(W) dW=  - \\int_0^1 W(1-W) dW &lt;0, \\quad \\text{ since } \\int_0^1 W(1-W) dW &gt;0.\n\\] Thus for \\(v&gt;0\\) we have \\(P= W^\\prime&lt;0\\) and for \\(v&lt;0\\) we have \\(P= W^\\prime&gt;0\\).\nNote: \\(u(x,t) = W(z)\\), where \\(z= x- vt\\) with \\(v&lt;0\\) and \\(\\frac{ dW}{dz} &gt;0\\) will also be a travelling wave for the Fisher Equation 3.2, i.e. a travelling wave front moving to the left.\nNote: Instead of \\(z = x - vt\\) we can also consider \\(z=x+ vt\\) . The sign of \\(v\\) determines the direction of movement: If \\(z = x - vt\\) for \\(v&gt;0\\) we have travelling wave moving to the right and for \\(v&lt;0\\) we have travelling wave moving to the left.\nIf \\(z = x + vt\\) for \\(v&gt;0\\) we have travelling wave moving to the left and for \\(v&lt;0\\) we have travelling wave moving to the right.\n\n\n3.2.5 Stability of steady states\nThe Jacobian matrix for Equation 3.7 is given by: \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n-1 + 2W & \\, - v\n\\end{pmatrix}.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) the eigenvalues of \\(J(0,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(0,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- 1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_1 = \\frac 12 ( - v \\pm \\sqrt{ v^2 - 4})\n\\] and we have for \\(v&gt;0\\) that \\({R} e(\\lambda_1^\\pm) &lt;0\\).\nTherefore at \\((0, 0)\\) \\[\n\\begin{cases}\n\\text{ stable node if }\\,   v^2 \\geq 4, \\\\\n\\text{ stable focus if } \\,  v^2 \\leq 4 \\quad (\\text{ complex eigenvalues})\n\\end{cases}\n\\] At \\((W_2, P_2)=(1,0)\\) the eigenvalues of \\(J(1,0)\\) are solutions of the characteristic polynomial \\[\n\\det(J(1,0) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1 \\\\\n1 & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda - 1 = 0.\n\\] Thus \\[\n\\lambda^{\\pm}_2 = \\frac 12 ( - v \\pm \\sqrt{ v^2 + 4})\n\\] and we have for \\(v&gt;0\\) that \\(\\lambda_2^{-} &lt;0 &lt; \\lambda_2^+\\). Therefore \\((1,0)\\) is a saddle.\nThe eigenvectors are defined by \\[\n- \\lambda W + P = 0.\n\\] Thus at \\((W_1, P_1)=(0,0)\\) we have \\[\n\\Phi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^- W\n\\end{pmatrix}, \\quad  \\Phi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_1^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_1^- \\leq \\lambda_1^+ &lt;0 \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\]\nAt \\((W_2, P_2)=(1,0)\\) we have \\[\n\\Psi_1 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^- W\n\\end{pmatrix}, \\quad  \\Psi_2 = \\begin{pmatrix}\nW\\\\\n\\lambda_2^+ W\n\\end{pmatrix}.\n\\]\nConsider that \\[\n\\lambda_2^- &lt;0 &lt; \\lambda_2^+  \\quad \\textrm{and choose} \\quad W = \\pm 1.\n\\] The eigenvectors are sketched in Figure 3.3.\n\n\n\nFigure 3.3: Schematic diagram of eigenvectors.\n\n\n\nDefinition 3.2 The trajectory that connects two different points is called a heteroclinic connection. The trajectory that connects a point with itself is called a homoclinic connection.\n\n\n\n3.2.6 Minimal wave speed\nIt can be shown that for \\(v&lt;2\\) a heteroclinic connection between \\((0,0)\\) and \\((1,0)\\) exists, but in this situation the steady state \\((0,0)\\) is a stable focus and corresponds to an oscillatory front.\nIn the context of a model of a biological process \\(W\\) is the profile of a population density and \\(W\\geq 0\\). Hence, for \\(v&lt;2\\) trajectories connecting \\((0,0)\\) and \\((1,0)\\) are not biologically realistic.\nThus we obtain the minimal speed \\(v^\\ast_\\text{min}=2\\) (non-dimensionalized) for which we have a travelling wave front solution for Fisher’s equation.\nIn the original dimensional variables we have: \\[\nz^\\ast= x^\\ast - v^\\ast t^\\ast = x \\sqrt{ \\frac \\rho D} - v^\\ast t \\rho , \\quad\n\\sqrt{ \\frac D \\rho } z^\\ast= x  - \\sqrt{D \\rho}  \\, v^\\ast\\,  t.\n\\] Thus for \\(z = x - vt\\) we have \\[\nv=  v^\\ast \\sqrt{D \\rho},\n\\] and \\[\nv_{\\text{min}}=  v^\\ast_{\\text{min}} \\sqrt{D \\rho} = 2  \\sqrt{D \\rho}.\n\\]\n\n3.2.6.1 The existence of a confined region\nTo show the existence of a travelling wave we will construct a confined region or confined set in \\(\\mathbb{R}^2\\), which contains both steady states such that, once inside this region solution trajectories cannot escape from it (also known as an invariant region or invariant set).\nConsider \\[\nT= \\{ (W,P) : \\, 0 \\leq W \\leq 1,\\, \\, P \\leq 0, \\, \\,  P \\geq \\mu W \\}\n\\] for some \\(\\mu &lt;0\\).\nConsider normal vectors at each boundary of \\(T\\): \\[\n\\text{ at } P = 0 \\, : \\, \\, n_1 = \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix}, \\quad\n\\text{ at } W= 1 \\, : \\, \\, n_2 = \\begin{pmatrix}\n-1\\\\ 0\n\\end{pmatrix}, \\quad\n\\text{ at } P = \\mu W \\, : \\, \\, n_3 = \\begin{pmatrix}\n-\\mu \\\\1\n\\end{pmatrix}.\n\\] Consider the scalar product between normal vectors and the flow vector \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\ \\\\  \\dfrac{dP}{dz}\n\\end{pmatrix},\n\\] of Equation 3.7.\nAt \\(P=0\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_1 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n0 \\\\ -1\n\\end{pmatrix} =  \\left(v P + W(1-W)\\right) \\Big|_{P=0} =  W(1-W) \\geq 0 , \\text{ for } W\\in [0,1].\n\\]\nAt \\(W=1\\) \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_2 = \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-1 \\\\ 0\n\\end{pmatrix} =  -P  \\geq 0 , \\text{ since }P \\leq 0.\n\\]\nAt \\(P=\\mu W\\) \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 &= \\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix}\\cdot  \\begin{pmatrix}\n-\\mu \\\\ 1\n\\end{pmatrix} \\\\\n& =\\left(  - \\mu  P - vP -  W(1-W)\\right) \\Big|_{P=\\mu W}  \\\\\n&=   - \\mu^2 W - \\mu v W - W(1-W) = - W( \\mu^2 + \\mu v + 1) + W^2.\n\\end{aligned}\n\\] Thus\n\\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0,\n\\] if \\[\n\\mu^2 + \\mu v + 1 \\leq 0.\n\\] The last inequality is satisfied if we have real roots of the equation \\(\\mu^2 + \\mu v + 1 = 0\\). We have that\n\\[\n\\mu_{1,2} = \\frac{ - v \\pm \\sqrt{ v^2 -4}} 2\n\\]\nare real if \\(v^2 \\geq 4\\).\nThus, since \\(v &gt;0\\), for \\(v \\geq 2\\) and any \\[\n\\mu\\in \\left[ \\dfrac{ - v -\\sqrt{ v^2 -4}} 2, \\dfrac{ - v +\\sqrt{ v^2 -4}} 2 \\right]\n\\] we have \\[\n\\begin{pmatrix}\n\\dfrac{ dW}{dz} \\\\  \\\\ \\dfrac{dP}{dz}\n\\end{pmatrix} \\cdot n_3 \\geq 0 \\qquad \\text{ at } \\quad P=\\mu W.\n\\]\nTherefore we have shown that at the boundaries of \\(T\\) the flow vector points in to the region \\(T\\) and any trajectory approaching the boundaries from inside of \\(T\\) will return to \\(T\\) without crossing any of the boundaries of \\(T\\). Thus we have constructed an invariant (trapping) triangular region containing the steady states \\((0,0)\\) and \\((1,0)\\).\nIf we can show that there no other steady states or periodic solutions of the system Equation 3.7, then a trajectory that leaves \\((1,0)\\) must approach \\((0,0)\\).\n\nTheorem 3.1 Bendixson’s Negative Criterion, Dulac’s Negative Criterion\nIf there exists a function \\(\\varphi(W,P)\\), with \\(\\varphi \\in C^1(\\mathbb R^2)\\), such that \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P},\n\\]\nhas the same sign \\((\\neq 0)\\) almost everywhere in a simply connected region (region without holes), then the system \\[\n\\begin{aligned}\n\\dfrac{ dW}{dz} &= F(W,P) \\; ,\n\\\\   \\dfrac{dP}{dz} &= G(W,P),\n\\end{aligned}\n\\] has no periodic solutions in this region.\n\nWe can apply Theorem 3.1 to our situation taking \\(\\varphi(W,P) = 1\\). Then using Equation 3.7 we have \\[\n\\frac{\\partial(\\varphi F )}{\\partial W} +  \\frac{\\partial(\\varphi G )}{\\partial P} = - v &lt; 0\\; .\n\\] Thus we have no periodic solutions and also only two steady states \\((0,0)\\) and \\((1,0)\\) in the confined (invariant) simply-connected region \\(T\\). Therefore the trajectory that leaves \\((1,0)\\) will approach \\((0,0)\\).\nWe have therefore shown that for any \\(v\\geq 2\\) there exist a heteroclinic trajectory \\(P(W)\\) connecting \\((0,0)\\) and \\((1,0)\\).\n\nTheorem 3.2 For \\(P(W)\\) satisfying Equation 3.8, Equation 3.9 and \\(P(W) &lt; 0\\) for \\(W \\in (0,1)\\), there exists a solution \\(W(z)\\) of Equation 3.4 satisfying Equation 3.5 and Equation 3.6.\n\nThus for any wave speed \\(v\\) satisfying \\(v \\geq 2\\), we have the existence of travelling wave front \\(u(x,t)= W(x- vt)\\) of Fisher’s equation Equation 3.2.\n\n\n\n3.2.7 Initial conditions\nOne final key question is: For which initial conditions \\(u(x,0) = u_0(x)\\) does the solution evolve to a travelling wave solution?\nIf we start with a travelling wave shape initial condition, i.e. \\(u_0(x)= W(z)|_{t=0} = W(x)\\), then this simply propagates as a travelling wave. However if \\(u_0(x)\\neq W(x)\\), then it is not immediately obvious how the solution will evolve. This problem was considered by Kolmogorov et al. Kolmogorov, Petrovsky, and Piskunov (1937), who showed that for any initial data satisfying \\[\nu_0(x) \\geq 0, \\quad \\text{ with} \\quad  u_0(x) = \\begin{cases} 1 \\, \\text{ if } \\, x \\leq x_1, \\\\\n0 \\, \\text{ if } \\, x \\geq x_2,\n\\end{cases}\n\\] where \\(x_1 &lt; x_2\\) and \\(u_0\\) is continuous in \\([x_1, x_2]\\), the solution of Fisher’s Equation 3.2 evolves to a travelling wave with minimal speed \\[\nv_\\text{ min} = 2 \\sqrt{ \\rho D}\n\\] and \\[\nu(t,x) \\rightarrow 1 \\quad \\textrm{as} \\quad x\\rightarrow -\\infty, \\quad u(t,x) \\rightarrow 0 \\quad \\textrm{and} \\quad  x\\rightarrow +\\infty.\n\\]"
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#travelling-waves-in-bistable-equations",
    "href": "nonlinearreactiondiffusion.html#travelling-waves-in-bistable-equations",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.3 Travelling waves in bistable equations",
    "text": "3.3 Travelling waves in bistable equations\nConsider now the reaction-diffusion equation: \\[\n\\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2} +   f(u)\\qquad x\\in \\mathbb R, \\, \\, t &gt;0,  \\\\\n\\tag{3.11}\\] with initial condition \\[\nu(x,0)=u_0(x)  \\qquad x\\in \\mathbb R,\n\\] where \\(f(0) = f(a) = f(1)= 0\\) and \\(0 &lt; a&lt;1\\). There are three spatially uniform steady states \\(u_1 =0\\), \\(u_2 =a\\), \\(u_3=1\\).\nThe stability of the steady states is given by the sign of \\(f^\\prime(u_j)\\) for \\(j =1,2,3\\).\nIf we have that \\(f^\\prime (0) &lt; 0\\), \\(f^\\prime(a) &gt;0\\) and \\(f^\\prime(1) &lt;0\\) then \\(u_1=0\\) and \\(u_3=1\\) are stable steady states and \\(u_2 =a\\) is an unstable steady state of Equation 3.11.\nAn example of such a function is \\(f\\) is \\(f=u(u-a)(1-u)\\) which arises in the study of nerve action potentials along nerve fibres and other problems in excitable media.\nThe existence of two stable steady states gives rise to the name ``bistable equation’’."
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#numerical-solutions-2",
    "href": "nonlinearreactiondiffusion.html#numerical-solutions-2",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.4 Numerical solutions",
    "text": "3.4 Numerical solutions\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=100\n\na=0.2\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\n\nu_0=6*0.5*(1+np.tanh(-1*(x-50)))*0.5*(1+np.tanh(1*(x-50)))\nu_0=0.5*(1+np.tanh(-1*0.2*(x-50)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\nfig, ax = plt.subplots(1)\nu_samp=np.linspace(0,1,100)\nreac=u_samp*(u_samp-a)*(1-u_samp)\nax.plot(u_samp,reac) \nax.set_xlabel('$u$')\nax.set_ylabel('$f(u)$')\n\nplt.show()\n\n\ndef bistablePDErhs(u,t):\n    N_x=len(u)\n    f=np.zeros_like(u)\n    for i in range(1,N_x-1):\n      f[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f[i]=1/dx**2*(-u[i]+u[i+1]) \n    i=N_x-1\n\n    f[i]=1/dx**2*(u[i-1]-u[i])\n\n    reaction=u*(u-a)*(1-u) \n    f= f+reaction \n    return f  \n\nsol=odeint(bistablePDErhs,u_0,t)\n\nplt.plot(x, sol[0,:], 'r')\nplt.plot(x, sol[15,:], 'b')\nplt.plot(x, sol[30,:], 'm')\nplt.plot(x, sol[45,:], 'k')\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 3.4: A plot of f(u) against u.\n\n\n\n\n\n\n\nFigure 3.5: Numerical solution of bistable PDE."
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#general-assumptions-on-f",
    "href": "nonlinearreactiondiffusion.html#general-assumptions-on-f",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.5 General assumptions on \\(f\\)",
    "text": "3.5 General assumptions on \\(f\\)\n\n\\(f(0)=f(a)=f(1)=0\\),\n\\(f(u) &lt; 0\\) in \\((0,a)\\), \\(f(u) &gt;0\\) in \\((a,1)\\)\n\\(f^\\prime (0) &lt; 0\\), \\(f^\\prime (1) &lt; 0\\)\n\nIn a similar manner to the previous sections, we look for a travelling wave solution of the form \\(u(x,t) = W(z)\\) with \\(z= x-vt\\), yielding\n\\[\n\\frac{ d^2W}{dz^2}+  v \\frac{ dW}{dz} + f(W)  = 0,  \\; .\n\\tag{3.12}\\]\nWe can rewrite Equation 3.12 as asystem of two 1st order ODEs \\[\n\\begin{aligned}\n\\frac{ dW}{dz} = P = F(W,P) , \\\\\n\\frac{ d P}{dz}= -  v P - f(W)  = G(W,P),  \n\\end{aligned}\n\\tag{3.13}\\]\n\n3.5.1 Stability of the steady states\nThe steady states of Equation 3.13 are \\((W_1, P_1) = (0,0)\\), \\((W_2, P_2) = (a,0)\\), \\((W_3, P_3) = (1,0)\\).\nThe Jacobian matrix is given by \\[\nJ(W,P) = \\begin{pmatrix}\n\\frac{\\partial F}{\\partial W} & \\, \\frac{\\partial F }{\\partial P}\\\\\n\\frac{\\partial G }{\\partial W} & \\, \\frac{\\partial G }{\\partial P}\n\\end{pmatrix}  =\n\\begin{pmatrix}\n0 & \\,  1\\\\\n- f^\\prime(W) & \\, - v\n\\end{pmatrix}\n\\]\nAt steady states \\((W_j, P_j)\\), the eigenvalues of \\(J(W_j,P_j)\\) are solutions of the characteristic polynomial \\[\n\\det(J(W_j,P_j) - \\lambda I) = \\begin{vmatrix} -\\lambda & \\, 1\\\\\n- f^\\prime(W_j) & \\, -v - \\lambda\n\\end{vmatrix} = \\lambda^2 + v \\lambda + f^\\prime(W_j) = 0 .\n\\]\nTherefore:\n\\[\n\\lambda^{\\pm}_j = \\frac{ - v \\pm \\sqrt{ v^2 - 4 f^\\prime(W_j)}}2.\n\\]\nAt \\((W_1, P_1)=(0,0)\\) since \\(f^\\prime(0) &lt;0\\) we obtain $ _1^{-} &lt;0&lt;_1^{+} $ and it is a saddle point. \\\nAt \\((W_2, P_2)=(a,0)\\) since \\(f^\\prime(a) &gt;0\\) we obtain \\[\n(a,0) - \\begin{cases}\n\\text{ focus} \\quad \\text{ if} \\, v^2 &lt; 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n  \\text{ node} \\quad \\text{ if} \\, v^2 \\geq 4 f^\\prime(a) \\text{ and is stable if } v&gt;0,   \\text{ unstable if } v&lt;0, \\\\\n   \\text{centre } \\quad \\text{ if} \\, v=0 \\; . \\\\\n\\end{cases}\n\\] \\ At \\((W_3, P_3)=(1,0)\\) since \\(f^\\prime(1) &lt;0\\) we obtain $ _3^{-} &lt;0&lt;_3^{+} $ and it is a saddle point. \\\nEigenvectors are given by \\[\nP =\\lambda W\n\\] and at each steady state we have two eigenvectors \\[\n\\Psi_j^{\\pm} = \\begin{pmatrix}\nW\\\\\n\\lambda_j^\\pm W\n\\end{pmatrix} , \\qquad  j=1,2, 3.\n\\]\nAs we vary the wave speed \\(v\\), the stable and unstable manifolds move and we wish to show that for some \\(v\\) the unstable manifold leaving one saddle point coincides with the stable manifold entering the other saddle point, i.e. we can choose a value for the wave speed \\(v\\) such that a heteroclinic connection between \\((1,0)\\) and \\((0,0)\\) is obtained. We shall use a “shooting argument” to prove this.\n\n\n\nFigure 3.6: Schematic diagram of eigenvectors.\n\n\n\n\n3.5.2 Relation between sign of \\(v\\) and sign of \\(\\int\\limits_0^1 f(u) \\, du\\)\nConsider Equation 3.12, multiply it by \\(\\dfrac{dW}{dz}\\) and integrate over \\((-\\infty, + \\infty)\\): \\[\n\\int_{-\\infty}^{+ \\infty}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{-\\infty}^{+ \\infty}f(W)\\dfrac{dW}{dz} \\, dz =0.\n\\]\nThen \\[\n\\frac 12 \\int_{-\\infty}^{+ \\infty}  \\dfrac{d}{dz} \\left(\\left|\\dfrac{dW}{dz}\\right |^2\\right) \\, dz + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{W(-\\infty)}^{W(+\\infty)}f(W) \\, dW =0\n\\] and since \\(W(z) \\to 1\\) as \\(z \\to - \\infty\\) and \\(W(z) \\to 0\\) as \\(z \\to + \\infty\\) we obtain\n\\[\n\\frac 12 \\left( \\left|\\dfrac{dW(+\\infty)}{dz}\\right |^2-   \\left|\\dfrac{dW(-\\infty)}{dz}\\right |^2\\right)  + v\\int_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  + \\int_{1}^{0}f(W) \\, dW =0.\n\\] The fact that \\(W\\) is constant at \\(\\pm \\infty\\) implies that \\[\n\\dfrac{dW}{dz}\\Big|_{z=-\\infty} = \\dfrac{dW}{dz}\\Big|_{z=+\\infty}=0.\n\\] Thus we have\n\\[\nv\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2\\, dz  =  \\int\\limits_{0}^{1}f(W) dW\n\\] and \\[\nv= \\dfrac {\\int\\limits_{0}^{1}f(W) \\, dW}{\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz}.\n\\] Since \\(\\int\\limits_{-\\infty}^{+ \\infty} \\left|\\dfrac{dW}{dz} \\right|^2 dz &gt;0\\) we can conclude that \\[\n\\int_{0}^{1}f(u) \\, du &gt; 0  \\quad  \\Longrightarrow  \\quad v&gt; 0, \\\\\n  \\int_{0}^{1}f(u) \\, du =0 \\quad  \\Longrightarrow  \\quad v=0, \\\\\n   \\int_{0}^{1}f(u) \\, du &lt; 0  \\quad  \\Longrightarrow \\quad v &lt; 0.\n\\]\n\n\n3.5.3 The shooting method proof of a heteroclinic connection\n\n3.5.3.1 Numerical shooting method\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=300\n\na=0.2\nN_z=5000\n\nz=np.linspace(1,T,N_z)\n\nu_0=[0.99,-0.0001]\n\nc_1=2.0\nc_2=0.6\nc_3=0.425\n\ndef bistableTrWaveODErhs(u, t, c):\n    f=np.zeros_like(u)\n    reaction=u[0]*(u[0]-a)*(1-u[0]) \n\n    f[0]=u[1]\n    f[1]=-c*u[1]-reaction\n    return f  \n\nsol=odeint(bistableTrWaveODErhs,u_0,z, args=(c_1,))\nsol2=odeint(bistableTrWaveODErhs,u_0,z, args=(c_2,))\nsol3=odeint(bistableTrWaveODErhs,u_0,z, args=(c_3,))\n\nfig, ax = plt.subplots(1)\nplt.plot(sol[:,0],sol[:,1], 'r')\nplt.plot(sol2[:,0],sol2[:,1], 'b')\nplt.plot(sol3[:,0],sol3[:,1], 'k')\nax.set_xlim([-0.05, 1.05])\n\nplt.xlabel('$u$')\nplt.ylabel('$du/dz$')\nplt.legend(['c='+str(c_1),'c='+str(c_2), 'c='+str(c_3)])\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 3.7: Numerical solution of bistable PDE\n\n\n\n\nAssume \\[\n\\int\\limits_{0}^{1}f(u) \\, du &gt; 0.\n\\] i.e. \\(v&gt;0\\).\n\nConsider first \\(v=0\\).\nFrom the equations in Equation 3.13 and the assumptions on the function \\(f\\) we have\n\nIf \\(W \\in (0,a)\\)\nUsing the fact that \\(f(W) &lt;0\\) for \\(W \\in (0,a)\\) and \\(P&lt;0\\) and \\(v=0\\) we have \\[        \n  \\begin{cases}\n  \\dfrac{dW}{dz} = P &lt;0, \\\\\n  \\dfrac{dP}{dz} = - f(W) &gt;0\n  \\end{cases}  \\quad  \\rightarrow \\quad \\dfrac{dP}{dW} &lt;0\n  \\] Thus the trajectory enters \\((0,0)\\) with \\[\n\\dfrac{dP}{dW} &lt;0,\n\\] along the stable manifold \\(\\textit{M}_s^{(0,0)}\\) and intersects the line \\(\\{ W=a\\}\\) at the point \\((a, P_0)\\).\nIf \\(W \\in (a,1)\\)\nUsing the fact that \\(f(W) &gt;0\\) for \\(W \\in (a,1)\\) and \\(P&lt;0\\) and \\(v=0\\) we have \\[\n  \\begin{cases}\n  \\dfrac{dW}{dz} = P &lt;0, \\\\\n  \\dfrac{dP}{dz} = - f(W) &lt;0\n  \\end{cases}  \\quad  \\rightarrow \\quad \\dfrac{dP}{dW} &gt;0\n  \\] Thus the trajectory leaves \\((1,0)\\) with \\[\n   \\dfrac{dP}{dW} &gt;0\n  \\] along the unstable manifold \\(\\textit{M}_u^{(1,0)}\\) and intersects the line \\(\\{ W=a\\}\\) at the point \\((a, P_1)\\).\n\n\n\n\n\nFigure 3.8: Schematic diagram of eigenvectors.\n\n\nNow we shall compare \\(P_0\\) and \\(P_1\\). For this we consider again equation Equation 3.12, multiply by \\(\\dfrac{dW}{dz}\\) and integrate first over \\((-\\infty, z^\\ast)\\) and then over \\((z^\\ast, + \\infty)\\), where \\(z^\\ast \\in (-\\infty, + \\infty)\\) such that \\(W(z^\\ast)=a\\). Then since \\(v=0\\) we have first \\[    \n    \\int_{-\\infty}^{z^\\ast}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz   + \\int_{-\\infty}^{z^\\ast}f(W)\\dfrac{dW}{dz} \\, dz =0.\n\\] and \\[\n    \\frac 12\\left|\\dfrac{dW}{dz}\\right|^2 \\Big|_{z=-\\infty}^{z=z^\\ast}  + \\int_{W(-\\infty)}^{W(z^\\ast)}f(W) dW=0 \\; .\n\\] Since \\(W(-\\infty) =1\\) we are moving along the unstable manifold \\(M_u^{(1,0)}\\) and \\[\n\\dfrac{dW(z^\\ast)}{dz}=P(z^\\ast+ 0) = P_1.\n\\] Thus using that \\(\\dfrac{dW}{dz}\\Big|_{z= - \\infty} =0\\) we obtain\n\\[\n    \\frac 12 P^2_1  + \\int_{1}^{a}f(W) dW=0 \\; \\quad  \\Longrightarrow \\quad  P_1^2 = 2 \\int_{a}^{1}f(W) dW\n\\] Integration over \\((z^\\ast, + \\infty)\\) implies \\[\n\\int_{z^\\ast}^{+ \\infty}  \\dfrac{d^2W}{dz^2} \\dfrac{dW}{dz} \\, dz   + \\int_{z^\\ast}^{+ \\infty} f(W)\\dfrac{dW}{dz} \\, dz =0.\n\\] and \\[\n    \\frac 12 \\left|\\dfrac{dW(+ \\infty)}{dz}\\right|^2 -  \\frac 12 \\left|\\dfrac{dW(z^\\ast)}{dz}\\right|^2  + \\int_{W(z^\\ast)}^{W(+ \\infty)} f(W) \\, dW =0 \\; .\n\\] Since \\(W(+\\infty) =0\\) we are moving along the stable manifold \\(M_s^{(0,0)}\\) and \\(\\dfrac{dW(z^\\ast)}{dz}=P(z^\\ast- 0) = P_0\\). Thus using that \\(\\dfrac{dW}{dz}\\Big|_{z= + \\infty} =0\\) we obtain \\[\n    -\\frac 12 P^2_0  + \\int_{a}^{0}f(W) dW=0 \\;  \\quad  \\Longrightarrow \\quad  P_0^2 = - 2 \\int_{0}^{a}f(W) dW\\; .\n\\] Since \\[\n\\int\\limits_{0}^{1}f(u) \\, du &gt; 0\n\\] we obtain \\[\nP^2_1 - P_0^2=2 \\int\\limits_{0}^{1}f(W) \\, dW &gt; 0   \\quad  \\Longrightarrow \\quad P^2_1 &gt; P_0^2\n\\] Then since \\(P&lt;0\\) we have \\[\nP_1 &lt; P_0 \\; .\n\\]\n\nConsider \\(v&gt;0\\) large.\n\nFrom the equations in Equation 3.13 and the assumptions on the function \\(f\\) we have\n* If $W \\in (0,a)$\nUsing the fact that \\(f(W) &lt;0\\) for \\(W \\in (0,a)\\), \\(P&lt;0\\) and \\(v&gt;0\\) we have\n\\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{dW}{dz} &= P &lt;0, \\\\\n\\dfrac{dP}{dz} &= -vP- f(W) &gt;0\n\\end{cases}  \\quad  \\Longrightarrow \\quad \\dfrac{dP}{dW} &lt;0\n\\end{aligned}\n\\] Thus \\(P(W)\\) is always decreasing for \\(W \\in (0,a)\\). * If \\(W \\in (a,1)\\)\nUsing the fact that \\(f(W) &gt;0\\) for \\(W \\in (a,1)\\), \\(P&lt;0\\) and \\(v&gt;0\\) we have\n\\[\n\\begin{aligned}\n\\dfrac{dW}{dz} = P &lt;0, \\\\\n\\\\\n\\begin{cases}\n\\dfrac{dP}{dz} = -vP- f(W) &lt;0  \\quad \\text{ for small }  |P| \\textrm{ and }\n\\dfrac{dP}{dz} = -vP- f(W) &gt;0  \\quad \\text{ for large  } |P|.\n\\end{cases}\n\\end{aligned}\n\\]\nThus \\[\n\\begin{cases}\n\\dfrac{dP}{dW}   &gt;0 \\quad    \\text{ for small }  |P| ,\\\\\n\\\\\n\\dfrac{dP}{dW}  &lt;0  \\quad  \\text{ for large }  |P|\\; .\n\\end{cases}\n\\]\nTherefore if \\(v&gt;0\\) large we have that \\(P(W)\\) is monotone increasing for small \\(|P|\\) and monotone decreasing for large \\(|P|\\).\n\n\n\nFigure 3.9: Schematic diagram.\n\n\nThus since for \\(v=0\\) we have \\(P_1 &lt; P_0\\) and for \\(v&gt;0\\) we have that \\(P(W)\\) is monotone decreasing for large \\(|P|\\), due to the continuity of the phase trajectories with respect to the velocity \\(v\\) we obtain that there exists a travelling wave speed \\(v_0 &gt;0\\) such that \\(P_0= P_1\\) and we have a heteroclinic connection between \\((1,0)\\) and \\((0,0)\\) in the phase plane. Hence for \\(v=v_0\\) there exists a travelling wave front solution for the bistable Equation 3.11.\nWe can repeat the analysis for \\[  \n\\int\\limits_{0}^{1}f(u) \\, du &lt; 0\n\\] and obtain a travelling wave solution with \\(v_0 &lt;0\\).\nIf \\[\n\\int\\limits_{0}^{1}f(u) \\, du = 0,\n\\] then we have a standing wave with \\(v=0\\), since the calculations for \\(P_0\\) and \\(P_1\\) implies \\(P_0=P_1\\) and there exists a heteroclinic orbit between \\((1,0)\\) and \\((0,0)\\) in the phase space.\nNote: There exists a unique travelling wave velocity \\(v\\) for which we have a travelling wave solution for bistable Equation 3.11."
  },
  {
    "objectID": "nonlinearreactiondiffusion.html#references",
    "href": "nonlinearreactiondiffusion.html#references",
    "title": "3  Non linear reaction diffusion equations",
    "section": "3.6 References",
    "text": "3.6 References\n\n\n\n\nKolmogorov, AN, IG Petrovsky, and NS Piskunov. 1937. “Investigation of the Equation of Diffusion Combined with Increasing of the Substance and Its Application to a Biology Problem.” Bull. Moscow State Univ. Ser. A: Math. Mech 1 (6): 1–25.\n\n\n“The Wave of Advance of Advantageous Genes.” 1937. Annals of Eugenics 7 (4): 355–69."
  },
  {
    "objectID": "LotkaVolteraPDE.html#nondimensionalization",
    "href": "LotkaVolteraPDE.html#nondimensionalization",
    "title": "4  Lotka Voltera model",
    "section": "4.1 Nondimensionalization",
    "text": "4.1 Nondimensionalization\nConsider the scaling \\[\nx^\\ast = x \\sqrt{\\frac \\rho {D_n}}, \\qquad t^\\ast = \\rho, t , \\quad u^\\ast = \\frac uK, \\quad n^\\ast = n \\frac \\alpha \\rho.\n\\] Upon dropping the asteriked notation, Equation 4.1 transform to \\[\n\\begin{cases}\n&\\dfrac{\\partial u}{\\partial t} =  u ( 1 - u - n)  + D \\dfrac{\\partial^2 u}{\\partial x^2}\\; = \\; f(u,n) + D\\dfrac{\\partial^2 u}{\\partial x^2} \\qquad x\\in \\mathbb R , t&gt;0 \\,,  \\\\\n& \\dfrac{\\partial n}{\\partial t} = a\\,  n(u -b) + \\dfrac{\\partial^2  n}{\\partial x^2}\\; =\\; \\;  g(u,n) + \\dfrac{\\partial^2  n}{\\partial x^2}\\;  \\qquad x\\in \\mathbb R , t&gt;0,\n\\end{cases}\n\\tag{4.2}\\] where \\[\nD= \\dfrac{D_u}{D_n}, \\quad a = \\dfrac{\\beta K}\\rho, \\quad   b = \\dfrac \\gamma{ K \\beta}.\n\\]"
  },
  {
    "objectID": "LotkaVolteraPDE.html#numerical-solutions",
    "href": "LotkaVolteraPDE.html#numerical-solutions",
    "title": "4  Lotka Voltera model",
    "section": "4.2 Numerical solutions",
    "text": "4.2 Numerical solutions\nIn Figure 4.1 we plot numerical solution of Equation 4.2. No flux boundary conditions are imposed at \\(x=0\\) and \\(x=150\\).\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n\nT=100\nL=150\n\na=0.2\nb=0.4\nD_u=0.10\n\nN_x=100\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=b+(1-b)*0.5*(1+np.tanh(1*0.5*(x-50)))\nn_0=(1-b)*0.5*(1+np.tanh(-1*0.5*(x-50)))\n\nu_0=np.concatenate((u_0,n_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    n=sol[N_x:2*N_x]\n\n\n\n    f_u=np.zeros_like(u)\n    f_n=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=D_u/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n    i=0\n    f_u[i]=D_u/dx**2*(-u[i]+u[i+1]) \n    i=N_x-1\n    f_u[i]=D_u/dx**2*(u[i-1]-u[i])\n\n    for i in range(1,N_x-2):\n      f_n[i]=1/dx**2*(n[i-1]-2*n[i]+n[i+1]) \n    i=0\n    f_n[i]=1/dx**2*(-n[i]+n[i+1]) \n    i=N_x-1\n    f_n[i]=1/dx**2*(n[i-1]-n[i])\n\n    reaction_u=u*(1-u-n)\n    reaction_n=a*n*(u-b)\n\n    f_u=f_u+reaction_u\n    f_n=f_n+reaction_n\n\n    f= np.concatenate((f_u, f_n)) \n    return f  \n\nsol=odeint(LVPDErhs,u_0,t)\n\nu=sol[:,0:N_x]\nn=sol[:,N_x:2*N_x]\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, n[0,:],'r--')\nax[1].plot(x, n[16,:],'b--')\nax[1].plot(x, n[32,:],'m--')\nax[1].plot(x, n[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$n$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.1: Numerical solution of LV model. \\(a\\)=0.2. \\(b\\)=0.4."
  },
  {
    "objectID": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "href": "LotkaVolteraPDE.html#spatially-homogeneous-steady-states",
    "title": "4  Lotka Voltera model",
    "section": "4.3 Spatially homogeneous steady states",
    "text": "4.3 Spatially homogeneous steady states\nWe firstly consider spatially homogeneous steady states, i.e. \\[\nf(u,n) =0, \\quad g(u,n) = 0.\n\\] Thus \\[\n\\begin{aligned}\n&u(1-u-n) = 0,  \\quad  u =0, \\quad u+n=1,\\\\\n& an(u-b) = 0,  \\quad n =0, \\quad u =b.\n\\end{aligned}\n\\] Thus the steady states are \\[\n(u_1^\\ast, n_1^\\ast)= (0,0), \\quad (u_2^\\ast, n_2^\\ast)= (1,0), \\quad (u_3^\\ast, n_3^\\ast)= (b,1-b), \\, 0\\leq b &lt;1.\n\\]"
  },
  {
    "objectID": "LotkaVolteraPDE.html#stability-of-steady-states-to-spatially-homogeneous-perturbations",
    "href": "LotkaVolteraPDE.html#stability-of-steady-states-to-spatially-homogeneous-perturbations",
    "title": "4  Lotka Voltera model",
    "section": "4.4 Stability of steady states to spatially homogeneous perturbations",
    "text": "4.4 Stability of steady states to spatially homogeneous perturbations\nThe Jacobian matrix is \\[\n\\begin{aligned}\nJ(u_j^\\ast, n^\\ast_j) =\n\\begin{pmatrix}\n1-2u -n & -u \\\\\nan &a(u-b)\n\\end{pmatrix}_{(u^\\ast_j, n^\\ast_j)}, \\quad j = 1,2,3.\n\\end{aligned}\n\\]\nAt the steady state \\[\n(u_1^\\ast, n_1^\\ast)= (0,0)\n\\]\nthe characteristic equation is \\[\n\\det(J (0,0) - \\lambda I) = - (1- \\lambda)(\\lambda+ ab) = 0.\n\\]\nThe eigenvalues are \\[\n\\lambda_1^+ = 1, \\quad \\lambda_1^- = - ab &lt;0.\n\\]\nThus \\((0,0)\\) is a saddle point.\nAt the steady state\n\\[\n(u_2^\\ast, n_2^\\ast)= (1,0)\n\\]\nthe characteristic equation is\n\\[\n\\det(J (1,0) - \\lambda I) = - (1+ \\lambda)(a(1-b)- \\lambda) = 0.\n\\]\nThe eigenvalues are\n\\[\n\\lambda_2^- =- 1, \\quad \\lambda_2^+ = a(1-b) &gt;0 \\; \\text{ for } \\; 0 \\leq b &lt;1.\n\\]\nThus \\((1,0)\\) is a saddle point.\nAt the steady state \\[\n(u_3^\\ast, n_3^\\ast)= (b,1-b)\n\\]\nthe characteristic equation is\n\\[\n\\det(J (b,1-b) - \\lambda I) =\\lambda^2 + b \\lambda + ab(1-b) = 0.\n\\]\nIf \\[\n4 ab (1-b) \\leq b^2  \\implies \\lambda_3^{\\pm} &lt; 0,\n\\] (\\(b,1-b\\)) is a stable node.\nIf\n\\[\n4 ab (1-b) &gt; b^2 \\qquad \\implies  \\Re(\\lambda_3{\\pm}) &lt; 0,  \\Im(\\lambda_3^{\\pm}) \\neq 0,\n\\] (\\(b,1-b\\)) is a stable focus (spiral).\nFor \\(b&gt;0\\), \\(1-b&gt;0\\) spiral oscillations are biologically realistic so long \\(u&gt;0\\) and \\(n&gt;0\\)."
  },
  {
    "objectID": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "href": "LotkaVolteraPDE.html#existence-of-travelling-wave-profiles-connection-10-and-b1-b",
    "title": "4  Lotka Voltera model",
    "section": "4.5 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)",
    "text": "4.5 Existence of travelling wave profiles connection \\((1,0)\\) and \\((b,1-b)\\)\nCondider the travelling wave ansatz \\[\n\\begin{aligned}\nu(t,x) &= W(x+ vt) = W(z), \\quad v&gt;0, \\\\\nn(t,x) &= N( x + vt) = N(z), \\quad v &gt;0.\n\\end{aligned}\n\\]\nWe consider boundary conditions that connect \\((1,0)\\) to \\((b,1-b)\\), i.e. \\[\n\\begin{aligned}\nu(t,x) \\to 1 \\; \\text{ as } x \\to - \\infty,  & \\; \\qquad  W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad\\\\\nu(t,x) \\to b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad   W(z)\\to b \\; \\text{ as } z \\to + \\infty, \\\\\nn(t,x) \\to 0 \\;  \\text{ as } x \\to - \\infty ,  &\\qquad  \\;  N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad \\\\\nn(t,x) \\to 1-b \\; \\text{ as } x \\to +\\infty, & \\;  \\qquad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty.\n\\end{aligned}\n\\]\nEquation 4.2 transforms to \\[\n\\begin{aligned}\nv \\frac{dW}{dz} &= D \\frac{d^2W}{dz^2} + W(1-W-N),\\\\\nv \\frac{dN}{dz} &=  \\frac{d^2N}{dz^2} + a N(W-b),\n\\end{aligned}\n\\]\nwith boundary conditions given by \\[\n\\begin{aligned}\n& W(z)\\to 1 \\; \\text{ as } z \\to - \\infty, \\quad W(z)\\to b \\; \\text{ as } z \\to + \\infty, \\\\\n& N(z)\\to 0 \\;  \\text{ as } z \\to - \\infty, \\quad N(z)\\to 1-b \\;  \\text{ as } z \\to +\\infty.\n  \\end{aligned}\n\\tag{4.3}\\]\nUpon making the assumption that the prey moves much more slowly than the predator species, i.e.  \\[\nD= \\frac{D_u}{D_n} \\ll 1,\n\\]\nEquation 4.3 simplify to\n\\[\n\\begin{aligned}\nv \\frac{dW}{dz} &=  W(1-W-N) ,\\\\\nv \\frac{dN}{dz} &=  \\frac{d^2N}{dz^2} + a N(W-b).\n\\end{aligned}\n\\tag{4.4}\\]\nWe can rewrite Equation 4.4 as a system of first order ODEs: \\[\n\\begin{aligned}\n\\frac{dW}{dz} &= \\frac 1 v W(1-W-N) = F(W,N,P),\\\\\n\\frac{dN}{dz} &= P  = G(W, N,P),\\\\\n\\frac{dP}{dz} &= v P - a N(W-b)  = R(W,N,P).\n\\end{aligned}\n\\tag{4.5}\\]\nThe steady states of Equation 4.5 are \\[\n\\begin{aligned}\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) &= (0,0,0),\\\\\n(W^\\ast_2, N^\\ast_2, P^\\ast_2) &= (1,0,0), \\\\\n(W^\\ast_3, N^\\ast_3, P^\\ast_3) &=(b, 1-b, 0).\n\\end{aligned}\n\\]\nThe Jacobian matrix is \\[\nJ(W,N,P) = \\begin{pmatrix}\n\\dfrac 1 v - \\dfrac{2W} v - \\dfrac Nv & - \\dfrac Wv & 0 \\\\\n0 & 0 & 1 \\\\\n- aN & a(b-W) & v\n\\end{pmatrix}.\n\\]\nAt \\[\n(W^\\ast_1, N^\\ast_1, P^\\ast_1) = (0,0,0)\n\\]\nwe have \\[\n\\det(J(0,0,0) - \\lambda I)= \\left( \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v - ab) =0\n\\] and \\[\n\\lambda_1^1= \\frac 1 v &gt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 + 4 ab} } 2.\n\\]\nThus \\((0,0,0)\\) is a saddle point with a \\(2\\)-dim unstable manifold.\nAt \\((W^\\ast_2, N^\\ast_2, P^\\ast_2) = (1,0,0)\\) we have \\[\n\\det(J(1,0,0) - \\lambda I)= \\left(- \\frac 1 v - \\lambda\\right) (\\lambda^2 - \\lambda v + a(1-b)) =0,\n\\]\nand \\[\n\\lambda_1^1= -\\frac 1 v &lt; 0, \\quad \\lambda_2^{\\pm} = \\frac{ v \\pm \\sqrt{v^2 - 4 a(1-b)} } 2.\n\\]\nSince \\[\n0\\leq b &lt; 1 and 4(1-b)&gt;0,\n\\]\n\nIf \\(v^2 \\geq 4 a(1-b)\\), (1,0,0) is a saddle with 2-dim unstable manifold.\\\nIf \\(v^2 &lt; 4 a(1-b)\\) (1,0,0)is an unstable focus\n\nThus for a travelling wave with \\(W\\geq 0\\) and \\(N \\geq 0\\) to exist we require \\[\nv^2 \\geq  4 a(1-b)\n\\]\nand obtain a minimal wave speed \\[\nv_\\text{min}=2\\sqrt{a(1-b)}   \\quad \\text{ with } \\quad  0\\leq b&lt;1.\n\\]\nAt \\[\n(W^\\ast_3, N^\\ast_3, P^\\ast_3) =(b, 1-b, 0)\n\\] we have \\[\n\\det(J(b,1-b,0) - \\lambda I)= \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b) = p(\\lambda) =0.\n\\]\nIt can be shown that the extrema of \\(p(\\lambda)\\) are independent of the parameter \\(a\\).\nTo identify extrema, we compute \\[\np^\\prime(\\lambda) = 3 \\lambda^2 - 2 \\lambda \\left( v - \\frac b v\\right) - b = 0\n\\]\nand find that \\[\n\\lambda_{m,M}= \\frac 13 \\left[ \\left(v - \\frac bv \\right) \\pm \\sqrt{ \\left(v - \\frac bv\\right) ^2 + 3 b } \\right].\n\\]\nIf \\(a=0\\), the eigenvalues are \\[\n\\lambda_3^1 = 0, \\quad \\lambda_3^\\pm = \\frac 12 \\left( v - \\frac bv \\pm \\sqrt{\\left(v - \\frac bv\\right)^2 + 4 b} \\right).\n\\]\nThus there exists a critical value \\(a^\\ast&gt;0\\) such that for \\(a \\in (0, a^\\ast)\\), we obtain two real negative eigenvalues and one positive real eigenvalue. Hence \\((b, 1-b, 0)\\) is a saddle with \\(2\\)-dim stable manifold and \\(1\\)-dim unstable manifold\nFor \\(a&gt;a^\\ast\\), we obtain a pair of complex conjugate eigenvalues with negative real part and one real positive eigenvalue corresponding to \\(1\\)-dim unstable manifold.\nThis can be easily seen from a sketch of the cubic equation:\n\\[\np(\\lambda) = \\lambda^3 - \\lambda^2(v- \\frac b v) - \\lambda b - \\frac 1 v ab(1-b).\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlam=np.linspace(-1.2,1.2,100)\na=0.0\na2=0.05\na3=0.2\nb=0.2\nv=0.5\n\np1= lam**3-lam**2*(v-b/v)-lam*b-1/v*a*b*(1-b)\np2= lam**3-lam**2*(v-b/v)-lam*b-1/v*a2*b*(1-b)\np3= lam**3-lam**2*(v-b/v)-lam*b-1/v*a3*b*(1-b)\n\nfig, ax= plt.subplots()\nax.plot(lam,p1,lam,p2,lam,p3)\nax.grid(True)\n\n\n\n\n\nFigure 4.2: Plot of cubic.\n\n\n\n\nThus we have a possible heteroclinic connection between \\((1,0,0)\\) and \\((b, 1-b, 0)\\), i.e. between \\(2\\)-dim unstable manifold at \\((1,0,0)\\) and \\(2\\)-dim stable manifold at \\((b, 1-b, 0)\\), and therefore an existence of a travelling wave front solution for Equation 4.2 with\n\\[\n\\begin{aligned}\nu(x,t) \\to 1 \\; \\textrm{ as } x \\to - \\infty,  \\quad & u(x,t) \\to b \\; \\textrm{ as } x \\to +\\infty,  \\\\\nn(x,t) \\to 0 \\;  \\textrm{ as } x \\to - \\infty ,  \\quad & n(x,t) \\to 1-b \\; \\textrm{ as } x \\to +\\infty.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "LotkaVolteraPDE.html#exercise",
    "href": "LotkaVolteraPDE.html#exercise",
    "title": "4  Lotka Voltera model",
    "section": "4.6 Exercise",
    "text": "4.6 Exercise\nUse Python code to numerically investigate dependence of travelling wave solution on the parameter \\(a\\)."
  },
  {
    "objectID": "BacterialChemotaxis.html#model-derivation",
    "href": "BacterialChemotaxis.html#model-derivation",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.1 Model derivation",
    "text": "5.1 Model derivation\nWe consider a model for Dicty aggregation through the secretion of and chemotactic response to cAMP. We denote by \\(n({\\mathbf{x}}, t)\\) the density of amoebae and \\(a({\\mathbf{x}}, t)\\) the concentration of cAMP. The general conservation equation for the amoebae can be written:\n\\[\n\\frac{\\partial n}{\\partial  t} + \\nabla \\cdot {\\mathbf{J}} = f(n,a),\n\\] where \\(f(n,a)\\) models any reaction terms for the amoebae e.g. proliferation, and the flux is given by \\[\n{\\mathbf{J}} = {\\mathbf{J}}_{diffusion} + {\\mathbf{J}}_{chemotaxis}.\n\\]\nAssuming Fickian diffusion and the general chemotactic flux stated earlier (Section 1.1), the general reaction-diffusion-chemotaxis model for the amoebae responding to cAMP is given by:\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  \\underbrace{D_n \\nabla^2 n}_{diffusion} - \\underbrace{\\nabla \\cdot \\left( \\chi(a) n \\nabla a \\right)}_{chemotaxis} + f(n,a),   \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a + g(n,a),\n\\end{aligned}\n\\]\nwhere we have assumed Fickian diffusion for the cAMP and \\(g(a,n)\\) represents the kinetics i.e. source/sink terms, of cAMP.\nOne simple model has the following assumptiond:\n\\[f(n,a) = 0, \\;\\;\\; g(n,a) = \\mu n - \\delta a, \\;\\;\\; \\chi (a) = \\chi_0\\]\ni.e. \n\nthere are no kinetics for the amoebae - they simply move randomly via diffusion and undergo chemotaxis in response to cAMP;\nproliferation is neglected; - this is a reasonable assumption given the timescales involved, since they amoebae move on a faster timescale than they proliferate;\nthe amoebae are assumed to produce cAMP in proportion to their density, which means the more amoebae there are, the more cAMP (a reasonable first approximation);\nthe chemotactic function is taken to be a constant, again a reasonable first approximation;\n\\(D_a &gt; D_n\\) since chemicals diffuse faster than cells move randomly.\n\nUnder such assumptions we obtain the model equation\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} & =  D_n \\nabla^2 n - \\chi_0 \\nabla \\cdot \\left( n \\nabla a \\right), \\\\\n\\frac{\\partial a}{\\partial  t} & =   D_a \\nabla^2 a +  \\mu n - \\delta a,\n\\end{aligned}\n\\]\nwhich becomes, upon considering a 1-dimensional domain \\([0,L]\\),\n\\[\n\\begin{aligned}\n\\frac{\\partial n}{\\partial  t} &=  D_n \\frac{\\partial ^2 n}{\\partial x^2} - \\chi_0 \\frac{\\partial}{\\partial x} \\left( n \\frac{\\partial a}{\\partial x} \\right), \\\\\n  & & \\hspace{4.5cm} ( \\dagger ) \\\\\n\\frac{\\partial a}{\\partial  t} &=  D_a \\frac{\\partial ^2 a}{\\partial x^2}  +  \\mu n - \\delta a,\n\\end{aligned}\n\\tag{5.1}\\]\nwith zero flux boundary conditions:\n\\[\n\\begin{aligned}\nD_a \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L, \\\\\nD_n \\frac{\\partial n}{\\partial  x} - \\chi_0 n \\frac{\\partial a}{\\partial  x} & =  0, \\;\\;\\; x = 0,L.\n\\end{aligned}\n\\]\nThese reduce to:\n\\[\n\\frac{\\partial a}{\\partial  x} = \\frac{\\partial n}{\\partial  x} = 0, \\;\\;\\; x = 0,L.\n\\]"
  },
  {
    "objectID": "BacterialChemotaxis.html#numerical-solutions",
    "href": "BacterialChemotaxis.html#numerical-solutions",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.2 Numerical solutions",
    "text": "5.2 Numerical solutions\nIn Figure 5.2 we plot numerical solution of Equation 5.1 together with no-flux boundary condition. The initial data are uniformly sampled. Note the emergence of periodic spatial structure in both variables. These correspond to peaks and troughs of cell density. The cells produce chemoattractant, \\(a\\), and the this induces a chemtactic flux up the gradient in \\(a\\). Hence more cells move towards regions where \\(a\\) is high, more chemoattractant is produced in this region etc.\n\nWhat is the long-time behaviour of these solutions\nFor which parameters do we expect to see pattern formation?\nHow does spatial pattern depend on the initial data?\n\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport random\n\n\nT=80\nL=150\n\nmu=1.2\ndelta=0.1\nD_n=2.50\nD_a=2.5\nchi_0=1.4\n\nN_x=200\nN_t=100\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=np.ones_like(x)+0.01*np.random.uniform(low=0.0, high=0.1, size=(N_x,))\nn_0=np.ones_like(x)\n\nu_0=np.concatenate((u_0,n_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef LVPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    n=sol[0:N_x]\n    a=sol[N_x:2*N_x]\n\n\n\n    f_n=np.zeros_like(n)\n    f_a=np.zeros_like(n)\n\n    for i in range(1,N_x-2):\n      f_n[i]=D_n/dx**2*(n[i-1]-2*n[i]+n[i+1]) - chi_0*n[i]*1/dx**2*(a[i-1]-2*a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i-1])*(n[i+1]-n[i-1])\n\n    i=0\n    f_n[i]=D_n/dx**2*(-n[i]+n[i+1]) - chi_0*n[i]*1/(2*dx)**2*(-a[i]+a[i+1])-chi_0/(2*dx)**2*(a[i+1]-a[i])*(n[i+1]-n[i])\n\n    i=N_x-1\n    f_n[i]=D_n/dx**2*(n[i-1]-n[i])- chi_0*n[i]*1/(2*dx)**2*(a[i-1]-a[i])-chi_0/(2*dx)**2*(a[i]-a[i-1])*(n[i]-n[i-1])\n\n\n    for i in range(1,N_x-2):\n      f_a[i]=D_a/dx**2*(a[i-1]-2*a[i]+a[i+1]) \n    i=0\n    f_a[i]=D_a/dx**2*(-a[i]+a[i+1]) \n    i=N_x-1\n    f_a[i]=D_a/dx**2*(a[i-1]-a[i])\n\n    reaction_n=0\n    reaction_a=mu*n-delta*a\n\n    f_n=f_n+reaction_n\n    f_a=f_a+reaction_a\n\n    f= np.concatenate((f_n, f_a)) \n    return f  \n\nsol=odeint(LVPDErhs,u_0,t)\n\nn=sol[:,0:N_x]\na=sol[:,0:N_x]\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,n[0,:],'r')\nax[0].plot(x,n[16,:],'b')\nax[0].plot(x,n[32,:],'m')\nax[0].plot(x,n[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$n$')\n\nax[1].plot(x, a[0,:],'r--')\nax[1].plot(x, a[16,:],'b--')\nax[1].plot(x, a[32,:],'m--')\nax[1].plot(x, a[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$a$')\n\nplt.legend(['t'+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.2: Numerical solution of bacterial chemtaxis model"
  },
  {
    "objectID": "BacterialChemotaxis.html#spatially-homogeneous-steady-states",
    "href": "BacterialChemotaxis.html#spatially-homogeneous-steady-states",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.3 Spatially Homogeneous Steady States",
    "text": "5.3 Spatially Homogeneous Steady States\nDefine the total number of cells, \\(N\\), \\[\nN= \\int_0^L n(x,t)dx\n\\] Upon differentiation with respect to time \\[\n\\begin{aligned}\n\\frac{dN}{dt} &=\\int_0^L \\frac{\\partial n(x,t)}{\\partial t}dx\n&=\\int_0^L  D_n \\frac{\\partial ^2 n}{\\partial x^2} - \\chi_0 \\frac{\\partial}{\\partial x} \\left( n \\frac{\\partial a}{\\partial x} \\right) dx.\n\\end{aligned}\n\\] Upon integration of the right-hand side w.r.t. \\(x\\), subsequent application of the no-flux boundary condition implies \\[\n\\frac{dN}{dt}=0.\n\\] Hence the total number of cells in the domain is fixed by the initial data. For a spatially homogeneoud solutions, th4 cells must be uniformly distributed in space, i.e. \\[\nn^*=N/L\n\\]\nAdditionaly, the spatially homogeneous steady state solution \\((n^* , a^* )\\) satisfies:\n\\[\na^*=\\frac{\\mu}{\\delta} n^*.\n\\]\nWe now undertake a linear stability analysis to determine whether this is stable or unstable. If the above spatially homogeneous steady state is unstable, this will indicate that aggregation patterns may arise in the system."
  },
  {
    "objectID": "BacterialChemotaxis.html#stability-analysis",
    "href": "BacterialChemotaxis.html#stability-analysis",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.4 Stability Analysis",
    "text": "5.4 Stability Analysis\nIn a similar manner to previous stability analyses, we consider small perturbations around the spatially homogeneous steady state \\((n^* , a^* )\\), i.e.\n\\[\nn(x,t) = n^* + \\tilde{n}(x,t), \\;\\;\\; a(x,t) = a^* + \\tilde{a}(x,t)\n\\]\nwhere \\(\\tilde{n}(x,t)\\) and \\(\\tilde{a}(x,t)\\) are “small” so that higher order terms can be neglected.\nNOTE Unlike previous stability analysis, these perturbations are both time and space dependent.\nSubstituting the above perturbations into equations \\(( \\dagger )\\), we neglect higher order terms and retain only linear terms. This is largely straightforward, but we provide some detail for the linearization of the chemotactic term i.e. \n\\[\n\\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial}{\\partial x} \\left( a^* + \\tilde{a} \\right) \\right] = \\frac{\\partial}{\\partial x} \\left[ ( n^* + \\tilde{n}) \\frac{\\partial \\tilde{a}}{\\partial x}  \\right] \\approx n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}.\n\\]\nThe fully linearized system is then given by: \\[\n\\begin{aligned}\n\\frac{\\partial \\tilde{n}}{\\partial  t} & =  D_n \\frac{\\partial ^2 \\tilde{n}}{\\partial x^2} - \\chi_0 n^* \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2} \\\\\n\\frac{\\partial \\tilde{a}}{\\partial  t} & =   D_a \\frac{\\partial ^2 \\tilde{a}}{\\partial x^2}  +  \\mu \\tilde{n} - \\delta \\tilde{a}.\n\\end{aligned}\n\\tag{5.2}\\]\nAlthough the above equations are linear, an explicit solution is non-trivial and we are required to make a further “separation of variables” ansatz. We seek solutions of the form \\[\n\\tilde{n}(t,x) = u(t) \\phi_1(x)\n\\] and \\[\n\\tilde a (t,x) = v(t) \\phi_2(x)\n\\]\nUpon substitution \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}  \\phi_1  =   D_n  u\\frac{\\partial ^2 \\phi_1}{\\partial x^2} - \\chi_0 n^*  v\\frac{\\partial ^2 \\phi_1}{\\partial x^2} \\\\\n& \\frac{\\partial v}{\\partial  t}  \\phi_2=     D_a v \\frac{\\partial ^2  \\phi_2}{\\partial x^2}  +  \\mu u \\,  \\phi_1 - \\delta v\\,  \\phi_2, \\\\\n\\end{aligned}\n\\] with boundary conditions \\[\n\\begin{aligned}\n& u \\frac{\\partial \\phi_1}{\\partial x} = 0, \\quad   v \\frac{\\partial \\phi_2}{\\partial x} = 0 \\quad \\text{ for } \\; x = 0, \\; x=L.\n\\end{aligned}\n\\]\nWe assume that\n\\[\n\\phi_1 = \\phi_2 = \\phi,\n\\] where \\(\\phi\\) is the solution of the elliptic problem \\[\n\\begin{aligned}\n\\frac{d^2 \\phi}{dx^2} &= - k^2 \\phi && \\text{ in } \\; (0,L), \\\\\n\\frac{d \\phi}{dx} &= 0  && \\text{ for } \\; x=0, \\; x=L.\n\\end{aligned}\n\\] We can compute that solution of the equation for \\(\\phi\\) are of the form \\[\n\\phi(x) = A \\cos(kx) + B\\sin(kx).\n\\] Since \\(\\phi\\) satisfied zero Neumann boundary conditions we have that \\[\n\\phi(x) = A \\cos(kx),\n\\] where \\(A\\) is an arbitrary constanr, and \\[\nk = \\dfrac {m \\pi} L, \\quad m \\in \\mathbb N.\n\\]\nThen we have \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}  \\phi  =   - k^2 D_n  u \\phi +  \\chi_0 n^* k^2\\,  v \\, \\phi,  \\\\\n& \\frac{\\partial v}{\\partial  t} \\phi =   - k^2 D_a  \\, v \\phi  +  \\mu u \\,  \\phi - \\delta v\\,  \\phi,\n\\end{aligned}\n\\] and since \\(\\phi\\) is not identically zero on \\((0,L)\\) we obtain a system of linear ODEs for \\((u(t),v(t))\\) \\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t}    =   - k^2 D_n  u  +  \\chi_0 n^* k^2\\,  v,  \\\\\n& \\frac{\\partial v}{\\partial  t} =   - k^2 D_a  \\, v  +  \\mu u  - \\delta v.\n\\end{aligned}\n\\]\nWe know that solutions of linear ODEs have the form \\[\nu(t) = C_1 e^{\\lambda t} \\quad \\textrm{and} \\quad v(t) = C_2 e^{\\lambda t}\n\\] for some constant \\(C_1\\), \\(C_2\\) and \\(\\lambda\\) are eigenvalues of the corresponding matrix.\nThus we obtain \\[\n\\begin{aligned}\n\\lambda C_1 & =  - D_n k^2 C_1  + \\chi_0 n^* k^2 C_2,  \\\\\n\\lambda C_2 & = - D_a k^2 C_2 +  \\mu C_1 - \\delta C_2,\n\\end{aligned}\n\\] which can be written\n\\[\n\\left(\n\\begin{array}{cc}\n- D_n k^2 - \\lambda &  \\chi_0 n^* k^2 \\\\\n\\mu & - D_a k^2 -\\delta -\\lambda\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\nC_1 \\\\\nC_2\n\\end{array}\n\\right) = \\mathbf{0} .\n\\]\nRemark Notice that we obtained that \\(\\tilde n\\) and \\(\\tilde a\\) are of the form \\[\\tilde{n}(x,t) = C_1 e^{\\lambda t} e^{ikx}, \\;\\;\\; \\tilde{a}(x,t) = C_2 e^{\\lambda t} e^{ikx}.\\]\nFor a non-trivial solution (for non-trivial perturbations \\(\\tilde n\\), \\(\\tilde a\\)), i.e. \\(C_1 \\neq 0\\) and \\(C_2 \\neq 0\\), the determinant of the above matrix must be zero, and this leads to the following quadratic equation to be solved for \\(\\lambda\\):\n\\[\n\\lambda^2 + \\left( D_n k^2 + D_a k^2 + \\delta \\right) \\lambda + D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 = 0.\n\\]\nThis is of the form \\[\n\\lambda^2 + \\alpha \\lambda + \\beta = 0,\n\\]\nand so has roots: \\[\n\\lambda = \\frac{-\\alpha \\pm \\sqrt{\\alpha^2 - 4 \\beta}}{2}.\\]\nNOTE This has two real roots, since \\[\n\\alpha^2 - 4 \\beta &gt; 0\n\\] (see Exercise/Tutorial).\nFor stability, we require both roots to be negative. Since both roots are real, this leads to:\n\\[\n\\lambda &lt; 0  \\Leftrightarrow \\alpha &gt; 0 \\;\\;\\; \\text{and} \\;\\;\\; \\beta &gt;0.\n\\]\nNow \\[\\alpha = D_n k^2 + D_a k^2 + \\delta &gt; 0,\n\\] and so for stability, we require \\(\\beta &gt; 0\\) i.e. \n\\[\n\\begin{aligned}\n& & D_n k^2 \\left( D_a k^2 + \\delta \\right) - \\mu \\chi_0 n^* k^2 &gt; 0 \\\\\n& & \\Rightarrow \\mu \\chi_0 n^* &lt;  D_n  \\left( D_a k^2 + \\delta \\right)\n\\end{aligned}\n\\] Hence, we will have instability when this condition is not satisfied i.e.  \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a k^2 + \\delta \\right).\n\\]\nThe precise value of \\(k^2\\) can be determined from the zero-flux boundary conditions i.e. \\[\nk  =  \\frac{m \\pi}{L}, \\;\\;\\; m = 1,2, \\dots\n\\] if we look for non-constant \\(\\phi\\).\nHence, we will have instability whenever \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( D_a \\frac{m^2 \\pi^2}{L^2} + \\delta \\right), \\;\\;\\; m = 1,2, \\dots\n\\]\nIt can be shown (see Exercise/Tutorial), that \\(\\lambda (k^2)\\) ( or \\(\\lambda (m^2)\\)) is monotonic decreasing and hence the fastest growing mode is \\(m=1\\) i.e. we have an instability as long as \\[\n\\mu \\chi_0 n^* &gt;  D_n  \\left( \\frac{D_a \\pi^2}{L^2} + \\delta \\right).\n\\]\nIn general, from the above inequality, we can say that there is a likelihood of instability (amoebae aggregation) if:\n\n\\(D_a\\), \\(D_n\\) and \\(\\delta\\) are all ``small’’\nL is ``large’’\n\\(\\chi_0 , \\mu , n^*\\) are ``large’’\n\nConsidering all other parameters to be fixed, in theory the above result states that it is possible to find a large enough value for the chemotactic coefficient \\(\\chi_0\\) to satisfy the instability condition i.e. chemotaxis induces instability and leads to aggregation of the amoebae."
  },
  {
    "objectID": "BacterialChemotaxis.html#exercise",
    "href": "BacterialChemotaxis.html#exercise",
    "title": "5  Aggregation via chemotaxis",
    "section": "5.5 Exercise",
    "text": "5.5 Exercise\nFrom the results we have obtained we deduce that:\n\nchemotaxis has a destabilizing effect\ndiffusion has a stabilizing effect on spatially homogeneous solutions\n\nIf this is true then one might expect the numerical results presented in Figure 5.2 to have spatially homogeneous solutions if the diffusion coefficient is made sufficiently large. * Can you test this by running the code for larger values of the parameter \\(D\\)? * Alternatively, what happens if you make the chemotactic coefficient \\(\\chi_0\\) smaller? * what kind of aggregation patterns do you see if the system is solved in two spatial dimensions?\nHowever, there is one type of system where diffusion also has a destabilizing effect…\n\n\n\n\nDurston, AJ. 2013. “Dictyostelium: The Mathematician’s Organism.” Current Genomics 14 (6): 355–60."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion",
    "href": "DiffusionDrivenInstability.html#spatial-pattern-formation-via-reaction-diffusion",
    "title": "6  Diffusion driven instability",
    "section": "6.1 Spatial Pattern Formation via Reaction-Diffusion",
    "text": "6.1 Spatial Pattern Formation via Reaction-Diffusion\n\n6.1.1 Pattern in Developmental Biology\nEmbryology or developmental biology is that part of biology which is concerned with the formation, growth and development of the embryo from fertilization until birth. From the very moment of conception the embryo undergoes a process of dynamic change, brought about largely by cells responding to various chemical signalling cues e.g. migration, differentiation, proliferation.\n\nMany of the processes occurring at this early stage are vital for the successful subsequent development of the embryo and also lay down basic structures (e.g. somites) that form the foundation of major body structures later on (e.g. the vertebrae of the spine)\n\n\n\n\n\n\n\nProfessor Lewis Wolpert\n\n\n\nIt is not birth, marriage, or death, but gastrulation which is truly the most important time in your life.\n\n\nA fundamental question is: how do robust pattern emerge during ermbryo development?\nIn the Turing pre-pattern theory, chemicals, or morphogens, react together and, if certain conditions concerning their reaction kinetics and diffusion rates are satisfied (to be derived in the next section), then a pre-pattern of varying chemical concentrations is set up in the spatial domain. This means that throughout the spatial domain, the concentration levels of the chemicals will vary i.e. there will be a heterogeneous distribution of chemical concentrations which is known as a pre-pattern. Any cells in the domain which subsequently encounter these varying levels of morphogens will then respond by, for example, proliferating differentially throughout the domain. In this way, the domain will then contain a spatially heterogeneous distribution of cell densities (i.e. a cellular pattern) which have responded to the morphogen pre-pattern. This pre-pattern theory was first proposed by Alan Turing (of Enigma Code fame) in his seminal 1952 paper, The chemical basis of morphogenesis Turing (1990).\nIn the mechano-chemical theory, cells interact with their surroundings and by exerting forces perturb their local environment. The combination of cell migration/proliferation and cell-generated forces is sufficient in certain circumstances to create a spatially heterogeneous distribution of cell densities i.e. the pattern is generated simultaneously with the cell migration/proliferation. This alternative pattern formation theory was proposed by Murray and Oster Murray and Oster (1984) and is particularly appropriate for patterns generated in early embryogenesis by mesenchymal cells such as fibroblasts."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "href": "DiffusionDrivenInstability.html#reaction-diffusion-turing-pre-pattern-mechanisms",
    "title": "6  Diffusion driven instability",
    "section": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms",
    "text": "6.2 Reaction-diffusion (Turing) Pre-pattern Mechanisms\nWe now consider our general (dimensional) reaction-diffusion model for two chemicals or morphogens with concentrations \\(A({\\mathbf{x}}, t)\\) and \\(B({\\mathbf{x}}, t)\\) which react together and diffuse in some spatial domain:\n\\[\n\\begin{aligned}\n\\frac{\\partial A}{\\partial  t} & =  F(A,B)  + D_A \\nabla^2 A, \\\\\n\\frac{\\partial B}{\\partial  t} & =  G(A,B)  + D_B \\nabla^2 B,\n\\end{aligned}\n\\]\nwhere \\(F(A,B)\\) and \\(G(A,B)\\) describe the reaction kinetics between the two morphogens and \\(D_A, D_B &gt; 0\\) are the diffusion coefficients. Turing’s theory (Turing, 1952) The chemical basis of morphogenesis proposed that it was the diffusion of the substances \\(A,B\\) which led to the evolution of a spatially heterogeneous solution to arise i.e. a spatial pattern. This has given rise to the phrase diffusion-driven instability. This was a rather revolutionary and counter-intuitive proposal, since, as we have seen, diffusion normally has the opposite tendency i.e. to smooth or average out spatial heterogeneities, and to give rise to spatially homogeneous solutions.\nVarious forms can be considered for the kinetic functions \\(F\\) and \\(G\\). However, we will focus mainly on three specific classes as follows:\n\n6.2.1 Schnackenberg kinetics\n\\[\nF(A,B) = k_1 - k_2 A + k_3 A^2 B, \\;\\;\\;\\; G(A,B) = k_4 - k_3 A^2 B\n\\]\n\\(k_1\\), \\(k_2\\), \\(k_3\\), \\(k_4\\) \\(&gt;0\\). The term \\(k_3 A^2 B\\) is autocatalytic, since the species \\(A\\) upregulates its own production.\n\n\n6.2.2 Gierer and Meinhardt kinetics\nGierer and Meinhardt “A Theory of Biological Pattern Formation” (1972) developed a model that describes activator-inhibitor kinetics. The total reaction rates are \\[\nF(A,B) = k_1 - k_2 A + \\frac{k_3 A^2}{B}, \\quad G(A,B) = k_4 A^2 - k_5 B\n\\]\nwhere \\(k_1\\), \\(k_2\\), \\(k_3\\), \\(k_4\\), \\(k_5\\) &gt; 0. The term \\(k_3 A^2 / B\\) is autocatalytic.\n\n\n6.2.3 Thomas kinetics\nThomas developed a model of substrate inhibition in which \\[\n\\begin{aligned}\nF(A,B) &= k_1 - k_2 A - H(A,B), \\\\\nG(A,B) &= k_4 A^2 - k_4 B -H(A,B), \\\\\nH(A,B) &= \\frac{k_5 AB}{k_6 + k_7 + k_8 A^2}.\n\\end{aligned}\n\\]\nwith \\(k_i &gt; 0\\). In the original paper of Thomas (1975), \\(A\\) represents the concentration of oxygen (substrate) and \\(B\\) the concentration of uricase (enzyme). Substrate inhibition is evident in the term \\(k_8 A^2\\)."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#non-dimensionalization",
    "href": "DiffusionDrivenInstability.html#non-dimensionalization",
    "title": "6  Diffusion driven instability",
    "section": "6.3 Non-dimensionalization",
    "text": "6.3 Non-dimensionalization\nBefore proceeding further, it is prudent to non-dimensionalize each of the above systems.\n\n6.3.1 Schnakenberg\nWe illustrate this process for the Schnakenberg kinetics. Using the scaling\n\\[\nu = A \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad v = B \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad t^* = \\frac{D_A t}{L^2},\\quad x^* = \\frac{x}{L},\n\\]\nwhere \\(L\\) is a typical length scale, the dimensionless reaction-diffusion system with Schnakenberg kinetics becomes (upon dropping the \\(*\\) for notational convenience):\n\\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma ( a - u + u^2 v ) + \\nabla^2 u = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma ( b - u^2 v ) + d \\nabla^2 v = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\tag{6.1}\\]\nwhere \\[\nd = \\frac{D_B}{D_A}, \\quad a = \\frac{k_1}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad b = \\frac{k_4}{k_2} \\left( \\frac{k_3}{k_2} \\right)^{1/2}, \\quad \\gamma = \\frac{L^2 k_2}{D_A}.\n\\]\n\n\n6.3.2 Gierer and Meinhardt\nThe Gierer-Meinhardt kinetics can be non-dimensionalized as follows:\n\\[\n\\begin{aligned}\nf(u, v) & =  a - b u + \\frac{u^2}{v},\ng(u,v) &= u^2 - v, \\\\\n\\end{aligned}\n\\] where \\(a\\) and \\(b\\) are positive parameters (Exercise/Tutorial).\n\n\n6.3.3 Thomas\nThe Thomas kinetics can be non-dimensionalized as follows:\n\\[\n\\begin{aligned}\nf(u,v) & =  a - u - h(u,v), \\\\\ng(u,v) &= \\alpha (b - v) - h(u,v), \\\\\nh(u,v) & =  \\frac{\\rho u v}{1 + u + K u^2},\n\\end{aligned}\n\\] where \\(a\\) , \\(b\\), \\(\\alpha\\), \\(\\rho\\) , \\(K\\) are positive parameters (see Exercise/Tutorial).\n\n\n6.3.4 General\nAny reaction-diffusion system can be non-dimensionalized and scaled following the above procedure to take the general form: \\[\n\\begin{aligned}\n\\frac{\\partial u}{\\partial  t} & = \\gamma f(u,v)  + \\nabla^2 u, \\\\\n\\frac{\\partial v}{\\partial  t} & = \\gamma g(u,w)  + d \\nabla^2 v,\n\\end{aligned}\n\\]\nwhere the parameter \\(d\\) is the ratio of the diffusion coefficients and the parameter \\(\\gamma\\) can be interpreted in any one of the following ways:\n\n\\(\\gamma^{1/2}\\) is proportional to the linear size of the spatial domain in one-dimension. In two-dimensions, \\(\\gamma\\) is proportional to the area.\n\\(\\gamma\\) represents the relative strength of the reaction terms – an increase in \\(\\gamma\\) may represent an increase in the activity of some rate-limiting step in the reaction sequence.\nAn increase in \\(\\gamma\\) is equivalent to a decrease in the diffusion coefficient, \\(d\\).\n\nNote that in the case where the parameter \\(d &gt; 1\\), this means that the original diffusion coefficients are not equal. Specifically, in the case of the Gierer-Meinhardt activator-inhibitor system, \\(d &gt;1\\) implies that the inhibitor diffuses more quickly than the activator [\\(d &gt; 1 \\Rightarrow D_B &gt; D_A\\) ]. The spatial implications of this are shown in Figure 6.1 – the inhibitor diffuses a greater distance than the activator, giving rise to what is known as local activation, long-range inhibition.\n\n\n\nFigure 6.1: Schematic diagram of activator inhibitor"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#numerical-solution",
    "href": "DiffusionDrivenInstability.html#numerical-solution",
    "title": "6  Diffusion driven instability",
    "section": "6.4 Numerical solution",
    "text": "6.4 Numerical solution\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\nT=3\nL=1\n\ngamma=650.0\na=0.2\nb=1.3\nd=30.0\n\nN_x=80\nN_t=50\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\n\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,))\n\nu_0=np.concatenate((u_0,v_0))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\ndef ShcnackPDErhs(sol,t):\n\n    N_x=int(np.ceil(len(sol)/2))\n\n    u=sol[0:N_x]\n    v=sol[N_x:]\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n    for i in range(1,N_x-2):\n      f_u[i]=1/dx**2*(u[i-1]-2*u[i]+u[i+1]) \n\n    i=0\n    f_u[i]=1/dx**2*(-u[i]+u[i+1])\n\n    i=N_x-1\n    f_u[i]=1/dx**2*(u[i-1]-u[i])\n\n\n    for i in range(1,N_x-2):\n      f_v[i]=d/dx**2*(v[i-1]-2*v[i]+v[i+1]) \n    i=0\n    f_v[i]=d/dx**2*(-v[i]+v[i+1]) \n    i=N_x-1\n    f_v[i]=d/dx**2*(v[i-1]-v[i])\n\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n    f= np.concatenate((f_u,f_v)) \n    return f  \n\nsol=odeint(ShcnackPDErhs,u_0,t)\nu=sol[:,0:N_x]\nv=sol[:,N_x:]\n\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, v[0,:],'r--')\nax[1].plot(x, v[16,:],'b--')\nax[1].plot(x, v[32,:],'m--')\nax[1].plot(x, v[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$v$')\n\nplt.legend(['t='+ str(t[0]),'t='+ str(t[4]),'t='+ str(t[8]),'t='+ str(t[12])])\nplt.xlabel('$x$')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 6.2: DDI with Schnackenberg kinetics.\n\n\n\n\nIn Figure 6.3 we consider a numerical solution of the Schnackenberg model on a 2D square domain with no-flux boundary conditions.\n\n\nCode\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.integrate import solve_ivp\n\nimport matplotlib.pyplot as plt\nimport random\n\nT=5\nL=1\n\ngamma=650.0\na=0.2\nb=1.3\nd=25.0\n\nN_x=20\nN_t=30\n\nt=np.linspace(1,T,N_t)\nx=np.linspace(0,L,N_x)\ny=np.linspace(0,L,N_x)\n\n[x,y]=np.meshgrid(x,y)\n\nu_0=(a+b)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\nv_0=b*(1/(a+b)**2)*np.ones_like(x)+0.01*np.random.uniform(low=-1.0, high=1.0, size=(N_x,N_x))\n\nu_0=np.concatenate((np.ravel(u_0),np.ravel(v_0)))\n\ndx=L/(N_x-1)\ndt=T/(N_t-1)\n\n\n\ndef ShcnackPDErhs2d(sol,t):\n\n    num_nodes=int(np.ceil(len(sol)/2))\n\n    u=sol[0:num_nodes]\n    v=sol[num_nodes:]\n\n\n    u=np.reshape(u,(N_x,N_x))\n    v=np.reshape(v,(N_x,N_x))\n\n    f_u=np.zeros_like(u)\n    f_v=np.zeros_like(u)\n\n \n\n    for i in range(1,N_x-2):\n      for j in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-4*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-4*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n\n    i=0 \n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(-3*u[i,j]+u[i+1,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(-3*v[i,j]+v[i+1,j]+v[i,j+1]+v[i,j-1]) \n\n    i=N_x-1\n    for j in range(1,N_x-2):\n      f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i,j+1]+u[i,j-1]) \n      f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i,j+1]+v[i,j-1])   \n\n    j=0\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j+1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j+1]) \n\n    j =N_x-1\n    for i in range(1,N_x-2):\n        f_u[i,j]=1/dx**2*(u[i-1,j]-3*u[i,j]+u[i+1,j]+u[i,j-1]) \n        f_v[i,j]=d/dx**2*(v[i-1,j]-3*v[i,j]+v[i+1,j]+v[i,j-1])  \n\n    i=0\n    j=0\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j+1]) \n\n    i=0\n    j=N_x-1\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i+1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i+1,j]+v[i,j-1]) \n\n    i=N_x-1\n    j=0\n\n    f_u[i,j]=1/dx**2*(u[i-1,j]-2*u[i,j]+u[i,j+1]) \n    f_v[i,j]=d/dx**2*(v[i-1,j]-2*v[i,j]+v[i,j+1]) \n    \n    i=N_x-1\n    j=N_x-1\n\n\n    f_u[i,j]=1/dx**2*(-2*u[i,j]+u[i-1,j]+u[i,j-1]) \n    f_v[i,j]=d/dx**2*(-2*v[i,j]+v[i-1,j]+v[i,j-1]) \n\n\n    reaction_u=gamma*(a-u+(u**2)*v)\n    reaction_v=gamma*(b-(u**2)*v)\n\n    f_u=f_u+reaction_u\n    f_v=f_v+reaction_v\n\n\n\n    f= np.concatenate((np.ravel(f_u),np.ravel(f_v))) \n    return f  \n\nsol=odeint(ShcnackPDErhs2d,u_0,t)\n\nu_0=sol[0,0:N_x**2]\nv_0=sol[0,N_x**2:]\nu_0=np.reshape(u_0,(N_x,N_x))\nv_0=np.reshape(v_0,(N_x,N_x))\n\nu_m=sol[20,0:N_x**2]\nv_m=sol[20,N_x**2:]\nu_m=np.reshape(u_m,(N_x,N_x))\nv_m=np.reshape(v_m,(N_x,N_x))\n\nu=sol[-1,0:N_x**2]\nv=sol[-1,N_x**2:]\nu=np.reshape(u,(N_x,N_x))\nv=np.reshape(v,(N_x,N_x))\n\nfig, ax = plt.subplots(2,3)\nax[0,0].imshow(u_0)\nax[1,0].imshow(v_0)\nax[0,1].imshow(u_m)\nax[1,1].imshow(v_m)\nax[0,2].imshow(u)\nax[1,2].imshow(v)\n\n'''\nax[0].plot(x,u[0,:],'r')\nax[0].plot(x,u[16,:],'b')\nax[0].plot(x,u[32,:],'m')\nax[0].plot(x,u[48,:],'k')\nax[0].set_xlabel('$x$')\nax[0].set_ylabel('$u$')\n\nax[1].plot(x, v[0,:],'r--')\nax[1].plot(x, v[16,:],'b--')\nax[1].plot(x, v[32,:],'m--')\nax[1].plot(x, v[48,:],'k--')\nax[1].set_xlabel('$x$')\nax[1].set_ylabel('$v$')\n'''\n\nplt.xlabel('$x$')\nplt.show()\n\n\n\n\n\nFigure 6.3: DDI with Schnackenberg kinetics in 2D"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#general-conditions-for-diffusion-driven-instability",
    "href": "DiffusionDrivenInstability.html#general-conditions-for-diffusion-driven-instability",
    "title": "6  Diffusion driven instability",
    "section": "6.5 General conditions for diffusion-driven instability",
    "text": "6.5 General conditions for diffusion-driven instability\nLet \\(\\Omega \\subset R^n\\) be a domain with smooth (sufficiently regular) boundary \\(\\partial \\Omega\\), with outward unit normal \\({\\mathbf{n}}\\). Our general, non-dimensional reaction-diffusion system is then:\n\\[\n\\begin{aligned}\n&\\frac{\\partial u}{\\partial  t} = \\gamma\\, f(u,v)  +  \\nabla^2 u, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\\frac{\\partial v}{\\partial  t} = \\gamma\\, g(u,v)  + d \\nabla^2 v, \\qquad x\\in \\Omega, \\quad t&gt;0, \\\\\n&\n\\end{aligned}\n\\tag{6.2}\\]\ntogether with boundary and initial conditions \\[\n\\begin{aligned}\n\\nabla u \\cdot {\\mathbf{n} } = 0, \\qquad \\nabla v \\cdot {\\mathbf{n} } = 0, \\qquad x\\in \\partial \\Omega, \\quad t&gt;0, \\\\\nu(x,0)  = u_0(x), \\qquad  v(x,0)  = v_0(x), \\qquad x\\in \\Omega\\; .\n\\end{aligned}\n\\tag{6.3}\\]\nA spatially homogeneous steady-state of Equation 6.2 and Equation 6.3 satisfies \\[\nf(u,v) = 0 , \\qquad g(u,v) =0\n\\]\nand we denote it by \\((u_0, v_0)\\).\n\n6.5.1 Stability of spatially homogeneous steady states to spatially homogeneous perturbations\nBefore we consider the effect of diffusion in Equation 6.2 and Equation 6.3, we first explore the stability of the spatially homogeneous steady state.\nConsider the following perturbations to the steady state \\((u_0 , v_0)\\): \\[\nu(x,t) = u_0 + \\tilde u(t), \\quad  v(x,t) = v_0 + \\tilde v(t), \\qquad \\|\\tilde u(t) \\| \\ll 1, \\quad  \\|\\tilde v(t) \\| \\ll 1.\n\\]\nUpon substitution into Equation 6.2 \\[\n\\begin{aligned}\n\\frac{d\\tilde u}{d t} = \\gamma\\, f(u_0 + \\tilde u,v_0 + \\tilde v),  \\\\\n\\frac{d \\tilde v}{d  t} = \\gamma\\, g(u_0 + \\tilde u,v_0 + \\tilde v).\n\\end{aligned}\n\\tag{6.4}\\]\nTaylor expansion of \\(f\\) and \\(g\\) about \\((u_0, v_0)\\) yields the linearised system \\[\n\\begin{pmatrix}\n\\tilde u_t \\\\\n\\tilde v_t\n\\end{pmatrix}  = \\gamma J  \\begin{pmatrix}\n\\tilde u \\\\\n\\tilde v\n\\end{pmatrix},\n\\tag{6.5}\\]\nwhere \\[\nJ =J(u_0, v_0) =  \\begin{pmatrix}\nf_u & f_v  \\\\\ng_u & g_v\n\\end{pmatrix}_{(u_0 , v_0)} \\; .  \n\\]\nThe general solution of Equation 6.5 is\n\\[\n\\begin{pmatrix}\n\\tilde u(t) \\\\\n\\tilde v(t)\n\\end{pmatrix}   =  C_1 \\phi_1 e^{\\lambda_1 t} +  C_2 \\phi_2 e^{\\lambda_2 t},\n\\]\nwhere \\(C_1\\), \\(C_2\\) are arbitrary constants, \\(\\lambda_1, \\lambda_2\\) are the eigenvalues of \\(\\gamma J\\), i.e. solutions of the characteristic equation \\[\n\\det (\\gamma J - \\lambda I) = 0,\n\\]\nand \\(\\phi_1\\), \\(\\phi_2\\) are corresponding eigenvectors. It is easily seen that\n\\[\n\\lambda_{1,2} = \\frac \\gamma 2 \\left( \\textrm{tr} (J) \\pm \\sqrt{ \\textrm{tr}(J)^2 - 4 \\det(J)} \\right),\n\\]\nand thus a spatially homogeneous steady state \\((u_0, v_0)\\) is stable to spatially homogeneous perturbations if \\[\n{\\mathrm Re}( \\lambda_{1,2}) &lt;0,\n\\]\ni.e. if \\[\n\\begin{aligned}\n\\textrm{tr}(J) & = f_u + g_v &lt; 0, \\\\\n\\det(J) & = f_u g_v - f_v g_u &gt; 0.\n\\end{aligned}\n\\tag{6.6}\\]\nWe shall be interested only in such parameter values for which conditions Equation 6.6 are satisfied (i.e. the spatially homogeneous steady state is linearly stable in the absence of diffusion).\n\n\n6.5.2 Stability of spatially homogeneous steady states to spatially heterogeneous perturbations\nWe now consider perturbations about the spatially homogeneous steady state that are spatially dependent, i.e.  \\[\nu(x,t) = u_0 + \\tilde u(x,t), \\quad  v(x,t) = v_0 + \\tilde v(x,t), \\qquad \\|\\tilde u(x,t) \\| \\ll 1, \\quad  \\|\\tilde v(x,t) \\| \\ll 1.\n\\]\nUpon substitution in Equation 6.2 and Taylor expanding \\(f\\) and \\(g\\) about \\((u_0, v_0)\\) yields the linearised problem\n\\[\n\\begin{aligned}\n\\frac{\\partial \\tilde u(x,t)}{\\partial t} = \\gamma\\, \\left(f_u \\tilde u(x,t) + f_v \\tilde v(x,t)\\right) + \\nabla^2 \\tilde u(x,t)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{\\partial \\tilde v(x,t)}{\\partial   t} = \\gamma\\,  \\left(g_u  \\tilde u(x,t) + g_v \\tilde v(x,t)\\right) +d \\nabla^2 \\tilde v(x,t)  \\quad x\\in \\Omega,   t &gt;0,\n\\end{aligned}\n\\tag{6.7}\\]\nwith boundary conditions \\[\n\\begin{aligned}\n{\\mathbf{n}} \\cdot \\nabla \\tilde u (x,t) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla \\tilde v (x,t)  = 0, \\qquad   x\\in \\partial \\Omega, \\; t &gt;0.\n\\end{aligned}\n\\tag{6.8}\\]\nDefining \\[\nV(x,t) = \\begin{pmatrix}\n\\tilde u(x,t) \\\\\n\\tilde v(x,t)\n\\end{pmatrix}\n\\]\nwe rewrite Equation 6.7 as \\[\n\\frac{\\partial}{\\partial t}  V(x,t) = \\gamma J  V(x,t) + D \\nabla^2   V(x,t),\n\\]\nwhere\n\\[\nD =  \\begin{pmatrix}\n1 & 0 \\\\\n0 & d\n\\end{pmatrix}.\n\\]\nWe shall consider a separation of variables approach, i.e. \\[\nV(x,t) =\\begin{pmatrix}  \n\\bar u(t)  \\varphi_1(x)\n\\\\\n\\bar v(t)  \\varphi_2(x)\n\\end{pmatrix},\n\\]\nand obtain \\[\n\\begin{aligned}\n\\frac{d \\bar u(t)}{d t}\\varphi_1(x) = \\gamma\\, \\left(f_u \\bar u(t) \\varphi_1(x) + f_v \\bar v(t) \\varphi_2(x)\\right) +\\bar u(t)  \\nabla^2 \\varphi_1(x)  , \\quad x\\in \\Omega, \\;  t &gt;0, \\\\\n\\frac{d \\bar v(t)}{d t}\\varphi_2(x) = \\gamma\\,  \\left(g_u  \\bar u(t) \\varphi_1(x) + g_v \\bar v(t) \\varphi_2(x)\\right) +  d \\bar v(t) \\nabla^2  \\varphi_2(x)  ,  \\quad x\\in \\Omega, \\;  t &gt;0,  \\\\\n\\end{aligned}\n\\tag{6.9}\\]\nwith boundary conditions \\[\n\\begin{aligned}\n{\\mathbf{n}} \\cdot \\nabla \\varphi_1(x) = 0, \\qquad {\\mathbf{n}} \\cdot \\nabla\\varphi_2 (x) = 0, \\qquad   x\\in   \\partial \\Omega, \\; t &gt;0.\n\\end{aligned}\n\\tag{6.10}\\]\nIt is assumed that \\[\n\\bar u(t)\\, / \\hspace{-0.35 cm}\\equiv 0 \\quad \\textrm{and} \\quad  \\bar v(t)\\, / \\hspace{-0.35 cm}\\equiv 0\n\\] for \\(t&gt;0\\).\n\nLemma 6.1 Consider the spatial eigenvalue problem for the Laplacian \\(\\nabla^2\\) with zero-Neumann boundary conditions, i.e.\n\\[\n\\begin{aligned}\n\\nabla^2 \\psi(x) = -k^2 \\psi(x), \\qquad x \\in \\Omega,  \\\\\n{\\mathbf{n}} \\cdot \\nabla \\psi(x) = 0, \\qquad x\\in \\partial \\Omega.\n\\end{aligned}\n\\tag{6.11}\\]\nFor a bounded domain \\(\\Omega\\) there exists a discrete set of eigenvalues \\[\n0 \\leq k^2_1&lt; k_2^2\\leq k_3^2\\leq \\ldots \\leq k_j^2\\leq \\ldots,\n\\]\nwith \\[\nj \\in \\mathbb N, \\quad  \\textrm{and} \\quad k_j^2 \\to \\infty \\quad \\textrm{as}  \\quad j \\to \\infty.\n\\]\nMoreover, the eigenfunctions \\(\\{\\psi_k(x) \\}\\) form an orthogonal set of basis functions of the corresponding functional space (i.e. \\(L^2(\\Omega)\\), \\(H^1(\\Omega)\\)).\n\nThus we can look for the spatial component of the solution of Equation 6.9 as follows: \\[\n\\varphi(x) = \\begin{pmatrix}  \n\\varphi_1(x) \\\\\n\\varphi_2(x)\n\\end{pmatrix} = \\sum_k C_k \\psi_k(x), \\qquad C_k =  \\begin{pmatrix}  C_k^1 \\\\ C_k^2 \\end{pmatrix} \\in \\mathbb R^2 \\;\n\\]\nand \\[\n\\begin{aligned}\nV(x,t) =\\sum_k \\hat V_k(t) \\psi_k(x), \\qquad \\textrm{ where}\n\\quad \\hat V_k(t)=\n\\begin{pmatrix}  \nC_k^1 \\; \\bar u(t)\n\\\\\nC_k^2 \\; \\bar v(t)\n\\end{pmatrix}.\n\\end{aligned}\n\\tag{6.12}\\]\nSince \\[\n\\nabla^2 \\psi_k(x) = - k^2 \\psi_k(x)\n\\]\nwe obtain\n\\[\nD \\nabla^2  V(x,t) = D \\nabla^2 \\left[ \\sum_k \\hat V_k(t) \\psi_k(x) \\right]   = \\sum_k D \\hat V_k(t) \\nabla^2 \\psi_k(x)=\n- \\sum_k k^2 D \\hat V_k(t)  \\psi_k(x).\n\\]\nHence \\[\n\\sum_k \\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n  \\sum_k \\gamma J \\hat V_k(t) \\psi_k(x) -  \\sum_k k^2  D \\hat V_k(t) \\psi_k(x).\n\\]\nSince \\(\\{\\psi_k(x) \\}\\) is a orthogonal basis we obtain that\n\\[\n\\frac{d}{d t}  \\hat V_k(t) \\psi_k(x)  =\n   \\gamma J  \\hat V_k(t) \\psi_k(x) -  k^2  D \\hat V_k(t) \\psi_k(x),\n\\]\nfor each \\(k\\). Finally, since \\[\n\\psi_k(x)\\;  /\\hspace{-0.35 cm }\\equiv 0\n\\]\nin \\(\\Omega\\) this implies for each \\(k\\) a system of ODEs:\n\\[\n\\begin{aligned}\n\\frac{d}{d t}  \\hat V_k(t)   &=   \\left(\\gamma J  -  k^2  D\\right) \\hat V_k(t) &= \\tilde J\\hat V_k(t) ,\n\\end{aligned}\n\\tag{6.13}\\]\nwhere \\(\\tilde J\\) is the “modified” Jacobian:\n\\[\n\\tilde{J} =  \\begin{pmatrix}\n\\gamma f_u - k^2 & \\gamma f_v \\\\\n\\gamma g_u & \\gamma g_v - d k^2\n\\end{pmatrix}.\n\\]\nNow solutions of Equation 6.13 are of the form \\[\n\\hat V_k(t) = e^{\\lambda t} P_k\n\\]\nwith \\(P_k \\in \\mathbb R^2\\), where, since \\(P_k\\neq 0\\) (looking for nontrivial solutions), we find that \\(\\lambda\\) are the eigenvalues of \\(\\tilde J\\) , i.e. solutions of the characteristic equation \\[\n\\det(\\tilde J - \\lambda I) = \\det ( \\gamma J - k^2 D - \\lambda I) =0.\n\\tag{6.14}\\]\nEvaluating the above determinant, we arrive at the equation: \\[\n\\lambda^2 + [ k^2 (1 + d) - \\gamma (f_u + g_v) ] \\lambda + h(k^2) = 0,\n\\tag{6.15}\\]\nwhere \\[\nh(k^2) = dk^4 - \\gamma (df_u + g_v) k^2 + \\gamma^2 | J | .\n\\tag{6.16}\\]\nNOTE: From Equation 6.14, Equation 6.15 we can recover the characteristic equation for the spatially homogeneous perturbation when \\(k=0\\), i.e.  \\[\n\\tilde J \\Big|_{k=0} = ( \\gamma J - k^2 D )\\Big|_{k=0} = \\gamma J.\n\\]\nThus the steady state \\((u_0, v_0)\\) is unstable to spatially heterogeneous perturbations iff \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\textrm{and/or} \\quad {\\mathrm Re}(\\lambda_2) &gt;0,\n\\]\nwhere \\(\\lambda_{1,2}\\) are solutions of Equation 6.14, Equation 6.15.\nNow for \\[\n{\\mathrm Re}(\\lambda_1) &gt; 0 \\quad \\textrm{and/or } \\quad {\\mathrm Re}(\\lambda_2) &gt;0\n\\]\nto be satisfied we require \\[\n\\textrm{tr}(\\tilde J) &gt; 0 \\quad \\textrm{ or } \\quad \\det(\\tilde J) &lt;0.\n\\]\nConsider first \\({\\mathrm tr} (\\tilde{J})\\). We have \\[\n\\textrm{tr}(\\tilde J) = \\gamma ( f_u+ g_v) - k^2(1+d) &lt; 0, \\hspace{4 cm}  \n\\]\nsince \\(\\gamma &gt; 0\\) and \\[\nf_u+ g_v &lt; 0\n\\]\nby the stability condition for the spatially homogeneous perturbation Equation 6.6. Thus instability to the spatially heterogeneous perturbation can only occur if \\[\n\\det(\\tilde J) &lt; 0\n\\]\nand so we require: \\[\n\\det(\\tilde J) = h(k^2) = dk^4  - \\gamma ( d\\,  f_u + g_v) k^2 + \\gamma^2 \\det(J) &lt; 0.\n\\]\nFrom the spatially homogeneous stability conditions Equation 6.6 we have \\(\\det(J) &gt;0\\). Thus \\(h(k^2)&lt;0\\) is possible only if \\[\nd f_u + g_v &gt;0.\n\\tag{6.17}\\]\nHowever, once again, due to Equation 6.6, we have \\(f_u+ g_v &lt;0\\), and so we can conclude that \\(d\\neq 1\\) and \\(f_u\\) and \\(g_v\\) must have opposite signs.\nCondition Equation 6.17 is necessary but not sufficient to ensure \\(h(k^2) &lt;0\\). In order to guarantee that \\(h(k^2) &lt; 0\\), the minimum value \\(h_{min}\\) must be negative. Differentiating Equation 6.16 w.r.t. \\(k^2\\), we find that:\n\\[\nk^2_{m} = \\gamma \\frac{d f_u + g_v}{2d} \\;\\; \\Rightarrow \\;\\; h_{min} = \\gamma^2 \\left[ | J | - \\frac{(df_u + g_v)^2}{4d} \\right].\n\\tag{6.18}\\]\nThus the condition that \\(h(k^2) &lt; 0\\) for some \\(k^2\\) is:\n\\[\n\\frac{(df_u + g_v)^2}{4d} &gt; |J|.\n\\]\nThe transition from stability to instability i.e. bifurcation, occurs when \\(h_{min} = 0\\). From Equation 6.18, this means at bifurcation we have \\[\n|J| = \\frac{(df_u + g_v)^2}{4d}.\n\\tag{6.19}\\]\nFor a fixed set of kinetics parameters, this means that we have a critical diffusion coefficient \\(d_c(&gt;1)\\), which, after re-arranging Equation 6.19, is the appropriate root of\n\\[\nq(d_c) = d^2_c f_u^2 + 2( 2 f_v g_u - f_u g_v) d_c + g_v^2 =0.\n\\tag{6.20}\\]\nFinally, we note that using Equation 6.18, Equation 6.19, the critical wave number can be written: \\[\nk_c^2 =\\gamma  \\frac{( d_c f_u + g_v)} { 2 d_c} = \\gamma \\left[ \\frac {|J|}{d_c} \\right]^{1/2} = \\gamma \\left[ \\frac{f_u g_v - f_v g_u}{d_c} \\right]^{1/2}.\n\\tag{6.21}\\]\nFigure 6.5 (a) shows a schematic diagram of the (quadratic) function \\(h(k^2)\\) for three different values of the diffusion coefficient \\(d\\):\n\n\\(d &lt; d_c, \\; h(k^2) &gt; 0\\), and there is no pattern;\n\\(d = d_c, \\; h_{min} = 0\\), critical case;\n\\(d &gt; d_c, \\; h(k^2) &lt; 0\\), and there is pattern.\n\nHence we can see from Equation 6.15 that whenever \\(h(k^2) &lt; 0\\) the curve \\(\\lambda(k^2)\\) is positive for the same range of wavenumbers that make \\(h(k^2)\\) negative. The range of unstable wavenumbers \\[\nk^2_1 &lt; k^2 &lt; k^2_2\n\\]\ncan be found from the roots of Equation 6.16, \\(h(k^2) = 0\\):\n\\[\n\\begin{aligned}\nk^2_1 &= \\gamma \\frac{(df_u + g_v) - \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2} }{2d} &lt; k^2  \\\\\n&&lt; \\gamma \\frac{(df_u + g_v) +  \\left\\{ (df_u + g_v)^2 -4d |J| \\right\\}^{1/2}}{2d} = k^2_2\n\\end{aligned}\n\\tag{6.22}\\]\nFigure 6.5 (b) shows a schematic diagram of \\({\\mathrm Re}\\lambda (k^2)\\) for three different values of the diffusion coefficient \\(d\\):\n\n$d &lt; d_c, ; \\({\\mathrm Re}\\lambda (k^2)\\) &lt; 0, k^2 $, and there is no pattern;\n\\(d = d_c, \\; k^2_c = 0\\), critical case;\n\nThe expression \\(\\lambda = \\lambda (k^2)\\) is known as the dispersion relation and the plot of \\({\\mathrm Re} \\lambda\\) against \\(k^2\\) is known as the dispersion curve.\nFrom the previous analysis, within the unstable range of wavenumbers \\((k^2_1 , k^2_2)\\), \\({\\mathrm Re}\\lambda (k^2) &gt; 0\\) has a maximum value at wavenumber \\(k^2_m\\) given by Equation 6.18 when \\(d &gt; d_c\\). This implies that there is a fastest growing mode in the solution Equation 6.12 of our linearised system Equation 6.9.\nRecalling Equation 6.12,\n\\[\nV(x,t) = \\sum_k C_k e^{\\lambda(k^2) t} \\, \\psi_k(x),\n\\]\nand noting the above analysis, this implies that as \\(t\\to \\infty\\) the dominant contributions in the above sum are those for which \\({\\mathrm Re} \\lambda(k^2) &gt; 0\\), since all other modes will tend to zero exponentially fast as \\(t\\to \\infty\\). Thus, for large \\(t\\), the solution is effectively given by: \\[\nV(x,t) \\approx \\sum_{k_{1}}^{k_2} C_k e^{\\lambda(k^2) t} \\, \\psi_k(x) \\; .\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# genera\nk_sq_max=35\nk_sq_min_plot=6.4\nk_sq=np.linspace(0,k_sq_max,100)\n\n\n# Some made up numbers for this example\ngamma=100.0\nd_1=3.0\nd_2=6.0\n\nf_u=0.4\ng_v=-0.5\nJ=0.1 # positive determinant\n\n\n# Compute h\ndef Computeh(k_sq,d):\n  term1=d*f_u+g_v\n\n  h=d*k_sq**2-gamma*(term1)*k_sq+ gamma**2*J\n  return h\n\ndef SolveReLambda(k_sq,d):\n   # a lam^2 + b * lam +c\n    a=1\n    b= k_sq*(1+d)-gamma*(f_u+g_v)\n    c= Computeh(k_sq,d)\n    lambda_m= (-b-np.sqrt(b**2-4*a*c))/(2*a)\n    lambda_p= (-b+np.sqrt(b**2-4*a*c))//(2*a)\n    return lambda_m,lambda_p\n\ndef TestDDIconditions(d):\n\n    cond_1=f_u+g_v\n    cond_2 = J\n    cond_3 = d*f_u+g_v\n    cond_4 = (d*f_u+g_v)**2-4*d*J\n\n    cond_true=np.zeros((4,1),dtype=bool)\n    cond_true[0]=(cond_1&lt;0) \n    cond_true[1]= (cond_2&gt;0) \n    cond_true[2]= (cond_3&gt;0)\n    cond_true[3]=(cond_4&lt;0)\n\n\n    return cond_true\n\nh_1=Computeh(k_sq,d_1)\nh_2=Computeh(k_sq,d_2)\n\nl_1_m, l_1_p = SolveReLambda(k_sq,d_1)\nl_2_m, l_2_p = SolveReLambda(k_sq,d_2)\n\nconditions_satisfied1=TestDDIconditions(d_1)\nconditions_satisfied2=TestDDIconditions(d_2)\n\n\nfig, ax=plt.subplots()\nax.plot(k_sq,h_1,'r',k_sq,h_2,'k')\nax.set_xlabel('$k^2$')\nax.set_ylabel('$h$')\nax.legend(['d='+str(d_1),'d='+str(d_2)])\nax.set_ylim([-1000,4000])\nax.fill_betweenx ([-1000, 4000], [k_sq_min_plot], [25],alpha=0.2)\nax.set_xlim([0,k_sq_max])\n\nplt.show()\n\nfig, ax=plt.subplots()\nax.plot(k_sq,np.real(l_1_m),'r',k_sq,np.real(l_2_m),'k')\nax.plot(k_sq,np.real(l_1_p),'r--',k_sq,np.real(l_2_p),'k--')\n\nplt.grid()\nax.set_xlabel('$k^2$')\nax.set_ylabel('$\\Re\\{\\lambda\\}$')\nax.set_ylim([-100,25])\nax.fill_betweenx ([-100, 5], [k_sq_min_plot], [25],alpha=0.2)\nax.set_xlim([0,k_sq_max])\n\nax.legend(['d='+str(d_1),'d='+str(d_2)])\nplt.show()\n\n\n\n\n\nFigure 6.4: A plot of \\(h(k^2)\\) plotted against \\(k^2\\). Shaded region denotes unstable wave numbers in case of largets \\(d\\).\n\n\n\n\n\n\n\nFigure 6.5: The real part of the eigenvalue plotted against \\(k^2\\).\n\n\n\n\nNOTE\nAll the previous calculations concern a linear stability analysis carried out about a spatially homogeneous steady state of the system Equation 6.2. This linear theory indicates that for \\(d &gt; d_c\\) there exists a finite number of linearly unstable spatial eigenfunctions which grow exponentially as \\(t \\to \\infty\\). However, this linear theory holds only when we are close to the steady state i.e. it only holds for small perturbations. In the full nonlinear system the exponentially growing (unbounded) modes will eventually be bounded by the nonlinear terms and so bounded, stable spatial patterns characterised by the corresponding wavenumbers will be formed.\nSummary\nWe have obtained conditions for the generation of spatial patterns via systems of reaction-diffusion equations of the general form Equation 6.2. Such systems involve two chemicals or morphogens reacting and diffusing together to generate a chemical pre-pattern that underlies a subsequent cellular pattern. The four conditions are as follows:\n\\[\n\\begin{aligned}\nf_u + g_v &&lt; 0, \\\\\nf_u g_v - f_v g_u &&gt; 0, \\\\\nd f_u + g_v &&gt; 0, \\\\\n(d f_u + g_v)^2 - 4d (f_u g_v - f_v g_u)^2 &&lt; 0 , \\nonumber\n\\end{aligned}\n\\tag{6.23}\\]\nwith all partial derivatives being evaluated at the spatially homogeneous steady state \\((u_0 , v_0)\\).\nFrom the first and third conditions, \\(d \\neq 1\\) and \\(f_u\\) and \\(g_v\\) must be of different signs. For each of the reaction kinetics mentioned here (Schnakenberg, Gierer-Meinhardt, Thomas), we have that \\(f_u &gt; 0, g_v &lt; 0\\) and so this implies that \\(d &gt; 1\\).\nIf the conditions Equation 6.23 are satisfied, then there is a range of unstable wavenumbers given by Equation 6.22 which give rise to a spatial pattern. The spatial patterns which initially grow are those spatial eigenfunctions \\(\\psi_k(x)\\) whose wavenumbers \\(k\\) are such that \\(k_1 &lt; k &lt; k_2\\).\nIn most biological systems, the kinetic parameters and diffusion coefficients are fixed. This means that the only variable parameter in the system is \\(\\gamma\\) which as we have seen is related to the size of the domain under consideration. This has implications when considering patterns on finite domains, as will be seen in the next section."
  },
  {
    "objectID": "DiffusionDrivenInstability.html#exercises",
    "href": "DiffusionDrivenInstability.html#exercises",
    "title": "6  Diffusion driven instability",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\nDemonstrate that the derived results are consistent with numerical solutions. Some predictions to test:\n\nNo patterning when diffusion coefficients are equal\nHow does spatial pattern formation change as you try values of parameters \\(a\\) and \\(b\\)?\nCan you correlate the observation of pattern to the conditions for DDI being satisfied?\nwhat about different kinetics (e.g. Gierer-Meinhardt, Thomas models)?"
  },
  {
    "objectID": "DiffusionDrivenInstability.html#references",
    "href": "DiffusionDrivenInstability.html#references",
    "title": "6  Diffusion driven instability",
    "section": "6.7 References",
    "text": "6.7 References\n\n\n\n\n“A Theory of Biological Pattern Formation.” 1972. Kybernetik 12: 30–39.\n\n\nMurray, James D, and George F Oster. 1984. “Generation of Biological Pattern and Form.” Mathematical Medicine and Biology: A Journal of the IMA 1 (1): 51–75.\n\n\nTuring, Alan Mathison. 1990. “The Chemical Basis of Morphogenesis.” Bulletin of Mathematical Biology 52: 153–97."
  },
  {
    "objectID": "SIR_PDE.html#spatial-spread-of-rabies-among-foxes",
    "href": "SIR_PDE.html#spatial-spread-of-rabies-among-foxes",
    "title": "7  Infectious disease",
    "section": "7.2 Spatial spread of rabies among foxes",
    "text": "7.2 Spatial spread of rabies among foxes\nSpread of rabies is due primary to the migration of infected foxes. We assume the heathy foxes are territorial and do not travel very far, whereas rabid foxes wander over large distances.\nThus we assume that \\(D_S \\ll D_I\\) and \\(d= { D_S}/{D_I} \\approx 0\\).\n\\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  SI \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} = SI - \\mu I+  \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = 1, \\qquad I(0,x) = \\frac{I_0}{\\bar S_0},  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.8}\\]\nWe shall look for travelling wave solutions of Equation 7.8: travelling wave front for \\(S\\) and travelling wave pulse for \\(I\\). Considering \\[\nS(t,x) = s(z), \\quad I(t,x) = i(z), \\quad z = x - v t, \\quad v &gt;0\n\\] and obtain following ODEs for \\(s\\) and \\(i\\)\n\\[\n\\begin{aligned}\n&  v s^\\prime = i s  \\; , \\\\\n& i^{\\prime \\prime} + v i^\\prime + i s - \\mu i= 0\\;\n\\end{aligned}\n\\tag{7.9}\\] and corresponding boundary conditions\n\\[\n\\begin{aligned}\ns(z) \\to 1 \\qquad  z\\to + \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to + \\infty\\; ,\\\\\ns(z) \\to \\sigma \\qquad  z\\to - \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to - \\infty\\; ,\\\\\ns^\\prime(z) \\to 0\\qquad  z\\to \\pm \\infty, \\quad \\qquad i^\\prime(z) \\to 0 \\qquad z \\to \\pm \\infty \\; ,\n\\end{aligned}\n\\tag{7.10}\\] where \\(0 \\leq \\sigma &lt;1\\).\nAs before, the steady states of Equation 7.9 are given by \\[\nis =0 , \\quad i ( s- \\mu) = 0  \\quad \\Longrightarrow \\quad  i=0, \\quad s = \\text{const} \\; .\n\\]\nConsidering boundary conditions Equation 7.10 we obtain two steady states \\[\n(s_0, i_0) = ( 1, 0), \\qquad (s_0, i_0) = (\\sigma, 0) \\; .\n\\]\nLinearising equations Equation 7.9 about the steady state \\((1,0)\\) and requiring that \\(i\\) is nonnegative we obtain, as for Equation 7.2, the necessary conditions for existence of travelling wave solutions satisfying Equation 7.9 and Equation 7.10 : \\[\nv \\geq 2 \\sqrt{ 1- \\mu} \\, \\quad \\text{ and } \\quad 0 \\leq \\mu &lt; 1\\; .  \n\\]\nWe can determine the relation between density of susceptibles left behind the infection pulse and the model parameters.\nUsing first equation in Equation 7.9 in the second implies \\[\ni^{\\prime \\prime} + v i^\\prime + v s^\\prime  - \\mu i= 0\\; .\n\\tag{7.11}\\] Integrating with respect to \\(z\\) yields\n\\[\ni^{\\prime } + v i + v s  - \\mu \\int i\\, dz = K= const\\; .\n\\tag{7.12}\\]\nConsider now ageing the first equation in Equation 7.9 \\[\ni= v \\frac {s^\\prime} s, \\quad \\quad s \\neq 0 \\;\n\\]\nand obtain from Equation 7.12 \\[\ni^{\\prime } + v i + v s  - v  \\mu \\int   \\frac {s^\\prime} s\\, dz = K= const\\; .\n\\] or \\[\ni^{\\prime } + v i + v s  - v  \\mu \\ln(s) = K\\; .\n\\tag{7.13}\\]\nUsing now in Equation 7.13 boundary conditions as \\(z \\to + \\infty\\), from Equation 7.10, we can determine constant \\(K\\):\n\\[\nv    = K\\; .\n\\] Thus we have \\[\ni^{\\prime } + v i + v( s  - \\mu \\ln(s) -1)= 0\\; .\n\\tag{7.14}\\] Using now in Equation 7.14 boundary conditions as \\(z \\to - \\infty\\), see Equation 7.10, gives\n\\[\nv( \\sigma - \\mu \\ln(\\sigma) -1)= 0\\; .\n\\] and \\[\n\\frac{ \\sigma- 1}{\\ln(\\sigma)} = \\mu \\; .\n\\tag{7.15}\\] We obtain that the number of susceptibles is defined independently of the wave speed and the smaller \\(\\mu\\) corresponds to smaller \\(\\sigma\\) ( i.e. fever susceptibles survive infection wave). Thus \\(\\mu\\) measures how sever the epidemic is.\nConsidering the critical value for \\(\\mu =1\\), which in dimensional terms means \\[\n\\frac a { r S_0} = 1,\n\\] we can conclude that there exists no wave of infection\n\nif \\(S_0\\) is too low - density of foxes is too low in order to spread the disease,\n\nor if removal rate is too large - high death rate and the infection is too virulent\nor if infection rate \\(r\\) is too small - the disease is too"
  },
  {
    "objectID": "NumericalMethods.html#python-libraries",
    "href": "NumericalMethods.html#python-libraries",
    "title": "8  Numerical methods in Python",
    "section": "8.1 Python libraries",
    "text": "8.1 Python libraries\n\nmatplotlib\nnumpp\nscipy"
  },
  {
    "objectID": "NumericalMethods.html#single-pdes",
    "href": "NumericalMethods.html#single-pdes",
    "title": "8  Numerical methods in Python",
    "section": "8.2 Single PDEs",
    "text": "8.2 Single PDEs\n\n8.2.1 MOL\n\n\n8.2.2 Spatial discretisation\n\n\n8.2.3 odeint\n\n\n8.2.4 implementing boundary conditions\n\n\n8.2.5 Identifying parameters"
  },
  {
    "objectID": "NumericalMethods.html#systems-of-pdes",
    "href": "NumericalMethods.html#systems-of-pdes",
    "title": "8  Numerical methods in Python",
    "section": "8.3 Systems of PDEs",
    "text": "8.3 Systems of PDEs"
  },
  {
    "objectID": "linearstablityanalysis.html",
    "href": "linearstablityanalysis.html",
    "title": "9  Linear stability analysis of a system of nonlinear ODES",
    "section": "",
    "text": "Consider a system of ODEs\n\\[\\begin{equation*}\n\\frac{du}{dt} = f(u) \\quad \\text{ with } \\quad u \\in \\mathbb R^m\\quad  \\text{ and }\\quad  t \\in \\mathbb R.\n\\end{equation*}\\]\nAs an example consider \\(m=2\\): \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{du_1}{dt} =F(u_1, u_2) ,\\\\\n\\dfrac{du_2}{dt} =G(u_1, u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.1}\\]\n\\((u_1, u_2) = (u^\\ast_1, u^\\ast_2)\\) is the steady state of the system Equation 9.1, i.e. \\[\n\\dfrac{du_1}{dt} = 0\n\\] and \\[\n\\dfrac{du_2}{dt} = 0\n\\].\nTo determine the behaviour of the solution near a steady state we consider \\[\nu_1(t) = u^\\ast_1 + \\bar u_1(t), \\quad  u_2(t) = u^\\ast_2 + \\bar u_2(t)\n\\] \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d(u^\\ast_1+ \\bar u_1)}{dt} =F(u^\\ast_1+ u_1, u^\\ast_2+ \\bar u_2) ,\\\\\n\\dfrac{d(u^\\ast_2+\\bar u_2)}{dt} =G(u^\\ast_1+u_1,u^\\ast_2+\\bar u_2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.2}\\]\nThen using the fact that \\((u^\\ast_1, u^\\ast_2)\\) is a steady state and applying Taylor series expansion about \\(( u^\\ast_1, u^\\ast_2)\\) and assuming that\n\\[\n\\sup_{t}|\\bar u_1(t)| \\ll 1, \\sup_{t}|\\bar u_2(t)|\\ll 1\n\\] (small perturbations of the steady state) we have \\[\n\\begin{aligned}\n\\begin{cases}\n\\dfrac{d  \\bar u_1}{dt} =F(u^\\ast_1, u^\\ast_2) +\\dfrac{\\partial F}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial F}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\, \\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2) ,\\\\\n\\dfrac{d \\bar u_2}{dt} =G(u^\\ast_1,u^\\ast_2)+ \\dfrac{\\partial G}{\\partial u_1}(u^\\ast_1, u^\\ast_2) \\,   \\bar u_1\n+\\dfrac{\\partial G}{\\partial u_2}(u^\\ast_1, u^\\ast_2) \\,\\bar u_2 + O(|\\bar u_1|^2, |\\bar u_2|^2)\n\\end{cases}\n\\end{aligned}\n\\tag{9.3}\\]\nThus since \\((u^\\ast_1, u^\\ast_2)\\) is a steady state, i.e. \\(F(u^\\ast_1, u^\\ast_2) =0\\) and \\(G(u^\\ast_1, u^\\ast_2) =0\\) (ignoring negligibly small higher order terms) we obtain system of linearised equations \\[\n\\begin{aligned}\n\\begin{pmatrix}\n\\dfrac{d  \\bar u_1}{dt} \\\\\n\\dfrac{d \\bar u_2}{dt}\n\\end{pmatrix} = J( u^\\ast_1, u^\\ast_2) \\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\end{aligned}\n\\tag{9.4}\\] where the Jacobian matrix \\(J(u^\\ast_1, u^\\ast_2)\\) is defined as \\[\nJ( u^\\ast_1, u^\\ast_2) = \\begin{pmatrix}\n\\dfrac{\\partial F(u^\\ast_1, u^\\ast_2) }{\\partial u_1}\\; \\; & \\dfrac{\\partial F(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\\\\\n\\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_1} & \\dfrac{\\partial G(u^\\ast_1, u^\\ast_2)}{\\partial u_2}\n\\end{pmatrix}\n\\] Therefore the behaviour of the nonlinear system Equation 9.1 near the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by solutions of system of linear ODEs Equation 9.4.\nSince Equation 9.4 is linear we can write the general solution of (eqsystem_ode14?) \\[\\begin{equation}\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix} = e^{\\lambda_1 t} \\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix}   +\ne^{\\lambda_2 t} \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\end{equation}\\] where \\(\\lambda_1\\) and \\(\\lambda_2\\) are eigenvalues of Jacobian matrix \\(J( u^\\ast_1, u^\\ast_2)\\) and \\[\n\\phi=\\begin{pmatrix} \\phi_1 \\\\\n\\phi_2\n\\end{pmatrix} \\quad \\textrm{and} \\quad  \\psi= \\begin{pmatrix} \\psi_1 \\\\\n\\psi_2\n\\end{pmatrix}\n\\] are corresponding eigenvectors.\nDenote \\[\\bar u=\n\\begin{pmatrix} \\bar u_1 \\\\\n\\bar u_2\n\\end{pmatrix}\n\\].\nIf both \\(\\lambda_{1,2} \\neq 0\\) then the stability of the steady state \\((u^\\ast_1, u^\\ast_2)\\) is determined by the real part of the eigenvalues \\(\\lambda_{1,2}\\).\n\nIf either \\(\\mathcal Re (\\lambda_1)&gt;0\\) or \\(\\mathcal Re (\\lambda_2)&gt;0\\) then\n\\(|\\bar u(t)| \\to +\\infty\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is unstable.\nIf \\(\\mathcal Re (\\lambda_1)&lt;0\\) and \\(\\mathcal Re (\\lambda_2)&lt;0\\) then\n\\(|\\bar u(t)| \\to 0\\) as \\(t \\to + \\infty\\) and \\((u^\\ast_1, u^\\ast_2)\\) is stable.\nIf \\(\\lambda_1=0\\) or \\(\\lambda_2=0\\) we have to consider higher order terms.\n\nDenote \\(\\beta = \\textrm{tr} (J( u^\\ast_1, u^\\ast_2))\\) and \\(\\gamma= \\det(J( u^\\ast_1, u^\\ast_2))\\). Then the characteristic (eigenvalue) equation for \\(J( u^\\ast_1, u^\\ast_2)\\) is \\[\n\\lambda^2 - \\beta \\lambda + \\gamma = 0 \\; , \\quad  \\lambda_{1,2} = \\frac{ \\beta \\pm \\sqrt{ \\beta^2 - 4 \\gamma}} 2.\n\\] Then\n\nIf \\(\\gamma &lt;0\\) we have two real eigenvalues with different signs, i.e. \\(\\lambda_1 &lt; 0 &lt; \\lambda_2\\). Thus \\((u^\\ast_1, u^\\ast_2)\\) is a saddle.\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 \\geq 4\\gamma\\) we have two real eigenvalues with the same sign. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a node.\n\nif \\(\\beta &gt;0\\) then \\(\\lambda_2 &gt; \\lambda_1 &gt;0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable node.\nif \\(\\beta &lt;0\\) then \\(\\lambda_1 &lt; \\lambda_2 &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable node.\n\nIf \\(\\gamma &gt;0\\) and \\(\\beta^2 &lt; 4\\gamma\\) we have two complex conjugate eigenvalues. Thus \\((u^\\ast_1, u^\\ast_2)\\) is a focus (spiral).\n\nif \\(\\beta &gt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &gt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is an unstable focus\nif \\(\\beta &lt;0\\) then \\(\\mathcal Re(\\lambda_{1,2}) &lt; 0\\) and \\((u^\\ast_1, u^\\ast_2)\\) is a stable focus.\nIf \\(\\beta =0\\) then for linear system we have a centre, but in general we have no information on the behaviour of the nonlinear system near the steady state \\((u^\\ast_1, u^\\ast_2)\\).\n\n\n** Insert figure phase plane **"
  },
  {
    "objectID": "SIR_PDE.html#generalising-the-sir-model",
    "href": "SIR_PDE.html#generalising-the-sir-model",
    "title": "7  Infectious disease",
    "section": "7.1 Generalising the SIR model",
    "text": "7.1 Generalising the SIR model\nAssumptions\n\nTotal population is constant: the duration of the epidemic is short compared to the lifetime of its hosts, so we can neglect birth and disease-unrelated death\nConsider a disease which, after recovery, confers immunity (and/or death if lethal)\nSimple diffusion for spatial distribution of population\n\nConsider consider three categories of population\n\n\\(S\\) – susceptibles - can be infected\n\\(I\\) – invectives - have the disease and can transmit to susceptibles\n\\(R\\) – recovered (removed) - have had the disease and are no longer infective.\n\nProgress through the disease \\[\nS \\longrightarrow I \\longrightarrow R\n\\]\nModel assumptions * The gain in the invectives class is at the rate proportional to the number of invectives \\(I\\) and susceptibles \\(S\\), i.e. \\(r\\; I\\; S\\), ; \\(r&gt;0\\).\n\nThe susceptibles are lost at the same rate, i.r. \\(r\\; I\\; S\\)\nThe rate of removal of invectives to the recovered class \\(R\\) is proportional to the number of invectives, i.e. \\(a\\; I\\), ; \\(a&gt;0\\).\n\n\\(1/a\\) measures the time spent in the infectious state.\n\nThe incubation period is short enough to be negligible: susceptibles are directly infected after coming into contact with the disease (with invectives).\n\nThen a simple SIR model reads (in a long thin domain or in \\(3\\)-dim domain with solutions in a form of planar fronts) \\[\n\\begin{aligned}\n&\\frac{\\partial S}{\\partial t} = - r SI + D_S \\frac{ \\partial^2 S}{\\partial x^2}\\; ,  &\\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n&\\frac{\\partial I}{\\partial t} = r SI - a I+ D_I \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  &\\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n&\\frac{\\partial R}{\\partial t} = a I + D_R \\frac{ \\partial^2 R}{\\partial x^2} \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; \\\\\n&S(0,x) = S_0(x), \\qquad I(0,x) = I_0(x), \\quad R(0,x) = R_0(x),& \\qquad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.1}\\]\nwhere\n\n\\(a&gt;0\\) – removal or death rate\n\\(r&gt;0\\) – transmission or infection rate\n\\(D_S&gt;0\\), ; \\(D_I&gt;0\\), ; \\(D_R&gt;0\\) – diffusion coefficients\n\nWe assume that \\(S_0(x) \\geq 0\\), \\(I_0(x) \\geq 0\\), \\(R_0(x) \\geq 0\\) for \\(x \\in \\mathbb R\\) and obtain that solutions of Equation 7.1 are nonnegative, i.e.  \\[\nS(t,x) \\geq 0, \\quad I(t,x) \\geq 0, \\quad R(t,x) \\geq 0, \\quad  x\\in \\mathbb R, \\quad t &gt;0 \\; .\n\\]\nTo analyse the model Equation 7.1 it is sufficient to consider the first two equations, since \\(R\\) is completely determined by \\(I\\) and does not influence the dynamics of \\(S\\) and \\(I\\).\nConsidering the non-dimensionalisation \\[\nI^\\ast = \\frac I{\\bar S_0} , \\quad S^\\ast = \\frac S{\\bar S_0} ,  \\quad x^\\ast = \\left(\\frac{ r \\bar S_0}{D_I} \\right)^{1/2} x, \\quad t^\\ast = r \\bar S_0 t\n\\] we obtain ( after dropping \\(`\\ast'\\))\n\\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  SI + d \\frac{ \\partial^2 S}{\\partial x^2}\\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} = SI - \\mu I+  \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = \\frac{S_0(x)}{\\bar S_0}, \\qquad I(0,x) = \\frac{I_0(x)}{\\bar S_0},  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\] where \\(\\bar S_0\\) is a representative population density and \\(\\mu = a /{ r \\bar S_0}\\).\nWe would like to investigate the spatial spread of an epidemic wave of invectives into a uniform susceptibles population \\(S_0(x) =\\bar S_0\\). We would like to determine conditions for existence of an epidemic wave and propagation speed.\nWe shall assume first that \\(D_S= D_I\\), i.e. \\(d=1\\). Consider travelling wave solutions \\[\nS(t,x) = s(z), \\quad I(t,x) = i(z), \\quad z = x - v t, \\quad v &gt;0\n\\] and obtain following ODEs for \\(s\\) and \\(i\\) \\[\n\\begin{aligned}\ns^{\\prime \\prime} + v s^\\prime - i s = 0 \\; , \\\\\ni^{\\prime \\prime} + v i^\\prime + i s - \\mu i= 0\\; .\n\\end{aligned}\n\\tag{7.2}\\]\nWe would like to analyse the existence of a travelling wave from for \\(S\\) and travelling wave pulse for \\(I\\). We assume that the infection comes into susceptible population from the left.\nTherefore we consider the following boundary conditions for the travelling wave solutions\n\\[\n\\begin{aligned}\ns(z) \\to 1 \\qquad  z\\to + \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to + \\infty\\; ,\\\\\ns(z) \\to \\sigma \\qquad  z\\to - \\infty, \\quad \\qquad  i(z) \\to 0 \\qquad  z\\to - \\infty\\; ,\\\\\ns^\\prime(z) \\to 0\\qquad  z\\to \\pm \\infty, \\quad \\qquad i^\\prime(z) \\to 0 \\qquad z \\to \\pm \\infty \\; ,\n\\end{aligned}\n\\tag{7.3}\\] where \\(0 \\leq \\sigma &lt;1\\).\nThe steady states of Equation 7.2 are given by \\[\nis =0 , \\quad i ( s- \\mu) = 0  \\quad \\Longrightarrow \\quad \\ i=0, \\quad s = \\text{const}.\n\\] Considering boundary conditions Equation 7.3 we obtain two steady states \\[\n(s_0, i_0) = ( 1, 0), \\qquad (s_0, i_0) = (\\sigma, 0)\n\\] Hence we would like to have a heteroclinic connection between \\((\\sigma , 0)\\) and \\((1,0)\\).\nThe necessary condition for existence of travelling wave solutions satisfying Equation 7.2 and Equation 7.3 is\n\\[\nv \\geq 2 \\sqrt{ 1- \\mu} \\, \\quad \\text{ and } \\quad 0 \\leq \\mu &lt; 1\\; .  \n\\tag{7.4}\\]\nIn terms of original parameters we have \\[\n\\mu = \\frac a { r S_0} &lt; 1.\n\\] This is the necessary threshold conditions for the propagation of an epidemic wave pulse. The condition Equation 7.4 determine also the non-dimensionalised minimal wave speed \\[\nv^\\ast_{\\text{min}} = 2\\sqrt{ 1- \\mu}\n\\]\nIn dimensional terms we obtain \\[\nz^\\ast = x^\\ast - v^\\ast t^\\ast = \\left( \\frac { r S_0} {D_I} \\right)^{1/} x - v^\\ast r S_0 t  =\n\\left( \\frac { r S_0} {D_I} \\right)^{1/} ( x - v t) = \\left( \\frac { r S_0} {D_I} \\right)^{1/} z\n\\] and \\[\nv = \\sqrt{ r S_0 D_I} v^\\ast \\quad v_{\\text{min}} = 2  \\sqrt{ r S_0 D_I}\\sqrt{ 1- \\mu} =\n2  \\sqrt{ r S_0 D_I}\\sqrt{ 1- \\frac a{ r S_0} }\n\\]\nWe can analyse the behaviour of travelling wave solutions as \\(z \\to + \\infty\\).\nLinearised equation for the second equation in Equation 7.2 near \\(s=1\\), \\(i=0\\), i.e. as \\(z \\to + \\infty\\) reads \\[\ni^{\\prime \\prime} + v i^\\prime + i  - \\mu i = 0\\; .\n\\] Thus\n\\[\ni(z) \\sim \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.5}\\] We can also show that the travelling wave solution \\(s(z)\\) can not have a local maximum, since for \\(s^\\prime(z) = 0\\) first equation in Equation 7.2 implies \\[\ns^{\\prime \\prime}(z) = is &gt;0,\n\\] which implies a local minimum. So \\(s(z)\\) is monotone increasing.\nConsidering linearisation of the first equation in Equation 7.2 near \\(s=1\\), \\(i=0\\), i.e. as \\(z \\to + \\infty\\), we obtain with \\(s(z) = 1 - \\tilde s(z)\\) \\[\n\\tilde s^{\\prime \\prime} + v \\tilde s^{\\prime} - i = 0 \\; .\n\\] The using Equation 7.5 we can conclude that\n\\[\n\\tilde s(z) \\sim \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.6}\\] and\n\\[\ns(z) \\sim 1 - C \\exp \\left(\\frac 1 2 \\left[ - v \\pm \\sqrt{ v^2 - 4(1-\\mu)} \\right] z \\right) \\quad \\text{ as } z \\to + \\infty \\; .\n\\tag{7.7}\\]"
  },
  {
    "objectID": "SIR_PDE.html#generalisation-of-simple-sir-model",
    "href": "SIR_PDE.html#generalisation-of-simple-sir-model",
    "title": "7  Infectious disease",
    "section": "7.3 Generalisation of simple SIR model",
    "text": "7.3 Generalisation of simple SIR model\nWe developed a simple model for the passage of a wave of infection, however data of a spread of rabies in continental Europe looks quite different, i.e. comprises oscillations behind the wave front. It is likely that birth-death processes, not included in the simple model, impact dynamics of susceptibles and invectives.\nWe generalised the simple model by considering growth of susceptibles population in a logistic manner\n\\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  rSI + B S\\left( 1 - \\frac S{S_0} \\right) \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} =  r SI - a I+  D_I \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = S_0, \\qquad I(0,x) = I_0,  & \\quad x \\in \\mathbb R \\; ,\n\\end{aligned}\n\\tag{7.16}\\] where \\(B\\) is the intrinsic growth rate and \\(S_0\\) is the carrying capacity.\nWe can non-dimensionalize Equation 7.16 as before and obtain \\[\n\\begin{aligned}\n& \\frac{\\partial S}{\\partial t} = -  SI + b S\\left( 1 -  S \\right) \\; , & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& \\frac{\\partial I}{\\partial t} =   SI - \\mu \\,  I+   \\frac{ \\partial^2 I}{\\partial x^2} \\; ,  & \\qquad x \\in \\mathbb R , \\; t&gt;0 \\; , \\\\\n& S(0,x) = 1, \\qquad I(0,x) = I_0/S_0,  & \\quad x \\in \\mathbb R,\n\\end{aligned}\n\\tag{7.17}\\] where \\[\nb= \\frac{B}{r S_0}.\n\\]\nSpatially homogeneous steady states of Equation 7.17 are \\((S^\\ast_1, I^\\ast_1) = (1,0)\\) and \\((S^\\ast_1, I^\\ast_1) = (\\mu, b(1-\\mu))\\).\nTo analyse the existence of travelling wave solutions we write equations for \\(s(z)\\) and \\(i(z)\\), where \\(s(z)=S(t,x)\\), \\(i(z) = I(t,x)\\) with \\(z= x- vt\\)\n\\[\n\\begin{aligned}\n&  -v s^\\prime =- i s  + b s ( 1-s) \\; , \\\\\n& - v i^\\prime =  i s - \\mu i +  i^{\\prime \\prime}  \\;\n\\end{aligned}\n\\] {eq-sir_tw_growth} and by introducing new variable \\(w= i^\\prime\\) obtain\n\\[\n\\begin{aligned}\n&   s^\\prime = \\frac 1 v i\\,  s  - \\frac  b v \\,  s ( 1-s) \\; , \\\\\n& i^\\prime = w, \\\\\n& w^{\\prime}= -  v w - i (s - \\mu)\\; .\n\\end{aligned}\n\\tag{7.18}\\] The system Equation 7.18 has two stationary solutions\n\\[\n(s^\\ast_1, i^\\ast_1, w^\\ast_1) = (1,0,0)\n\\] and\n\\[(s^\\ast_2, i^\\ast_2, w^\\ast_2) = (\\mu, b(1-\\mu),0)\n\\]. Considering linearisation of Equation 7.18 and computing eigenvalues of the Jabocian matrix \\[\nJ(s,i,w)= \\begin{pmatrix}\n\\frac{i}{v} - \\frac{b}{v}  + \\frac{2bs}{v} & \\frac{s}{v} & 0 \\\\\n0 & 0 & 1\\\\\n- i & \\mu - s & -v\n\\end{pmatrix}\n\\]\nevaluated at the steady states we obtain that \\[\n(s^\\ast_1, i^\\ast_1, w^\\ast_1) = (1,0,0)\n\\]\nis a saddle point and \\[\n(s^\\ast_2, i^\\ast_2, w^\\ast_2) = (\\mu, b(1-\\mu),0)\n\\]\nis a stable node for \\(\\mu &lt; \\mu^\\ast\\) and a stable spiral (focus) for \\(\\mu &gt;\\mu^\\ast\\), with some threshold value \\(\\mu^\\ast\\).\nThus we can show that a travelling wave solution exists which connects two steady states \\((1,0)\\) and\n\\[\n(\\mu, b(1-\\mu))\n\\] and there exists a threshold \\(\\mu=\\mu^\\ast\\) such that for \\[\n1&gt;\\mu &gt; \\mu^\\ast\n\\]\nthe approach to \\[\n(\\mu, b(1-\\mu))\n\\] is oscillatory, whereas for \\[\n0&lt;\\mu &lt; \\mu^\\ast\n\\] it is monotonic."
  }
]